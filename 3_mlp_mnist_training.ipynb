{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"3_mlp_mnist_training.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyN8UH7Q4FuNcTzUOmhZEe2z"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"zPTNy_tHUrrI"},"source":["<h1><center> MLP MNIST Training </center></h1>\n","\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"N_fSAUpAZj9E"},"source":["### Cristiano De Nobili - My Contacts\n","For any questions or doubts you can find my contacts here:\n","\n","<p align=\"center\">\n","\n","[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Instagram_logo_2016.svg/2048px-Instagram_logo_2016.svg.png\" width=\"20\">](https://www.instagram.com/denocris/?hl=it)\n","[<img src=\"https://1.bp.blogspot.com/-Rwqcet_SHbk/T8_acMUmlmI/AAAAAAAAGgw/KD_fx__8Q4w/s1600/Twitter+bird.png\" width=\"30\">](https://twitter.com/denocris) \n","[<img src=\"https://loghi-famosi.com/wp-content/uploads/2020/04/Linkedin-Simbolo.png\" width=\"40\">](https://www.linkedin.com/in/cristiano-de-nobili/)     \n","\n","</p>\n","\n","or here (https://denocris.com).\n","\n","### Useful Links\n","\n","All notebooks can be found [here!](https://drive.google.com/drive/folders/1i3cNfzWZTNXfvkFVVIIDXjRDdSa9L9Dv?usp=sharing)\n","\n","Introductory slides [here!](https://www.canva.com/design/DAEa5hLfuWg/-L2EFFfZLVuiDkmg4KiKkQ/view?utm_content=DAEa5hLfuWg&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink)\n","\n","Collection of references: [here!](https://denocris.notion.site/Deep-Learning-References-0c5af2dc5c8d40baba19f1328d596fff)\n"]},{"cell_type":"markdown","metadata":{"id":"rychVYL5J_-O"},"source":["### Tools used \n","\n","PyTorch, NumPy, sklearn. To perform grid search we will use the Optuna optimization library.\n","\n","### Notebook Outline\n","\n","* information theory background;\n","* write and train a MLP on MNIST using hold-out validation;\n","* implement grid search with Optuna;\n","* learn k-fold cross-validation.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"p1WdF9dANBDu"},"source":["## Packages and GPU Settings"]},{"cell_type":"code","metadata":{"id":"M99bQapvPh-e"},"source":["%%capture\n","!pip install -q tensorboard\n","!pip install -q optuna "],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"53Fac-e3rNUw"},"source":["import torch\n","\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torchvision.datasets import MNIST\n","from torch.utils.data import DataLoader, TensorDataset, random_split\n","from torch.utils.tensorboard import SummaryWriter\n","from torchvision import transforms\n","from torchsummary import summary\n","\n","\n","from matplotlib import pyplot as plt\n","import numpy as np\n","import random\n","import optuna"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SG9z4Rz_HCPS"},"source":["GPU info e device set up"]},{"cell_type":"code","metadata":{"id":"MjmlP7ZObnce","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155537841,"user_tz":-60,"elapsed":18,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"3859c89e-e643-4c5a-929c-cc2b6a7bf65a"},"source":["gpu_info = !nvidia-smi\n","gpu_info = '\\n'.join(gpu_info)\n","if gpu_info.find('failed') >= 0:\n","  print('Select the Runtime → \"Change runtime type\" menu to enable a GPU accelerator, ')\n","  print('and then re-execute this cell.')\n","else:\n","  print(gpu_info)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Sun Jan  2 20:32:17 2022       \n","+-----------------------------------------------------------------------------+\n","| NVIDIA-SMI 495.44       Driver Version: 460.32.03    CUDA Version: 11.2     |\n","|-------------------------------+----------------------+----------------------+\n","| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n","| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n","|                               |                      |               MIG M. |\n","|===============================+======================+======================|\n","|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n","| N/A   35C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n","|                               |                      |                  N/A |\n","+-------------------------------+----------------------+----------------------+\n","                                                                               \n","+-----------------------------------------------------------------------------+\n","| Processes:                                                                  |\n","|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n","|        ID   ID                                                   Usage      |\n","|=============================================================================|\n","|  No running processes found                                                 |\n","+-----------------------------------------------------------------------------+\n"]}]},{"cell_type":"code","metadata":{"id":"Ozj-Ar_7b_55"},"source":["use_cuda = torch.cuda.is_available()\n","device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n","kwargs = {'num_workers': 1, 'pin_memory': True} if use_cuda else {}"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"uOyMhZgTHinw"},"source":["## Information Theory Background \n"]},{"cell_type":"markdown","metadata":{"id":"a_h2KilRH39t"},"source":["Basic notions of Information Theory are essetial for the understanding of many machine/deep learning mechanisms as we will see in a while."]},{"cell_type":"markdown","metadata":{"id":"CtrqdhkMID39"},"source":["### Self-Information\n","\n","Every event takes with it an ammount of self-information. The idea behind self-information goes as follows\n","\n","* if an event always occurs, we associate it with a smaller amount of information. It will not suprise us!\n","* On the other side, a rare event is associated with a huge amount of information. It will suprise us!\n","\n","I am not surprise to see the sunrise every morning (likely event). Instead,  I would be really suprised if tomorrow the Sun will not rise (unlikely event). This amount of surprise or self-information of the event $x$ is quantified by\n","\n","$$I(x) = - \\log p(x),$$\n","\n","where $p(x)$ is the probability of the event $x$. If $p(x)=1$, then self-info is zero. A rare event instead has a huge surpise factor.\n","\n","### Shannon Entropy \n","\n","Here the original paper by Claude Shannon (1948): [A Mathematical Theory of Communication](http://people.math.harvard.edu/~ctm/home/text/others/shannon/entropy/entropy.pdf).\n","\n","In terms of self-info, Shannon Entropy is the average self-information (expected value) over all possible values of X.\n","The entropy for a probability $p(x)$ distribution is\n","\n","$$ S = - \\sum_i p(x_i) \\log p(x_i),$$\n","\n","where we assume we know the probability $p$ for each outcome $i$ and $ \\sum_i p(x_i)=1$. If we use $log_2$ for our calculation we can interpret entropy as *the minimum number of bits it would take us to encode our information*.\n","\n","For continous variables, we can use the integral form\n","\n","$$ S = - \\int  p(x) \\log p(x) \\, dx,$$\n","\n","where now $p(x)$ is taking the role of a probability density function (PDF). Take in mind that a broad probability density has higher entropy than a narrowed one (think about Gaussian distribution vs delta Dirac, which has $S=0$).\n","\n","In both discrete and continous formulation, we are computing the expectation (i.e. average) of the negative log-probability (i.e. self-info) which is the theoretical minimum encoding size of the information from the event $x$. The same formula is usually written as\n","\n","$$S = \\mathbb E _{\\, x \\sim p} \\left[ -\\log p(x) \\right],$$\n","\n","where $x \\sim p$ means that we calculate the expectation with the probability distribution $p$."]},{"cell_type":"markdown","metadata":{"id":"8BEow_oxYSje"},"source":["Let's give an example! \n","\n","<!---\n","  REMIND to change open with uc\n"," https://drive.google.com/open?id=1Y52T3Z4dwRU4Rq5L5bEVYh0d3kU0aVB8\n","--->\n","\n","  <center>  <img src=https://drive.google.com/uc?id=1GaAeK8xIZCVDRb-oHQNUzRuoOprFh1eS \" width=\"700\">  </center> "]},{"cell_type":"markdown","metadata":{"id":"K5E4znWyYWDT"},"source":["Let us say we have to pass a message about what drink Cristiano will order during an event. In general, Cristiano loves [Midori Sour](https://drizly.com/midori-sour/r-b972d5282bec6fe8) , Daiquiri, Spritz and Wine.\n","\n","On Monday, Cristiano loves to listen Jazz and the probability distribution of his choice is: \n","\n","$$P(\\text Midori ) =  P(\\text Daiquiri ) = P(\\text Spritz ) = P(\\text Wine ) = 0.25,$$\n","\n","while the corresponding entropy\n","\n","$$S = - \\frac{1}{4} \\log \\frac{1}{4} - \\frac{1}{4} \\log \\frac{1}{4} - \\frac{1}{4} \\log \\frac{1}{4} - \\frac{1}{4} \\log \\frac{1}{4} = 2$$\n","\n","On Wednesday, he usually meets with some friends after work: \n","\n","$$P(\\text Midori ) = 0.125,\\;  P(\\text Daiquiri ) =0.125,\\;  P(\\text Spritz ) = 0.5,\\; P(\\text  Wine ) = 0.25,$$\n","\n","while the corresponding entropy\n","\n","$$S = - \\frac{1}{8} \\log \\frac{1}{8} - \\frac{1}{8} \\log \\frac{1}{8} - \\frac{1}{2} \\log \\frac{1}{2} - \\frac{1}{4} \\log \\frac{1}{4} = 1.75$$\n","\n","\n","On Thursday, he often goes to an event where cocktail attire dress code is required\n","\n","$$P(\\text Midori ) = 0.95,\\;  P(\\text Daiquiri ) =0.02,\\;  P(\\text Spritz ) = 0.018,\\; P(\\text  Wine ) = 0.012,$$\n","\n","and the corresponding entropy\n","\n","$$S = - 0.95 \\log 0.95 - 0.02 \\log 0.02 - 0.018 \\log 0.018 - 0.012 \\log 0.012 = 0.364$$"]},{"cell_type":"code","metadata":{"id":"KReLhZDvICt1","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599731724144,"user_tz":-120,"elapsed":734,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"3d38218f-ef94-4b5b-cbd3-1b05a3645d78"},"source":["# On Monday, all drinks have equal probability to be chose\n","entropy_1 = -0.25*np.log2(0.25)-0.25*np.log2(0.25)-0.25*np.log2(0.25)-0.25*np.log2(0.25)\n","print('On Monday, high entropy: ', entropy_1)\n","\n","# On Wednesday, some are more probable than others\n","entropy_2 = -0.5*np.log2(0.5)-0.25*np.log2(0.25)-0.125*np.log2(0.125)-0.125*np.log2(0.125)\n","print('On Wednesday, medium entropy: ', entropy_2)\n","\n","# On Thursday, one drink is by far the most probable\n","entropy_3 = -0.95*np.log2(0.95)-0.02*np.log2(0.02)-0.018*np.log2(0.018)-0.012*np.log2(0.012)\n","print('On Thursday, low entropy: ', entropy_3)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["On Monday, high entropy:  2.0\n","On Wednesday, medium entropy:  1.75\n","On Thursday, low entropy:  0.36407300467232967\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"CZh-58l2Qwvu"},"source":["If entropy is high (encoding size $log_2 p(x)$ is big on average), it means we have many message types with small and almost equal probabilities. Hence, every time a new message arrives, you would expect a different type than previous messages. You may see it as a disorder or uncertainty or unpredictability.\n","\n","On the contrary, when a message has much smaller probability than other messages, it appears as a surprise because on average you would expect other more frequently sent message types. Moreover, a rare message type has more information than more frequent message types because it eliminates a lot of other probabilities and tells us more specific information.\n","\n","In the drink scenario, by sending “Wine” on thursday which happens 1.2% of the times, we are reducing the uncertainty by 98.8% of the probability distribution (“Midori, Daiquiri, Spritz”) provided we had no information before. If we were sending “Midori” (95%) instead, we would be reducing the uncertainty by 5% only.\n","\n","If the entropy is high (ex: fair coin), the average encoding size is significant which means each message tends to have more (specific) information. Again, this is why high entropy is associated with disorder, uncertainty, surprise, unpredictability, amount of information. The more random a message is, the more information will be gained from decoding the message.\n","\n","Low entropy (ex: sunrise) means that most of the times we are receiving the more predictable information which means less disorder, less uncertainty, less surprise, more predictability and less (specific) information. This is the Thursday case."]},{"cell_type":"markdown","metadata":{"id":"Fu6ZmWp5UGDa"},"source":["### Cross Entropy\n","\n","Suppose to have two distributions, the true one $p(x)$ and the estimated $q(x)$. In the language of neural networks, $p(x)$ would be the grond truth (labels in one hot-encoding) and $q(x)$ the outcome of the net, i.e. the one that your machine learning algorithm is trying to match. Cross entropy is a mathematical tool for comparing two probability distributions $p(x)$ and $q(x)$ and it is expressed by the formula \n","\n","$$ H (p,q) = - \\int p(x) \\log q(x)\\,dx.$$\n","\n","If $\\log$ is in base $2$, then cross entropy measures the number of bits you will need encoding symbols from $p$ using the wrong distribution $q$. Subtracting to cross entropy the entropy of $p$, you are counting the cost in terms of bits of using the wrong distribution $q$ (this somehow will be KL-divergence). An important property of cross-entropy is that its value is minimum (and corresponds to $H(p)$) when $p(x)=q(x)$. That is the reason why, during training we want to minimize its value. This corresponds to force the estimated distribution $q(x)$ to be close to the true one $p(x)$."]},{"cell_type":"markdown","metadata":{"id":"60tieif3uc-l"},"source":["### Kullback-Leibler Divergence\n","\n","KL-divergence is just a slight modification of our formula for entropy. Rather than just having our probability distribution $h$ we add into the game our approximating distribution $g$. Then we look at the difference of the log values for each\n","\n","$$D_{KL}(h || g) =  \\sum_i h(x_i) (\\log h(x) - \\log g(x)) = \\sum_i h(x_i) \\log \\frac{h(x)}{g(x)}$$ \n","\n","from which\n","\n","$$H(h, g) =  H(h) + D_{KL}(h || g).$$ \n","\n","\n","KL-divergence is the expectation of the log-difference between the probability of data in the original distribution $h$ with the approximating distribution $g$. Again, if we think in terms of $\\log_2$ we can interpret this as how many bits of information we expect to lose when we choose an approximation $g$ of our original ditribution $h$. \n","\n","In the variational autoencoder loss function, the KL-divergence is used to force the distribution of latent variables $q(z | x)$ to be a normal distribution $n(z)$ so that we can sample latent variables from the normal distribution. As such, the KL-divergence is included in the loss function to improve the similarity between the distribution of latent variables and the normal distribution. More about **KL** can be found [here](https://towardsdatascience.com/demystifying-kl-divergence-7ebe4317ee68) and about **cross-entropy** [here](https://towardsdatascience.com/demystifying-cross-entropy-e80e3ad54a8)."]},{"cell_type":"markdown","metadata":{"id":"0hbIeSgD_YUw"},"source":["## Training, Validation and Test Sets\n","\n","* **parameters:** weights and biases of a DNN which transform the input before applying the activation function. Each layer has its own set of parameters. The parameters are adjusted through backpropagation to minimize the loss function or in other words are learned during the training process;\n","\n","* **hyperparameters:** unlike parameters, their values are not adapted by the learning algorithm itself. They can be viewed as settings that can be used to control the behaviour of the algorithm. Examples are number of layers, type of architecture, batch size, learning rate, etc...;\n","\n","* **training set:** a set of examples used for learning. It affects parameters ann in particular they are optimized according to this set;\n","\n","* **validation set:** a set of examples not seen by the model during training. It is like a mini-test set that provides feedback to the model during training on how well the current weights generalize beyond the training set. It does not impact or adjust weights directly, but providing information about overfitting it can indirectly impact weights if some regularization techniques are applied. In addition, validation set is widely used to tune hyperparameters;\n","\n","* **test set:** a set of examples used at the end of training and validation to assess the predictive power of your model."]},{"cell_type":"markdown","metadata":{"id":"MHSBvKR3QNTV"},"source":["## A Complete Training of a MLP Model on MNIST Dataset\n","\n","In this section, we want to show a complete train of a MLP network . We will show the following pipelines\n","\n","* Import, preprocess and properly normalize training and test data;\n","* Build up the MLP and init its weights;\n","* Train and evaluate the model using standard hold-out validation;\n","* Tune hyperparameters with Optuna;\n","* Train and evaluate the model using K-Fold Cross-Validation."]},{"cell_type":"markdown","metadata":{"id":"ZBKPCzq6T781"},"source":["## Train MLP Model with hold-out validation"]},{"cell_type":"markdown","metadata":{"id":"9AE9tPDSt6KK"},"source":["### Import and Preprocess Data"]},{"cell_type":"markdown","source":["MNIST is a dataset for handwritten digit recognition.\n","\n","* The dataset is composed of 60,000 grayscale images\n","  * by default, the dataset is already split into a training set of 50,000 images, while the remaining 10,000 images make up the test/validation set\n","* Each image is composed of 28x28 pixel\n","* Only one digit is present in each image\n","  * thus, we will be classifying digits from 0 to 9 (10 classes)\n","* The digit is centered within the image\n","\n","From **torchvision** we import the MNIST dataset "],"metadata":{"id":"hD8f7nPP_zs0"}},{"cell_type":"code","source":["%%capture\n","#Download data\n","train_set = MNIST('./data', train=True, download=True)\n","test_set = MNIST('./data', train=False, download=True)"],"metadata":{"id":"5_MazLV_qDmi"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["train_set.data.numpy().shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4JYVj4sWrWv4","executionInfo":{"status":"ok","timestamp":1641155589533,"user_tz":-60,"elapsed":252,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"4a1ca433-0f22-481c-bdc5-582f22bf830c"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(60000, 28, 28)"]},"metadata":{},"execution_count":6}]},{"cell_type":"code","metadata":{"id":"PYW3X_OjjrVt","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155590805,"user_tz":-60,"elapsed":234,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"eb1c8b70-a145-4e03-a199-411dfc15df9c"},"source":["# First image in dataset\n","img = train_set.data.numpy()[0]\n","img.shape"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(28, 28)"]},"metadata":{},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"rCuQNDuWoKSA","colab":{"base_uri":"https://localhost:8080/","height":282},"executionInfo":{"status":"ok","timestamp":1641155592180,"user_tz":-60,"elapsed":468,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"e5e465d3-9cf4-4a00-fe18-cbc545e9e95a"},"source":["plt.imshow(img, interpolation=\"nearest\", cmap=\"gray_r\")"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa43e200bd0>"]},"metadata":{},"execution_count":8},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"code","source":["imgs = train_set.data.numpy()[0:5]\n","imgs.shape"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"ykqVWzhgoE8t","executionInfo":{"status":"ok","timestamp":1641155596536,"user_tz":-60,"elapsed":244,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"fe8d4dda-49ba-46a7-c96c-a7bdeb32b0dd"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["(5, 28, 28)"]},"metadata":{},"execution_count":9}]},{"cell_type":"markdown","source":["Applying a reshape we can view more than one sample"],"metadata":{"id":"VErobQDOsuie"}},{"cell_type":"code","source":["# use this trick\n","multi_img_reshaped = imgs.reshape(5*28, 28)\n","plt.imshow(multi_img_reshaped, cmap=\"gray\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":286},"id":"sVUuKi_hoAvG","executionInfo":{"status":"ok","timestamp":1641155600584,"user_tz":-60,"elapsed":276,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"ad93e7b0-6a60-4842-dc4d-0e4abf812959"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<matplotlib.image.AxesImage at 0x7fa43dcb18d0>"]},"metadata":{},"execution_count":10},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"needs_background":"light"}}]},{"cell_type":"markdown","source":["Normally, digital pixels have values from $0$ to $255$. On the other side, neural networks process inputs using small weight values, and inputs with large integer values can disrupt or slow down the learning process. Therefore it is a good practice to normalize input to small values. We will apply the centering procedure, that consist of dividing first all pixel values by the highest value $255$. Then, we subtract the mean value and dividing by the standard deviation.\n","\n","As a first step, let us compute mean and standard deviation of MNIST training dataset:"],"metadata":{"id":"pzPVNUawtNt8"}},{"cell_type":"code","metadata":{"id":"U7oqJm4LuTB7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155607419,"user_tz":-60,"elapsed":680,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"f4a3ff44-888c-434f-d51a-7137886a4fdb"},"source":["train_set_array = train_set.data.numpy() / 255.0\n","test_set_array = test_set.data.numpy() / 255.0\n","\n","print('Train mean and std: %f  %f' %(train_set_array.mean(), train_set_array.std()))\n","print('Test mean and std: %f  %f' %(test_set_array.mean(), test_set_array.std()))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train mean and std: 0.130660  0.308108\n","Test mean and std: 0.132515  0.310480\n"]}]},{"cell_type":"markdown","source":["Now we go on with three steps:\n","\n","* Set random seeds;\n","* Apply **transforms** ([Official Docs](https://pytorch.org/vision/stable/transforms.html)) which allows a set of common image transformations that can be composed;\n","* Use `DataLoader`, that combines a dataset and a sampler, and provides an iterable over the given dataset. It handles the dataset in mini-batch for Stochastic Gradient Descent."],"metadata":{"id":"SF-lJXJctxKO"}},{"cell_type":"code","source":["# set the seed: built-in python, numpy, and pytorch\n","seed = 172\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed) # works for all devices (CPU and GPU)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"6_4rNQ74t9FF","executionInfo":{"status":"ok","timestamp":1641155635002,"user_tz":-60,"elapsed":224,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"eb3312d5-00f9-409d-d4c1-b35dca548f02"},"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7fa475596510>"]},"metadata":{},"execution_count":12}]},{"cell_type":"code","metadata":{"id":"fQj-ZUoUvjTC"},"source":["batch_size = 16\n","\n","transform = transforms.Compose([transforms.ToTensor(), \n","                                        transforms.Normalize( (0.1307,), (0.3081,))])\n","\n","# DataLoader: combines a dataset and a sampler, and provides an iterable over the given dataset.\n","train_loader = DataLoader(MNIST(root = './data', train = True, transform = transform, download=True), batch_size=batch_size , shuffle=False)\n","# Splitting the test images (tot 10k) in valid and test set.\n","valid_loader_tmp, test_loader_tmp = random_split(MNIST(root = './data', train = False, transform = transform, download=True), [7000, 3000]) \n","\n","valid_loader = DataLoader(valid_loader_tmp, batch_size=batch_size , shuffle=False)\n","test_loader = DataLoader(test_loader_tmp, batch_size=batch_size , shuffle=False)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"N2FRkLfBA6yW","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155639747,"user_tz":-60,"elapsed":241,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"2804aabb-89cc-4e56-da7f-612d3519e3f1"},"source":["# check for seed = 172\n","imgs_check = next(iter(valid_loader))\n","np.array_equal(imgs_check[1].numpy() , np.array([1, 4, 6, 5, 9, 7, 3, 4, 7, 0, 2, 1, 9, 7, 6, 4]))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":14}]},{"cell_type":"markdown","metadata":{"id":"nxdgzVqr0Zgg"},"source":["**A good practice** is to normalize the test set using the training normalization parameters (mean and std).\n","\n","We want testing data points to represent real-world data that the network has never seen. If we take the mean and variance of the whole dataset we will be introducing future information into the training explanatory variables (i.e. the mean and variance).\n","\n","Therefore, you should perform feature normalisation over the training data. Then perform normalisation on testing instances as well, but this time using the mean and variance of training explanatory variables. In this way, we can test and evaluate whether our model can generalize well to new, unseen data points.\n","\n","To better understand imagine now that we have trained our model and we are on a production where new data keep coming for prediction. We might not get them in mass, but one by one such as in an API call. We do not have the mean and standard deviation of those new data. We only have the mean and std during the training process.  To sum up, the goal is to be as close as possible to real problems. Therefore, during training we should not use any knowledge we get from the test data."]},{"cell_type":"markdown","metadata":{"id":"5ryJmjq3amVy"},"source":["###MLP Model\n","\n","The idea is to introduce a few concepts, build up a pipeline and be as clear as possible. "]},{"cell_type":"code","source":["# write here the class for your MLP\n","class MLP(nn.Module):\n","    def __init__(self, dropout_rate = .2):\n","        super().__init__()\n","\n","\n","        self.flat = torch.nn.Flatten() # X comes in as a n x 1 x 28 x 28 -> we need n 784-size vectors (or, a n x 784 matrix). flatten does this\n","        self.layer1 = torch.nn.Linear(784, 16)\n","        self.layer2 = torch.nn.Linear(16, 32)\n","        self.layer3 = torch.nn.Linear(32, 24)\n","        self.layer4 = torch.nn.Linear(24, 10)\n","        \n","        self.droput = nn.Dropout2d(p = dropout_rate)\n","\n","\n","    def forward(self, X): \n","        out = self.flat(X)\n","        out = self.layer1(out)\n","        out = torch.nn.functional.relu(out)\n","        out = self.layer2(out)\n","        out = torch.nn.functional.relu(out)\n","        out = self.layer3(out)\n","        out = torch.nn.functional.relu(out)\n","        out = self.droput(out)\n","        logits = self.layer4(out)\n","        # out = torch.nn.functional.softmax(out) -> this is wrong since we will use NegativeLogLikelihood Loss\n","        # softmax transforms a vector into a simplex (vector of positive nums summing to 1): \n","        # [1,2,3,4] -> [0.1, 0.2, 0.3, 0.4]\n","        # instead we need the logsoftmax\n","        #out = torch.nn.functional.log_softmax(out)\n","        return logits"],"metadata":{"id":"H6UteiKb27Fc"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UUEiwOtSqFx1"},"source":["### Weights Initialization"]},{"cell_type":"markdown","metadata":{"id":"dimObwP6bUgb"},"source":["We will now initialize weights (and biases) using Xavier initialization. If you are more interested in understanding its details, you can find here the origina paper by [Xavier and Bengio](http://proceedings.mlr.press/v9/glorot10a/glorot10a.pdf).\n","\n","There are several ways to initialize parmeters. However, the most naively ones might cause vanishing gradinet effects during training. Researchers finded more safe initializations. One of them is Xavier initialization.\n","It sets a layer’s weights to values chosen from a random uniform distribution that is bounded between\n","\n","\n","$$\\pm \\frac{\\sqrt{6}}{\\sqrt{n_i+n_{i+1}}}, $$\n","\n","where $n_i$ is the number of incoming network connections, or *fan-in*, to the layer, and $n_{i+1}$ is the number of outgoing network connections from that layer, also known as the *fan-out*. We are going to use it for weights initialization (`nn.init.xavier_uniform_(m.weight)`). For biases initialization instead we will adopt a slightly different approach, just to show you how you can play with initializations."]},{"cell_type":"code","metadata":{"id":"eUUdTKP7fhFo"},"source":["def weight_init(m):\n","    torch.manual_seed(seed) \n","    if isinstance(m, nn.Linear):\n","        nn.init.xavier_uniform_(m.weight)\n","        if m.bias is not None:\n","            fan_in, _ = nn.init._calculate_fan_in_and_fan_out(m.weight)\n","            bound = 1 / np.sqrt(fan_in)\n","            nn.init.uniform_(m.bias, -bound, bound)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"22InO0WGtZu_","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155753358,"user_tz":-60,"elapsed":8581,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"ace35660-be6f-4c11-9e2a-c1794c23f65c"},"source":["model = MLP(dropout_rate = 0.2)\n","#lenet = MLP(dropout_rate = 0.000001)\n","\n","# apply weight init\n","model.apply(weight_init)\n","\n","# put the model on the device\n","model.to(device) \n"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["MLP(\n","  (flat): Flatten(start_dim=1, end_dim=-1)\n","  (layer1): Linear(in_features=784, out_features=16, bias=True)\n","  (layer2): Linear(in_features=16, out_features=32, bias=True)\n","  (layer3): Linear(in_features=32, out_features=24, bias=True)\n","  (layer4): Linear(in_features=24, out_features=10, bias=True)\n","  (droput): Dropout2d(p=0.2, inplace=False)\n",")"]},"metadata":{},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"74o3mkz0vfYR","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155757937,"user_tz":-60,"elapsed":256,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"dd596361-8975-4525-ac4a-62af7a442597"},"source":["# check that the model is working\n","summary(model, (1, 28, 28))"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["----------------------------------------------------------------\n","        Layer (type)               Output Shape         Param #\n","================================================================\n","           Flatten-1                  [-1, 784]               0\n","            Linear-2                   [-1, 16]          12,560\n","            Linear-3                   [-1, 32]             544\n","            Linear-4                   [-1, 24]             792\n","         Dropout2d-5                   [-1, 24]               0\n","            Linear-6                   [-1, 10]             250\n","================================================================\n","Total params: 14,146\n","Trainable params: 14,146\n","Non-trainable params: 0\n","----------------------------------------------------------------\n","Input size (MB): 0.00\n","Forward/backward pass size (MB): 0.01\n","Params size (MB): 0.05\n","Estimated Total Size (MB): 0.06\n","----------------------------------------------------------------\n"]}]},{"cell_type":"markdown","metadata":{"id":"cl5aSZSDdC0W"},"source":["To keep under control all steps"]},{"cell_type":"code","metadata":{"id":"vDDrKnst15wX","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641155761218,"user_tz":-60,"elapsed":238,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"2186c187-f9cd-43e3-820c-d935d4802530"},"source":["torch.save(model.state_dict(), './weights_init')\n","\n","list(model.parameters())[0]"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Parameter containing:\n","tensor([[-0.0438, -0.0506,  0.0692,  ..., -0.0128,  0.0556,  0.0760],\n","        [-0.0749,  0.0550, -0.0272,  ..., -0.0708,  0.0174,  0.0558],\n","        [-0.0713,  0.0166,  0.0674,  ..., -0.0340, -0.0851,  0.0855],\n","        ...,\n","        [-0.0401, -0.0709, -0.0674,  ...,  0.0730,  0.0402, -0.0470],\n","        [-0.0060, -0.0686, -0.0389,  ..., -0.0635, -0.0832,  0.0736],\n","        [ 0.0243, -0.0643, -0.0081,  ..., -0.0625, -0.0108,  0.0190]],\n","       device='cuda:0', requires_grad=True)"]},"metadata":{},"execution_count":22}]},{"cell_type":"markdown","metadata":{"id":"ROpfooUCqNrT"},"source":["### Training and Evaluation\n","\n","Let us first define \n","\n","* a function that computes accuracy from logits (applying a softmax function);\n","\n","* a function that computes evaluation.\n","\n","Logits are the unnormalized final scores (predictions) of our model. We must apply softmax to it to get a probability distribution over our classes. If you remind, the LeNet() class returns logits\n"]},{"cell_type":"code","metadata":{"id":"--ZryiNvxyth"},"source":["def get_accuracy_from_logits(logits, labels):\n","    softmax = nn.Softmax(dim=1)\n","    argmax = torch.argmax(softmax(logits.float()), dim=1)\n","    pred_class = argmax.long()\n","    acc = (pred_class == labels.long()).float().mean()\n","    return acc\n","\n","def evaluate(net, crit, dataloader, device):\n","    net.eval()\n","\n","    mean_acc, mean_loss = 0, 0\n","    count = 0\n","\n","    with torch.no_grad():\n","        for data, labels in dataloader:\n","            data, labels = data.to(device), labels.to(device)\n","            logits = net(data)\n","            mean_loss += crit(logits, labels).item()\n","            mean_acc += get_accuracy_from_logits(logits, labels)\n","            count += 1\n","\n","    return mean_acc / count, mean_loss / count"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"TnmsFxJppv1n","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641156325691,"user_tz":-60,"elapsed":2,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"1d0559af-909b-4d28-af8f-626e9394db1b"},"source":["len(train_loader) # 3750*batch_size"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["3750"]},"metadata":{},"execution_count":27}]},{"cell_type":"code","metadata":{"id":"1hotozlhni1N"},"source":["# The SummaryWriter class is your main entry to log data for consumption and visualization by TensorBoard.\n","writer = SummaryWriter() # it will output to ./runs/ directory by default\n","\n","def training(model, train_loader, valid_loader, optim, crit, epochs, device, model_save = True):\n","    # set up the model on training phase\n","    model.train()\n","    best_acc = 0\n","    tot_len = len(train_loader)\n","    for epoch in range(1, epochs + 1):\n","        for batch_idx, (data, labels) in enumerate(train_loader):\n","            # transfer data on the device\n","            data, labels = data.to(device), labels.to(device)\n","            #Clear gradients  \n","            # Since the backward() function accumulates gradients, and you do not want to mix up \n","            # gradients between different batches, you have to zero them out at the start of a new batch.\n","            optim.zero_grad()\n","            logits = model(data)\n","            loss = crit(logits, labels)\n","            loss.backward()\n","            optim.step()\n","            if batch_idx % 200 == 0:\n","                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n","                    epoch, batch_idx * len(data), len(train_loader.dataset),\n","                    100. * batch_idx / len(train_loader), loss.item()))\n","                writer.add_scalars('Loss', {'train': loss.item()}, batch_idx + tot_len*(epoch-1))\n","\n","            if batch_idx % 500 == 0:\n","                _, valid_loss = evaluate(model, crit, valid_loader, device)\n","                writer.add_scalars('Loss', {'valid': valid_loss}, batch_idx + tot_len*(epoch-1))\n","                # set again the model to train mode\n","                model.train()\n","    \n","        valid_acc, _ = evaluate(model, crit, valid_loader, device)\n","        #writer.add_scalar('Accuracy', valid_acc, tot_len + tot_len*(epoch-1))\n","        writer.add_scalars('Acc', {'valid': valid_acc}, tot_len + tot_len*(epoch-1))\n","\n","        if valid_acc > best_acc:\n","          print(\"Best validation accuracy improved from {} to {}, saving model...\".format(best_acc, valid_acc))\n","          best_acc = valid_acc\n","          if model_save:\n","            torch.save(model.state_dict(), 'Models/lenet_{}.pt'.format(epoch))\n","\n","    return best_acc\n","    \n","def test(model, device, test_loader):\n","    model.eval()\n","    test_loss = 0\n","    correct = 0\n","    with torch.no_grad():\n","        for data, labels in test_loader:\n","            data, labels = data.to(device), labels.to(device)\n","            output = model(data)\n","            test_loss += criterion(output, labels).item() # sum up batch loss\n","            pred = output.argmax(dim=1, keepdim=True) # get the index of the max log-probability\n","            correct += pred.eq(labels.view_as(pred)).sum().item()\n","\n","    test_loss /= len(test_loader.dataset)\n","\n","    print('\\nTest set: Loss: {:.4f}, Accuracy: {}/{} ({:.1f}%)\\n'.format(\n","        test_loss, correct, len(test_loader.dataset),\n","        100. * correct / len(test_loader.dataset)))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dcNjSHBbEiI0"},"source":["#!rm -rf runs\n","#!rm -rf Models"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4kENFWEdZKsh"},"source":["epochs = 3\n","!mkdir Models\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"61YjipGhv2za"},"source":["Let us train the MLP model"]},{"cell_type":"code","metadata":{"id":"xjjff52rZJGE","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641156410319,"user_tz":-60,"elapsed":80926,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"e179e194-376d-455f-ce11-7894eaf6e8f0"},"source":["# define loss function\n","criterion = nn.CrossEntropyLoss() # The input is expected to contain raw, unnormalized scores for each class (logits)\n","\n","# define optimizer\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001) \n","\n","kwargs = {'optim': optimizer, 'crit': criterion, \n","          'epochs': epochs, 'device': device}\n","\n","training(model, train_loader, valid_loader, **kwargs)\n","\n","writer.close()"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Train Epoch: 1 [0/60000 (0%)]\tLoss: 2.572841\n","Train Epoch: 1 [3200/60000 (5%)]\tLoss: 1.843356\n","Train Epoch: 1 [6400/60000 (11%)]\tLoss: 1.614798\n","Train Epoch: 1 [9600/60000 (16%)]\tLoss: 1.669044\n","Train Epoch: 1 [12800/60000 (21%)]\tLoss: 1.150312\n","Train Epoch: 1 [16000/60000 (27%)]\tLoss: 1.089453\n","Train Epoch: 1 [19200/60000 (32%)]\tLoss: 0.900591\n","Train Epoch: 1 [22400/60000 (37%)]\tLoss: 0.599012\n","Train Epoch: 1 [25600/60000 (43%)]\tLoss: 0.950690\n","Train Epoch: 1 [28800/60000 (48%)]\tLoss: 0.788940\n","Train Epoch: 1 [32000/60000 (53%)]\tLoss: 0.397875\n","Train Epoch: 1 [35200/60000 (59%)]\tLoss: 0.698616\n","Train Epoch: 1 [38400/60000 (64%)]\tLoss: 0.859560\n","Train Epoch: 1 [41600/60000 (69%)]\tLoss: 0.923415\n","Train Epoch: 1 [44800/60000 (75%)]\tLoss: 0.510844\n","Train Epoch: 1 [48000/60000 (80%)]\tLoss: 0.691882\n","Train Epoch: 1 [51200/60000 (85%)]\tLoss: 0.408627\n","Train Epoch: 1 [54400/60000 (91%)]\tLoss: 0.570020\n","Train Epoch: 1 [57600/60000 (96%)]\tLoss: 0.600812\n","Best validation accuracy improved from 0 to 0.8888412714004517, saving model...\n","Train Epoch: 2 [0/60000 (0%)]\tLoss: 0.193975\n","Train Epoch: 2 [3200/60000 (5%)]\tLoss: 0.471150\n","Train Epoch: 2 [6400/60000 (11%)]\tLoss: 0.373775\n","Train Epoch: 2 [9600/60000 (16%)]\tLoss: 0.790539\n","Train Epoch: 2 [12800/60000 (21%)]\tLoss: 0.478527\n","Train Epoch: 2 [16000/60000 (27%)]\tLoss: 0.478691\n","Train Epoch: 2 [19200/60000 (32%)]\tLoss: 0.332226\n","Train Epoch: 2 [22400/60000 (37%)]\tLoss: 0.159774\n","Train Epoch: 2 [25600/60000 (43%)]\tLoss: 0.455616\n","Train Epoch: 2 [28800/60000 (48%)]\tLoss: 0.428194\n","Train Epoch: 2 [32000/60000 (53%)]\tLoss: 0.423905\n","Train Epoch: 2 [35200/60000 (59%)]\tLoss: 0.854356\n","Train Epoch: 2 [38400/60000 (64%)]\tLoss: 0.591989\n","Train Epoch: 2 [41600/60000 (69%)]\tLoss: 0.555455\n","Train Epoch: 2 [44800/60000 (75%)]\tLoss: 0.248455\n","Train Epoch: 2 [48000/60000 (80%)]\tLoss: 0.645581\n","Train Epoch: 2 [51200/60000 (85%)]\tLoss: 0.465090\n","Train Epoch: 2 [54400/60000 (91%)]\tLoss: 0.520598\n","Train Epoch: 2 [57600/60000 (96%)]\tLoss: 0.268912\n","Best validation accuracy improved from 0.8888412714004517 to 0.9098173379898071, saving model...\n","Train Epoch: 3 [0/60000 (0%)]\tLoss: 0.085157\n","Train Epoch: 3 [3200/60000 (5%)]\tLoss: 0.275836\n","Train Epoch: 3 [6400/60000 (11%)]\tLoss: 0.056133\n","Train Epoch: 3 [9600/60000 (16%)]\tLoss: 0.275194\n","Train Epoch: 3 [12800/60000 (21%)]\tLoss: 0.365397\n","Train Epoch: 3 [16000/60000 (27%)]\tLoss: 0.413637\n","Train Epoch: 3 [19200/60000 (32%)]\tLoss: 0.372746\n","Train Epoch: 3 [22400/60000 (37%)]\tLoss: 0.191080\n","Train Epoch: 3 [25600/60000 (43%)]\tLoss: 0.270831\n","Train Epoch: 3 [28800/60000 (48%)]\tLoss: 0.257164\n","Train Epoch: 3 [32000/60000 (53%)]\tLoss: 0.265054\n","Train Epoch: 3 [35200/60000 (59%)]\tLoss: 0.497251\n","Train Epoch: 3 [38400/60000 (64%)]\tLoss: 0.495352\n","Train Epoch: 3 [41600/60000 (69%)]\tLoss: 0.616690\n","Train Epoch: 3 [44800/60000 (75%)]\tLoss: 0.351929\n","Train Epoch: 3 [48000/60000 (80%)]\tLoss: 0.223793\n","Train Epoch: 3 [51200/60000 (85%)]\tLoss: 0.314125\n","Train Epoch: 3 [54400/60000 (91%)]\tLoss: 0.314714\n","Train Epoch: 3 [57600/60000 (96%)]\tLoss: 0.247419\n","Best validation accuracy improved from 0.9098173379898071 to 0.9208047389984131, saving model...\n"]}]},{"cell_type":"markdown","metadata":{"id":"W6QyPq_6H6YO"},"source":["Let us now evaluate the model on the test set"]},{"cell_type":"code","metadata":{"id":"_pBd_Wz83GlS","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641148473803,"user_tz":-60,"elapsed":569,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"94687a59-0b0e-4057-efbf-ebcd6c767558"},"source":["# Model with Batch Normalization active\n","test(model, device = device, test_loader=test_loader)"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Test set: Loss: 0.0155, Accuracy: 2777/3000 (92.6%)\n","\n"]}]},{"cell_type":"code","metadata":{"id":"vKQKAqaI3KGu"},"source":["list(model.parameters())[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9m8rzjnKmU9P","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1641148551648,"user_tz":-60,"elapsed":227,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"}},"outputId":"33200abc-bbc8-4be5-9c59-1a4c1d60465c"},"source":["model_ = MLP(dropout_rate = 0.2)\n","model_.cuda()\n","model_.load_state_dict(torch.load('./weights_init'))"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<All keys matched successfully>"]},"metadata":{},"execution_count":78}]},{"cell_type":"code","metadata":{"id":"Qydnfz95mfrS"},"source":["list(model_.parameters())[0][0]"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"DoSdmZ-BblFi"},"source":["# Start tensorboard.\n","%load_ext tensorboard\n","%tensorboard --logdir runs/"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2VEH5WiYLYjB"},"source":["## Hyperparameters Tuning with Optuna\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"zJJo9vkBl2Qv"},"source":["Hyperparameter optimization is an important issue in machine learning. Parameters are learned during training, as we have seen so far. Hyperparameters are instead setup before training and they do not take part to backpropagation. Different hyperparameter setups can evolve in different performances. Therefore it is important to explore the landscape of hyperparameter combinations and find out the best one according to a choosen metric.\n","\n","[Optuna](https://optuna.org/) is an open source hyperparameter optimization framework to automate hyperparameter search. Optuna is framework agnostic. You can use it with any machine learning or deep learning framework.\n","\n","The main objects of an Optuna pipeline are\n","\n","* a **trial** corresponds to a single execution of the objective function and it is internally instantiated upon each invocation of the function;\n","\n","* **suggest methods** are called inside the objective function to obtain parameters for a trial;\n","\n","* a **study object** is created to start the optimization."]},{"cell_type":"code","metadata":{"id":"SXgEz_vuPAQp"},"source":["# let us define our objective function\n","def train_mnist(trial):\n","\n","  # configuration\n","  cfg = { 'device' : \"cuda\" if torch.cuda.is_available() else \"cpu\",\n","          'n_epochs' : 1,\n","          'seed' : 0,\n","          'model_save' : False,\n","          'lr' : trial.suggest_loguniform('lr', 1e-4, 1e-2),          \n","          'dropout': trial.suggest_discrete_uniform('dropout', 0.1, 0.3, 0.5),\n","          'optimizer': trial.suggest_categorical('optimizer',[torch.optim.SGD, torch.optim.Adam]),\n","          'batch_norm': trial.suggest_categorical('batch_norm',[True, False]),\n","          }\n","\n","  torch.manual_seed(cfg['seed'])\n","  # model\n","  model = MLP(dropout_rate = cfg['dropout']).to(device)\n","  # apply weight init\n","  model.apply(weight_init)\n","\n","  criterion = nn.CrossEntropyLoss()\n","  optimizer = cfg['optimizer'](model.parameters(), lr=cfg['lr'])\n","\n","  best_valid_acc = training(model, train_loader, valid_loader, optimizer, criterion, \n","                  epochs = cfg['n_epochs'], device = cfg['device'], model_save = cfg['model_save'])\n","\n","  return best_valid_acc"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RKpYTX-vEW6U"},"source":["To determine the hyperparameter values to be used in a trial, we must define e sampler. We will use `optuna.samplers.TPESampler()` that is based on Tree-structured Parzen Estimator algorithm (it makes use of Gaussian Mixture Models, more details [here](https://optuna.readthedocs.io/en/stable/reference/generated/optuna.samplers.TPESampler.html#optuna.samplers.TPESampler)). There are [several samplers](https://optuna.readthedocs.io/en/stable/reference/samplers.html), for instance also the most basic ones like `optuna.samplers.GridSampler` which suggests all combinations of parameters in the given search space during the study."]},{"cell_type":"code","metadata":{"id":"BoZYv0C3jCj4"},"source":["import joblib\n","\n","# a sampler has the responsibility to determine the parameter values to be evaluated in a trial.\n","sampler = optuna.samplers.TPESampler()\n","# You can also try \n","# sampler = optuna.samplers.GridSampler()\n","    \n","study = optuna.create_study(sampler=sampler, direction='maximize')\n","study.optimize(func=train_mnist, n_trials=15)\n","\n","# persist an arbitrary Python object into one file.\n","joblib.dump(study, './optuna_report.pkl')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XR7f5Y9gfxMz","colab":{"base_uri":"https://localhost:8080/","height":497},"executionInfo":{"status":"ok","timestamp":1599665015980,"user_tz":-120,"elapsed":1780,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"7267f7e4-32a2-4632-f1a9-0dbca7ff5efb"},"source":["# load the saved study\n","study = joblib.load('./optuna_report.pkl')\n","# convert in dataframe\n","df = study.trials_dataframe().drop(['state','datetime_start','datetime_complete'], axis=1)\n","df"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>number</th>\n","      <th>value</th>\n","      <th>duration</th>\n","      <th>params_batch_norm</th>\n","      <th>params_dropout</th>\n","      <th>params_lr</th>\n","      <th>params_optimizer</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>0.964041</td>\n","      <td>00:00:32.986281</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.004218</td>\n","      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>0.960331</td>\n","      <td>00:00:32.950794</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.003184</td>\n","      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>0.970034</td>\n","      <td>00:00:37.023680</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.001350</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>0.967894</td>\n","      <td>00:00:37.129444</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.009139</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>0.970177</td>\n","      <td>00:00:37.018455</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.000459</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>5</td>\n","      <td>0.958619</td>\n","      <td>00:00:37.011276</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.000163</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>6</td>\n","      <td>0.799087</td>\n","      <td>00:00:33.030336</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.000167</td>\n","      <td>&lt;class 'torch.optim.sgd.SGD'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>7</td>\n","      <td>0.967323</td>\n","      <td>00:00:36.794189</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.000430</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>8</td>\n","      <td>0.972032</td>\n","      <td>00:00:36.507813</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.000860</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>9</th>\n","      <td>9</td>\n","      <td>0.951199</td>\n","      <td>00:00:36.426737</td>\n","      <td>False</td>\n","      <td>0.1</td>\n","      <td>0.000105</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>10</th>\n","      <td>10</td>\n","      <td>0.969178</td>\n","      <td>00:00:36.309231</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.001205</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>11</th>\n","      <td>11</td>\n","      <td>0.971889</td>\n","      <td>00:00:36.135850</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.000520</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>12</th>\n","      <td>12</td>\n","      <td>0.967894</td>\n","      <td>00:00:36.359138</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.000502</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>13</th>\n","      <td>13</td>\n","      <td>0.973031</td>\n","      <td>00:00:36.360311</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.000660</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","    <tr>\n","      <th>14</th>\n","      <td>14</td>\n","      <td>0.967894</td>\n","      <td>00:00:36.710861</td>\n","      <td>True</td>\n","      <td>0.1</td>\n","      <td>0.002131</td>\n","      <td>&lt;class 'torch.optim.adam.Adam'&gt;</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["    number     value  ... params_lr                 params_optimizer\n","0        0  0.964041  ...  0.004218    <class 'torch.optim.sgd.SGD'>\n","1        1  0.960331  ...  0.003184    <class 'torch.optim.sgd.SGD'>\n","2        2  0.970034  ...  0.001350  <class 'torch.optim.adam.Adam'>\n","3        3  0.967894  ...  0.009139  <class 'torch.optim.adam.Adam'>\n","4        4  0.970177  ...  0.000459  <class 'torch.optim.adam.Adam'>\n","5        5  0.958619  ...  0.000163  <class 'torch.optim.adam.Adam'>\n","6        6  0.799087  ...  0.000167    <class 'torch.optim.sgd.SGD'>\n","7        7  0.967323  ...  0.000430  <class 'torch.optim.adam.Adam'>\n","8        8  0.972032  ...  0.000860  <class 'torch.optim.adam.Adam'>\n","9        9  0.951199  ...  0.000105  <class 'torch.optim.adam.Adam'>\n","10      10  0.969178  ...  0.001205  <class 'torch.optim.adam.Adam'>\n","11      11  0.971889  ...  0.000520  <class 'torch.optim.adam.Adam'>\n","12      12  0.967894  ...  0.000502  <class 'torch.optim.adam.Adam'>\n","13      13  0.973031  ...  0.000660  <class 'torch.optim.adam.Adam'>\n","14      14  0.967894  ...  0.002131  <class 'torch.optim.adam.Adam'>\n","\n","[15 rows x 7 columns]"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"code","metadata":{"id":"dSJzu-9PgZCV","colab":{"base_uri":"https://localhost:8080/","height":54},"executionInfo":{"status":"ok","timestamp":1599665083110,"user_tz":-120,"elapsed":1154,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"4d0cef9f-0239-41b2-f761-c0f4cceddf3e"},"source":["study.best_trial"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["FrozenTrial(number=13, value=0.9730308055877686, datetime_start=datetime.datetime(2020, 9, 9, 15, 19, 20, 717374), datetime_complete=datetime.datetime(2020, 9, 9, 15, 19, 57, 77685), params={'lr': 0.0006595402688301448, 'dropout': 0.1, 'optimizer': <class 'torch.optim.adam.Adam'>, 'batch_norm': True}, distributions={'lr': LogUniformDistribution(high=0.01, low=0.0001), 'dropout': DiscreteUniformDistribution(high=0.1, low=0.1, q=0.5), 'optimizer': CategoricalDistribution(choices=(<class 'torch.optim.sgd.SGD'>, <class 'torch.optim.adam.Adam'>)), 'batch_norm': CategoricalDistribution(choices=(True, False))}, user_attrs={}, system_attrs={}, intermediate_values={}, trial_id=13, state=TrialState.COMPLETE)"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"jVpuIr6mgZMv","colab":{"base_uri":"https://localhost:8080/","height":542},"executionInfo":{"status":"ok","timestamp":1599665101897,"user_tz":-120,"elapsed":3068,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"7e2217ee-0292-4da4-bd96-f2e185337cb2"},"source":["#optuna.visualization.plot_contour(study, params=['lr','optimizer'])\n","optuna.visualization.plot_optimization_history(study)"],"execution_count":null,"outputs":[{"output_type":"display_data","data":{"text/html":["<html>\n","<head><meta charset=\"utf-8\" /></head>\n","<body>\n","    <div>\n","            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n","                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n","        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n","            <div id=\"175e1b94-80f7-4261-a2ec-ce7adbb2ca8e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n","            <script type=\"text/javascript\">\n","                \n","                    window.PLOTLYENV=window.PLOTLYENV || {};\n","                    \n","                if (document.getElementById(\"175e1b94-80f7-4261-a2ec-ce7adbb2ca8e\")) {\n","                    Plotly.newPlot(\n","                        '175e1b94-80f7-4261-a2ec-ce7adbb2ca8e',\n","                        [{\"mode\": \"markers\", \"name\": \"Objective Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [0.9640410542488098, 0.9603310227394104, 0.9700341820716858, 0.9678937792778015, 0.9701768755912781, 0.958618700504303, 0.7990867495536804, 0.9673230051994324, 0.9720319509506226, 0.9511985778808594, 0.9691780209541321, 0.9718892574310303, 0.9678937792778015, 0.9730308055877686, 0.9678937792778015]}, {\"name\": \"Best Value\", \"type\": \"scatter\", \"x\": [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14], \"y\": [0.9640410542488098, 0.9640410542488098, 0.9700341820716858, 0.9700341820716858, 0.9701768755912781, 0.9701768755912781, 0.9701768755912781, 0.9701768755912781, 0.9720319509506226, 0.9720319509506226, 0.9720319509506226, 0.9720319509506226, 0.9720319509506226, 0.9730308055877686, 0.9730308055877686]}],\n","                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Optimization History Plot\"}, \"xaxis\": {\"title\": {\"text\": \"#Trials\"}}, \"yaxis\": {\"title\": {\"text\": \"Objective Value\"}}},\n","                        {\"responsive\": true}\n","                    ).then(function(){\n","                            \n","var gd = document.getElementById('175e1b94-80f7-4261-a2ec-ce7adbb2ca8e');\n","var x = new MutationObserver(function (mutations, observer) {{\n","        var display = window.getComputedStyle(gd).display;\n","        if (!display || display === 'none') {{\n","            console.log([gd, 'removed!']);\n","            Plotly.purge(gd);\n","            observer.disconnect();\n","        }}\n","}});\n","\n","// Listen for the removal of the full notebook cells\n","var notebookContainer = gd.closest('#notebook-container');\n","if (notebookContainer) {{\n","    x.observe(notebookContainer, {childList: true});\n","}}\n","\n","// Listen for the clearing of the current output cell\n","var outputEl = gd.closest('.output');\n","if (outputEl) {{\n","    x.observe(outputEl, {childList: true});\n","}}\n","\n","                        })\n","                };\n","                \n","            </script>\n","        </div>\n","</body>\n","</html>"]},"metadata":{"tags":[]}}]},{"cell_type":"markdown","metadata":{"id":"jB704nfU-eiB"},"source":["## K-Fold Cross Validation"]},{"cell_type":"markdown","metadata":{"id":"ZPyYQxI1x8hB"},"source":["So far, we have used holdout set for model validation that consists of splitting once and for all the whole dataset in training and validation sets. This method is widely used but can suffer from the lucky split phenomenon.\n","\n","It is a good practice in machine learning to overwhelm hold-out validation and exploit cross-validation. This means that multiple rounds of train/validation are performed using different data partitions. Validation results are then averaged over the rounds to give a fair estimate of the model predictive performances. This process allows to reduce variance and avoids the lucky split phonomenon.\n","\n","Let see how it works. Cross-validation is always performed on training set (Think about MNIST dataset, that has 60k samples in training set and 10K in test set). In case of k-fold cross validation, say number of samples in training set is 100 and you have taken k = 5, then train set is equally divided in 5 equal parts: p1, p2, p3, p4, p5.\n","Now, in first iteration/fold p1 will be left out and remaining 4 parts (p2, p3, p4, p5) will be used for training the algorithm and p1 to validate it. Once algorithm is trained this trained model will be validated on p1 from this you will get error/accuracy metric. Now in 2nd iteration/fold p2 will be left out and again algorithm will be trained on remaining 4 parts( p1, p3, p4, p5) and once algorithm is trained it gets validated on p2. It continues till all 5 iterations are over. At last you will get average train and validated error/accuracy metrics from cross validation exercise. And this is how cross-validation works and is used.\n","\n","<center>  <img src=\"https://drive.google.com/uc?export=view&id=1qRpYnHSzc1lhutp-F3ehpEGMSSa18Eza\"width=\"800\">  </center> \n","\n","\n","The best scenario is that our accuracy is similar in all our folds, say 92.0, 91.5, 92.0, 92.5 and 91.8. This means that our algorithm (and our data) is consistent and we can be confident that by training it on all the data set and deploy it in production will lead to similar performance.\n","However, we could end up in a slightly different scenario, say 92.0, 44.0, 91.5, 92.5 and 91.8. These results look very strange. It looks like one of our folds is from a different distribution, we have to go back and make sure that our data is what we think it is.\n","\n","The worst scenario we can end up in is when we have considerable variation in our results, say 80, 44, 99, 60 and 87. Here it looks like that our algorithm or our data (or both) is no consistent, it could be that our algorithm is unable to learn, or our data is very complicated.\n"]},{"cell_type":"code","metadata":{"id":"pR3ds_7kCPko"},"source":["transform = transforms.Compose([transforms.ToTensor(), \n","                                        transforms.Normalize( (0.1307,), (0.3081,))])\n","\n","train_dataset = MNIST(root = './data', train = True, transform = transform, download=True)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p3MsWG5l6CHH"},"source":["from sklearn.model_selection import KFold\n","kfold = KFold(n_splits=5)\n","\n","def cross_validation(network, optim, crit, epochs, device, batch_size = 16, model_save = False):\n","    final_acc = []\n","    for fold, (train_index, valid_index) in enumerate(kfold.split(train_dataset.data, train_dataset.targets)):\n","        # reset weights to init values at each fold\n","        network.load_state_dict(torch.load('./weights_init'))\n","        print(list(network.parameters())[0][0])\n","        \n","        ### Dividing data into folds\n","        train_fold = torch.utils.data.Subset(train_dataset, train_index)\n","        valid_fold = torch.utils.data.Subset(train_dataset, valid_index)\n","\n","        train_loader_fold = DataLoader(train_fold, batch_size = batch_size, shuffle = False)\n","        valid_loader_fold = DataLoader(valid_fold, batch_size = batch_size, shuffle = False)\n","\n","        #print(len(train_loader_fold))\n","        #print(len(valid_loader_fold))\n","\n","        kwargs = {'optim': optim, 'crit': crit, \n","          'epochs': epochs, 'device': device, 'model_save': model_save}\n","        \n","        valid_acc = training(network, train_loader_fold, valid_loader_fold, **kwargs)\n","        final_acc.append(valid_acc.to('cpu'))\n","        #print(final_acc)\n","\n","        print('\\nFold number {} , Valid Accuracy: {}\\n'.format(fold + 1 , valid_acc))\n","    #print(final_acc)\n","    print('\\nFinal Accuracy Mean: {} , Final Accuracy Std: {}\\n'.format(np.array(final_acc).mean() , np.array(final_acc).std()))  \n","    return np.array(final_acc).mean(), np.array(final_acc).std()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"HvRbV5CRGdQ8"},"source":["model = MLP(dropout_rate = 0.2)\n","\n","device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n","model.to(device)\n","\n","optimizer = torch.optim.Adam(model.parameters(), lr = 0.00066) \n","criterion = nn.CrossEntropyLoss()\n","\n","kwargs = {'optim': optimizer, 'crit': criterion, \n","          'epochs': 3, 'device': device, 'batch_size': 32, 'model_save': False}\n","\n","cross_validation(model, **kwargs)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"o4KEtFhgobSR"},"source":["Cross validation is finished and now it is time to test the model on the test dataset"]},{"cell_type":"code","metadata":{"id":"bE30oneCl2Jp","colab":{"base_uri":"https://localhost:8080/","height":70},"executionInfo":{"status":"ok","timestamp":1599735287231,"user_tz":-120,"elapsed":1107,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"c7b9fa0c-e7f1-486c-9f5c-bf16eae4bea9"},"source":["test(model=model, device=device, test_loader=test_loader)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\n","Test set: Average loss: 0.0027, Accuracy: 2955/3000 (98.5%)\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"DJu6BGRjjJa-"},"source":["Since we are dealing with a multi-class classification (10 classes), let us check"]},{"cell_type":"code","metadata":{"id":"MLbuRknip0gf"},"source":["def confusion_matrix_data(model, device, test_loader):\n","    model.eval()\n","\n","    all_preds = np.array([])\n","    all_labels = np.array([])\n","    with torch.no_grad():\n","        for data, labels in test_loader:\n","            data, labels = data.to(device), labels.to(device)\n","            output = model(data)\n","            preds = output.argmax(dim=1, keepdim=True) \n","            # transfer to cpu and reshape preds from [[1],[2],[3]] to [1,2,3]\n","            preds = preds.to('cpu').detach().numpy().reshape(-1)\n","            labels = labels.to('cpu').detach().numpy()\n","\n","            all_preds = np.concatenate((all_preds, preds), axis=0)\n","            all_labels = np.concatenate((all_labels, labels), axis=0)\n","\n","    return all_preds, all_labels"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"x9eqkWGmcvJa","colab":{"base_uri":"https://localhost:8080/","height":194},"executionInfo":{"status":"ok","timestamp":1599752087482,"user_tz":-120,"elapsed":1129,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"0ca34127-7e2e-46d7-a267-351132f06640"},"source":["from sklearn import metrics\n","\n","preds, labels = confusion_matrix_data(model=lenet, device=device, test_loader=test_loader)\n","\n","cm = metrics.confusion_matrix(preds, labels)\n","\n","cm"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([[302,   0,   1,   0,   1,   0,   1,   0,   0,   1],\n","       [  0, 355,   0,   0,   0,   0,   2,   1,   0,   1],\n","       [  1,   0, 304,   1,   0,   0,   0,   3,   0,   0],\n","       [  0,   0,   0, 281,   0,   5,   0,   0,   2,   2],\n","       [  0,   0,   0,   0, 293,   0,   0,   0,   2,   2],\n","       [  0,   0,   0,   1,   0, 266,   1,   0,   0,   3],\n","       [  0,   0,   0,   0,   0,   1, 301,   0,   0,   0],\n","       [  1,   0,   3,   0,   0,   0,   0, 276,   2,   0],\n","       [  2,   1,   2,   1,   0,   2,   0,   0, 268,   3],\n","       [  0,   0,   0,   0,   0,   0,   0,   1,   0, 304]])"]},"metadata":{"tags":[]},"execution_count":88}]},{"cell_type":"code","metadata":{"id":"WpclKO10k4Uz","colab":{"base_uri":"https://localhost:8080/","height":596},"executionInfo":{"status":"ok","timestamp":1599752309772,"user_tz":-120,"elapsed":2567,"user":{"displayName":"denocris","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GjrN8dz6PznkXeNveLINUvYAypb09-x8tbG07aJQg=s64","userId":"14225405973604893991"}},"outputId":"b09bd774-2875-4e6b-c17b-51a73446a492"},"source":["## Plot multi-class metrics and confusion matrix \n","classes = ['0', '1', '2', '3', '4', '5', '6', '7', '8', '9']\n","print(metrics.classification_report(labels, preds))\n","\n","fig, ax = plt.subplots()\n","sns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, \n","            cbar=False)\n","ax.set(xlabel=\"Pred\", ylabel=\"True\", xticklabels=classes, \n","       yticklabels=classes, title=\"Confusion matrix\")\n","\n","plt.show()"],"execution_count":null,"outputs":[{"output_type":"stream","text":["              precision    recall  f1-score   support\n","\n","         0.0       0.99      0.99      0.99       306\n","         1.0       0.99      1.00      0.99       356\n","         2.0       0.98      0.98      0.98       310\n","         3.0       0.97      0.99      0.98       284\n","         4.0       0.99      1.00      0.99       294\n","         5.0       0.98      0.97      0.98       274\n","         6.0       1.00      0.99      0.99       305\n","         7.0       0.98      0.98      0.98       281\n","         8.0       0.96      0.98      0.97       274\n","         9.0       1.00      0.96      0.98       316\n","\n","    accuracy                           0.98      3000\n","   macro avg       0.98      0.98      0.98      3000\n","weighted avg       0.98      0.98      0.98      3000\n","\n"],"name":"stdout"},{"output_type":"display_data","data":{"image/png":"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\n","text/plain":["<Figure size 432x288 with 1 Axes>"]},"metadata":{"tags":[],"needs_background":"light"}}]},{"cell_type":"code","metadata":{"id":"y9JXxvRsqRfw"},"source":[""],"execution_count":null,"outputs":[]}]}