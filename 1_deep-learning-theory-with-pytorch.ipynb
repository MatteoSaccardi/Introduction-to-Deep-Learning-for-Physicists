{"cells":[{"cell_type":"markdown","metadata":{"id":"MfzNh72I8iEA"},"source":["# PyTorch Introduction"]},{"cell_type":"markdown","metadata":{"id":"N_fSAUpAZj9E"},"source":["### Cristiano De Nobili - My Contacts\n","For any questions or doubts you can find my contacts here:\n","\n","<p align=\"center\">\n","\n","[<img src=\"https://upload.wikimedia.org/wikipedia/commons/thumb/e/e7/Instagram_logo_2016.svg/2048px-Instagram_logo_2016.svg.png\" width=\"20\">](https://www.instagram.com/denocris/?hl=it)\n","[<img src=\"https://1.bp.blogspot.com/-Rwqcet_SHbk/T8_acMUmlmI/AAAAAAAAGgw/KD_fx__8Q4w/s1600/Twitter+bird.png\" width=\"30\">](https://twitter.com/denocris) \n","[<img src=\"https://loghi-famosi.com/wp-content/uploads/2020/04/Linkedin-Simbolo.png\" width=\"40\">](https://www.linkedin.com/in/cristiano-de-nobili/)     \n","\n","</p>\n","\n","or here (https://denocris.com).\n","\n","### Useful Links\n","\n","All notebooks can be found [here!](https://drive.google.com/drive/folders/1i3cNfzWZTNXfvkFVVIIDXjRDdSa9L9Dv?usp=sharing)\n","\n","Introductory slides [here!](https://www.canva.com/design/DAEa5hLfuWg/-L2EFFfZLVuiDkmg4KiKkQ/view?utm_content=DAEa5hLfuWg&utm_campaign=designshare&utm_medium=link&utm_source=publishsharelink)\n","\n","Collection of references: [here!](https://denocris.notion.site/Deep-Learning-References-0c5af2dc5c8d40baba19f1328d596fff)\n"]},{"cell_type":"markdown","metadata":{"id":"V4dADpOozq54"},"source":["### Notebook Outline\n","\n","* Why PyTorch?\n","* Tensors and basic operations in PyTorch;\n","* Automatic Differentiation;"]},{"cell_type":"markdown","metadata":{"id":"7YX9cX2IHGNg"},"source":["### Why PyTorch?\n"]},{"cell_type":"markdown","metadata":{"id":"kRD-GtvQFfnJ"},"source":["[PyTorch](https://pytorch.org/) is amongst the most widely used libraries for performing machine learning research and numerical computations. PyTorch is similar to NumPy, with the additional benefit that PyTorch allows you to perform your computations on CPUs and GPUs without any change to your code. PyTorch also makes it easy to distribute your computation across multiple devices or machines. One of the most important features of PyTorch is automatic differentiation. It allows computing the gradients of your functions analytically in an efficient manner which is crucial for training machine learning models using gradient descent method. \n","\n","So, we will now see these PyTorch useful classes (from PyTorch Tutorials):\n","\n","  -  ``torch.Tensor`` - A *multi-dimensional array* with support for autograd\n","     operations like ``backward()``. Also *holds the gradient* w.r.t. the\n","     tensor.\n","  -  ``nn.Module`` - Neural network module. *Convenient way of\n","     encapsulating parameters*, with helpers for moving them to GPU,\n","     exporting, loading, etc.\n","  -  ``nn.Parameter`` - A kind of Tensor, that is *automatically\n","     registered as a parameter when assigned as an attribute to a*\n","     ``Module``.\n","  -  ``autograd.Function`` - Implements *forward and backward definitions\n","     of an autograd operation*. Every ``Tensor`` operation creates at\n","     least a single ``Function`` node that connects to functions that\n","     created a ``Tensor`` and *encodes its history*."]},{"cell_type":"markdown","metadata":{"id":"vuvNyCyO18_V"},"source":["### Packages"]},{"cell_type":"code","execution_count":1,"metadata":{"executionInfo":{"elapsed":5889,"status":"ok","timestamp":1641917879863,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"-oQHt2dv1LHq"},"outputs":[],"source":["%matplotlib inline\n","\n","import random\n","import numpy as np\n","from matplotlib import pyplot as plt\n","\n","\n","import torch\n","import torch.nn as nn\n","from torchsummary import summary\n","from torch.utils.data import DataLoader, TensorDataset"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":279,"status":"ok","timestamp":1641917883121,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"utb5GxF91OPI"},"outputs":[],"source":["#device = torch.device('cpu')\n","device = torch.device('cuda') # Uncomment this to run on GPU"]},{"cell_type":"code","execution_count":4,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":374,"status":"ok","timestamp":1641917885346,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"TsjYQuD8rz8v","outputId":"301b97a6-85e1-4800-a70d-08b2e924f20e"},"outputs":[{"name":"stdout","output_type":"stream","text":["/bin/bash: nvidia-smi: comando non trovato\n"]}],"source":["!nvidia-smi"]},{"cell_type":"code","execution_count":3,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":525,"status":"ok","timestamp":1641917144983,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"9MeYPy3PTjqK","outputId":"b9fcdc83-8b23-4510-f3cf-af0844d6815f"},"outputs":[{"data":{"text/plain":["<torch._C.Generator at 0x11031fb10>"]},"execution_count":3,"metadata":{},"output_type":"execute_result"}],"source":["# set the seed for reproducibility: built-in python, numpy, and pytorch\n","seed = 172\n","random.seed(seed)\n","np.random.seed(seed)\n","torch.manual_seed(seed) # works for all devices (CPU and GPU)"]},{"cell_type":"markdown","metadata":{"id":"5UuTS05oKKD8"},"source":["### What is a tensor?"]},{"cell_type":"markdown","metadata":{"id":"PIm6ZeHwLDVa"},"source":["Like NumPy, PyTorch provides its own multidimensional array class, called `Tensor`. `Tensors` are essentially the equivalent of NumPy `ndarrays`. We can say that:\n","\n","* `Tensor` draws a lot of methods from NumPy\n","* `Tensor` has CUDA support\n"]},{"cell_type":"code","execution_count":4,"metadata":{"executionInfo":{"elapsed":345,"status":"ok","timestamp":1641917151889,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"mJDJ3RV7LEHj"},"outputs":[],"source":["# torch.tensor vs np.array\n","x = torch.tensor([[1.1,5,4],[3,2,1]])\n","y = np.array([[1.1,5,4],[3,2,1]])"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":289,"status":"ok","timestamp":1641838518506,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"IyDFsd-bLM2B","outputId":"f202c558-a012-46bd-fcb4-72cf54d3da5f"},"outputs":[{"data":{"text/plain":["(torch.float32, dtype('float64'))"]},"execution_count":5,"metadata":{},"output_type":"execute_result"}],"source":["x.dtype, y.dtype"]},{"cell_type":"markdown","metadata":{"id":"SmLfnpstLPcB"},"source":["`torch` already thinks with Machine Learning in mind as the Tensor is implicitly converted to dtype float32, while NumPy makes no such assumption. Since in deep learning memory is always a bottleneck. Especially when you are dealing with large volume of data and using a GPU with limited memory. I would recommend using `tf.float32` for a better speed with the price of a possible negligible loss of precision.\n","\n","For more info on Tensor data types, check [this page](https://pytorch.org/docs/stable/tensors.html).\n","\n","Note that if we put integers, torch.tensor infers the type"]},{"cell_type":"code","execution_count":6,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":370,"status":"ok","timestamp":1641917198204,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"TWE-VkMyRZss","outputId":"1caa0986-5d54-401f-df73-e2149b1f1084"},"outputs":[{"data":{"text/plain":["torch.int64"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["x = torch.tensor([[1,5,4],[3,2,1]])\n","x.dtype"]},{"cell_type":"markdown","metadata":{"id":"Y1aiBpmL50y1"},"source":["Tensors are simply multidimensional arrays\n","\n","* A scalar (a number) is a $0-dim$ array;\n","* a vector is a $1-dim$ array;\n","* a matrix is a $2-dim$ array;\n","* ...\n","\n","<center>  <img src=\"https://drive.google.com/uc?export=view&id=1BvK6ZGM7x_8x2LRfoVXvpaIE_mTycWqe\" width=\"650\" height=\"400\"> </center> \n","\n","\n","As in NumPy, we can call the `.shape` attribute to get the shape of the structures. Moreover, Tensors have also the `.size()` method which is analogous to `.shape`.\n","\n","\n"]},{"cell_type":"code","execution_count":7,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":726,"status":"ok","timestamp":1641917209343,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"EAPm5xKlOZwB","outputId":"51121f83-729e-446d-b712-aa9de2b9d6a9"},"outputs":[{"data":{"text/plain":["(torch.Size([2, 3]), torch.Size([2, 3]))"]},"execution_count":7,"metadata":{},"output_type":"execute_result"}],"source":["x.shape, x.size()"]},{"cell_type":"markdown","metadata":{"id":"mw7wbE0pPLoK"},"source":["Let's go step by step"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":323,"status":"ok","timestamp":1641917217035,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"1nNihCjoSYSB","outputId":"6625c05e-3bc5-4010-8928-f3baf658d079"},"outputs":[{"data":{"text/plain":["torch.Size([])"]},"execution_count":8,"metadata":{},"output_type":"execute_result"}],"source":["s = torch.tensor(3.14156)\n","s.size() "]},{"cell_type":"code","execution_count":9,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":284,"status":"ok","timestamp":1641917228692,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"83pRnQvAy8N6","outputId":"e66f9ee6-9ec4-468a-b278-8b5eba3237a6"},"outputs":[{"data":{"text/plain":["torch.Size([3])"]},"execution_count":9,"metadata":{},"output_type":"execute_result"}],"source":["v = torch.tensor([1,2,3])\n","v.size()"]},{"cell_type":"code","execution_count":10,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":368,"status":"ok","timestamp":1641917232144,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"t3rn3Ga8zQf9","outputId":"407e763a-9fda-4f56-8139-2361c1c2b102"},"outputs":[{"data":{"text/plain":["torch.Size([2, 3])"]},"execution_count":10,"metadata":{},"output_type":"execute_result"}],"source":["m = torch.tensor([[1,2,3], [3,4,5]])\n","m.size()"]},{"cell_type":"code","execution_count":11,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":17,"status":"ok","timestamp":1641917233858,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"xboKsaNq0iz7","outputId":"42575db5-6781-4453-f95f-a5940a253f68"},"outputs":[{"data":{"text/plain":["torch.Size([2, 2, 3])"]},"execution_count":11,"metadata":{},"output_type":"execute_result"}],"source":["t = torch.tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])\n","t.size()"]},{"cell_type":"code","execution_count":12,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":302,"status":"ok","timestamp":1641917237799,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"_RoM8DevMzqj","outputId":"167fa8b3-0af2-45ea-8d95-4095328219de"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(1)\n","tensor([1, 2, 3])\n","tensor([[1, 2],\n","        [3, 4]])\n","tensor([[[ 1,  2,  3],\n","         [ 4,  5,  6]],\n","\n","        [[ 7,  8,  9],\n","         [10, 11, 12]]])\n"]}],"source":["s = torch.tensor(1)\n","v = torch.tensor([1,2,3])\n","m = torch.tensor([[1,2], [3,4]])\n","t = torch.tensor([[[1,2,3], [4,5,6]], [[7,8,9], [10,11,12]]])\n","\n","print(s)\n","print(v)\n","print(m)\n","print(t)"]},{"cell_type":"markdown","metadata":{"id":"4-j26Q7hPzdg"},"source":["We can extract the size of the tensor by simply"]},{"cell_type":"code","execution_count":13,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":484,"status":"ok","timestamp":1641917273673,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"DfovTKBTNKEk","outputId":"13f58102-b241-4c2e-da11-9a1abfab8f6c"},"outputs":[{"data":{"text/plain":["(torch.Size([]), torch.Size([3]), torch.Size([2, 2]), torch.Size([2, 2, 3]))"]},"execution_count":13,"metadata":{},"output_type":"execute_result"}],"source":["s.size(), v.size(), m.size(), t.size()"]},{"cell_type":"code","execution_count":14,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":514,"status":"ok","timestamp":1641917309953,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"CmIGrICfgpU1","outputId":"ca317668-e79b-4cb0-e82b-600eadf05cbe"},"outputs":[{"name":"stdout","output_type":"stream","text":["torch.Size([2]) -> (axis=0, )\n","torch.Size([4, 2]) -> (axis=0, axis=1)\n","torch.Size([4, 2, 3]) -> (axis=0, axis=1, axis=2)\n"]}],"source":["t1 = torch.tensor([0,1])\n","print(t1.size(), '-> (axis=0, )')\n","\n","t2 = torch.tensor([[0,1],      [2,3],       [4,5],        [6,7]])\n","# from left to right, the outer and inner dimension\n","print(t2.size(), '-> (axis=0, axis=1)')\n","\n","t3 = torch.tensor([[[0,1,2],[3,4,5]],   [[6,7,8],[9,10,11]],    [[13,14,15],[16,17,18]],     [[19,20,21],[22,23,24]]])\n","# from left to right, the outer and inner dimension\n","print(t3.size(), '-> (axis=0, axis=1, axis=2)')"]},{"cell_type":"markdown","metadata":{"id":"0yKkxGU0P78b"},"source":["We can also generate a random vector of arbitrary size"]},{"cell_type":"code","execution_count":15,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1641917331986,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"ICFs-DmU33UR","outputId":"e931bdcc-ca6a-4fdd-f100-956bd611a43f"},"outputs":[{"data":{"text/plain":["tensor([[0.2469, 0.2080],\n","        [0.8997, 0.9753],\n","        [0.8461, 0.7945]])"]},"execution_count":15,"metadata":{},"output_type":"execute_result"}],"source":["d = torch.rand([3, 2])   # torch.randn([3, 3, 4]) #\n","d"]},{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":516,"status":"ok","timestamp":1641917527246,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"3VShwK4mQBif","outputId":"3b95793b-f269-4606-eb11-e70b5f93ef21"},"outputs":[{"data":{"text/plain":["tensor([[[0.9302, 0.0049, 0.4042, 0.1300],\n","         [0.2102, 0.9829, 0.0334, 0.4363],\n","         [0.3250, 0.3079, 0.2295, 0.1500]],\n","\n","        [[0.6592, 0.3632, 0.8722, 0.0489],\n","         [0.3148, 0.4832, 0.0953, 0.2106],\n","         [0.8527, 0.2870, 0.6727, 0.0772]],\n","\n","        [[0.1950, 0.7856, 0.5628, 0.3543],\n","         [0.9807, 0.0153, 0.7193, 0.6900],\n","         [0.6834, 0.6598, 0.5051, 0.7663]]])"]},"execution_count":16,"metadata":{},"output_type":"execute_result"}],"source":["d = torch.rand([3, 3, 4])   # torch.randn([3, 3, 4]) #\n","d"]},{"cell_type":"markdown","metadata":{"id":"Yyv_aYX3aFYY"},"source":["#### Slice of a Tensor"]},{"cell_type":"code","execution_count":20,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":747,"status":"ok","timestamp":1641917531604,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"LdIpTTHdcBpb","outputId":"c0e2ed3b-da65-425a-b0f0-05788900ff24"},"outputs":[{"data":{"text/plain":["[2, 3, 4, 5]"]},"execution_count":20,"metadata":{},"output_type":"execute_result"}],"source":["l = [0,1,2,3,4,5,6]\n","l[2:6]"]},{"cell_type":"code","execution_count":21,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1641917533105,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"ssRA7EgZbJer","outputId":"08bd97c7-fe67-4cd3-e09b-d8f9ee669e7b"},"outputs":[{"data":{"text/plain":["torch.Size([4, 2, 3])"]},"execution_count":21,"metadata":{},"output_type":"execute_result"}],"source":["t3 = torch.tensor([[[0,1,2],[3,4,5]],    [[6,7,8],[9,10,11]],    [[13,14,15],[16,17,18]],     [[19,20,21],[22,23,24]]])\n","t3.size()"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":198},"executionInfo":{"elapsed":649,"status":"error","timestamp":1641917856013,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"J1NzIs8ehegJ","outputId":"3bcda57b-a3d6-43e2-b9c9-e1e2a56aacb2"},"outputs":[{"data":{"text/plain":["tensor([[[ 3,  4]],\n","\n","        [[ 9, 10]]])"]},"execution_count":24,"metadata":{},"output_type":"execute_result"}],"source":["# Select some slices\n","# Ex: from axis-0 select the first 2 out of 4 elements, from axis-1 the last element, from axis-2 the first two.\n","t3[0:2, 1:2,  0:2]"]},{"cell_type":"markdown","metadata":{"id":"pd0KqxHqcjlj"},"source":["#### Operation with tensors"]},{"cell_type":"markdown","metadata":{"id":"-WpeUB-9QP08"},"source":["When you have more than one tensor you can perform algebric operations between them. Here matrix multiplication"]},{"cell_type":"code","execution_count":22,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1641840322716,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"5i2pi381QX_Z","outputId":"b629537b-02c7-497d-c261-588ac5e53b05"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[-3.4140, -1.1633, -1.1034,  0.2730],\n","        [ 2.4320,  2.8921,  2.0479,  2.6199],\n","        [-1.3882,  0.5998, -0.0675, -1.0088]]) Matrix multiplication: with '@'\n","tensor([[-3.4140, -1.1633, -1.1034,  0.2730],\n","        [ 2.4320,  2.8921,  2.0479,  2.6199],\n","        [-1.3882,  0.5998, -0.0675, -1.0088]]) Matrix multiplication: with torch.matmul\n","tensor([[-3.4140, -1.1633, -1.1034,  0.2730],\n","        [ 2.4320,  2.8921,  2.0479,  2.6199],\n","        [-1.3882,  0.5998, -0.0675, -1.0088]]) Matrix multiplication: with Tensor.matmul\n"]}],"source":["z1 = torch.randn([3, 5])  # random normal\n","z2 = torch.randn([5, 4])\n","\n","# first way\n","print(z1 @ z2, \"Matrix multiplication: with '@'\")\n","\n","# second way\n","print(torch.matmul(z1, z2), \"Matrix multiplication: with torch.matmul\")\n","\n","# third way\n","print(z1.matmul(z2), \"Matrix multiplication: with Tensor.matmul\")"]},{"cell_type":"markdown","metadata":{"id":"pLgIxmTscZwd"},"source":["Don't mistake `@` and `*` as the latter is the Hadamard (element-by-element) product!\n","\n"]},{"cell_type":"code","execution_count":23,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":439,"status":"ok","timestamp":1641840325646,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"003U7oWJch0l","outputId":"9b3390e5-85fb-442c-8a7f-85c47e82f481"},"outputs":[{"data":{"text/plain":["tensor([[1.0147e+00, 2.1133e-01, 8.3286e-01, 2.8867e-01, 4.8181e-02],\n","        [4.1150e-01, 2.0872e-02, 2.8725e+00, 1.1873e+00, 7.0016e-01],\n","        [6.6419e-04, 1.1683e+00, 1.4029e-02, 5.0814e-01, 1.3456e+00]])"]},"execution_count":23,"metadata":{},"output_type":"execute_result"}],"source":["z1*z1\n","#z1 * z2 # this gives an Exception\n"]},{"cell_type":"markdown","metadata":{"id":"aiXlfdE5eKry"},"source":["Generally, the \"regular\" arithmetic operators for Python act as element-wise operators in Tensors (as in ndarrays)\n"]},{"cell_type":"code","execution_count":24,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":397,"status":"ok","timestamp":1641840328634,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"dv0-OqIveNNL","outputId":"366b4900-b2a9-46ce-9a76-8d3512bdba77"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0., 0., 0., 0., 0.],\n","        [0., 0., 0., 0., 0.]]) z1 % z3 (remainder of integer division)\n","tensor([[1., 2., 3., 4., 5.],\n","        [1., 3., 5., 7., 9.]]) z3 // z1 (integer division)\n"]},{"name":"stderr","output_type":"stream","text":["/var/folders/3m/vfsrsg7x1c517wng2_5yjw2w0000gn/T/ipykernel_8725/690482680.py:5: UserWarning: __floordiv__ is deprecated, and its behavior will change in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values. To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor').\n","  print(z3 // z4, \"z3 // z1 (integer division)\")\n"]}],"source":["z3 = torch.Tensor([[2,4,6,8,10],[1,3,5,7,9]])\n","z4 = torch.Tensor([[2,2,2,2,2],[1,1,1,1,1]])\n","\n","print(z3 % z4, \"z1 % z3 (remainder of integer division)\")\n","print(z3 // z4, \"z3 // z1 (integer division)\") "]},{"cell_type":"markdown","metadata":{"id":"4CqgdzYshC54"},"source":["One important aspect to keep in mind is that a tensor has several dimensions, so we need to specify along what specific axis we want to perform our operation."]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":410,"status":"ok","timestamp":1641840337804,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"SzoOf8wVgiPU","outputId":"49605605-3e31-4b34-878d-93fcc0299f36"},"outputs":[{"name":"stdout","output_type":"stream","text":["Sum along axis 0:  tensor([2, 4])\n","Sum along axis 1:  tensor([1, 5])\n","Sum along axis -1:  tensor([1, 5])\n"]}],"source":["t4 = torch.tensor([[0,1], [2,3]])\n","\n","print('Sum along axis 0: ', torch.sum(t4, axis=0))\n","print('Sum along axis 1: ', torch.sum(t4, axis=1))\n","# axis -1 is the inner one\n","print('Sum along axis -1: ', torch.sum(t4, axis=-1))"]},{"cell_type":"markdown","metadata":{"id":"d6azzuJTaYyk"},"source":["Transposition"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":683,"status":"ok","timestamp":1641840344108,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"FPadmuzqaWtR","outputId":"82b3e850-383f-47ce-c46e-74573a213014"},"outputs":[{"name":"stdout","output_type":"stream","text":["z1\n","shape torch.Size([4, 5])\n","tensor([[0.2275, 0.1129, 0.2894, 0.1028, 0.1243],\n","        [0.8725, 0.2098, 0.9223, 0.4604, 0.9713],\n","        [0.1580, 0.9826, 0.4758, 0.8646, 0.0668],\n","        [0.3187, 0.4162, 0.7541, 0.1914, 0.2498]])\n","\n","z2\n","shape torch.Size([5, 4])\n","tensor([[0.2275, 0.8725, 0.1580, 0.3187],\n","        [0.1129, 0.2098, 0.9826, 0.4162],\n","        [0.2894, 0.9223, 0.4758, 0.7541],\n","        [0.1028, 0.4604, 0.8646, 0.1914],\n","        [0.1243, 0.9713, 0.0668, 0.2498]])\n"]}],"source":["z1 = torch.rand([4, 5])\n","print(\"z1\")\n","print(\"shape\", z1.shape)\n","print(z1)\n","\n","# transposition\n","z2 = z1.T\n","\n","print(\"\\nz2\")\n","print(\"shape\", z2.shape)\n","print(z2)"]},{"cell_type":"markdown","metadata":{"id":"WgglbGCCamfu"},"source":["Vector multiplication"]},{"cell_type":"code","execution_count":27,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1641840347887,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"isbCTG7gar6N","outputId":"13c691f3-9c15-450c-f71b-910eb78f2d2b"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([0.3625, 0.0263, 0.0519, 0.9678, 0.5962]) vec1\n","tensor([0.9451, 0.3874, 0.6686, 0.8693, 0.2951]) vec2\n","tensor(1.4048) I can use '@' even if the two vectors aren't conformable\n","tensor([[1.4048]])\n","tensor(1.4048)\n","tensor(1.4048)\n"]}],"source":["vec1 = torch.rand((5,)) # torch.tensor([1,2,3])\n","vec2 = torch.rand((5,)) # torch.tensor([4,5,6])\n","\n","print(vec1, \"vec1\")\n","print(vec2, \"vec2\")\n","\n","print(vec1 @ vec2, \"I can use '@' even if the two vectors aren't conformable\")\n","\n","print(vec1.unsqueeze(0) @ vec2.unsqueeze(-1))\n","\n","print(torch.matmul(vec1, vec2))\n","\n","print(torch.dot(vec1, vec2))"]},{"cell_type":"markdown","metadata":{"id":"mrh86ov7fepf"},"source":["#### More linear algebra"]},{"cell_type":"code","execution_count":31,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":307,"status":"ok","timestamp":1641840354874,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"dLIXl6I2f7l7","outputId":"2ebc1927-6670-4dcf-cf16-2ec522a601d3"},"outputs":[{"data":{"text/plain":["tensor(19.6214)"]},"execution_count":31,"metadata":{},"output_type":"execute_result"}],"source":["z3 = torch.Tensor([[2,4,6,8,10],[1,3,5,7,9]])\n","\n","z3_norm = z3.norm() # equivalent z3.norm(dim=1)\n","# np.sqrt(2**2+4**2+6**2+8**2+10**2 + 1**2+3**2+5**2+7**2+9**2)\n","z3_norm "]},{"cell_type":"code","execution_count":32,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1641840356568,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"2TIobuf7jKyA","outputId":"6587f713-e312-4fe2-c6a7-fb7fa4fd8bdc"},"outputs":[{"data":{"text/plain":["tensor([ 2.2361,  5.0000,  7.8102, 10.6301, 13.4536])"]},"execution_count":32,"metadata":{},"output_type":"execute_result"}],"source":["z3_norm = z3.norm(dim=0)\n","z3_norm"]},{"cell_type":"markdown","metadata":{"id":"YdbbJkWHixT_"},"source":["To \"disentangle\" the scalar from a Tensor use the .item() method.\n","\n"]},{"cell_type":"code","execution_count":33,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":5,"status":"ok","timestamp":1641840384979,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"OUxDAlxYiuwI","outputId":"23136f1b-bcb6-4a9c-a32e-37e7120af2b2"},"outputs":[{"data":{"text/plain":["2.2360680103302"]},"execution_count":33,"metadata":{},"output_type":"execute_result"}],"source":["z3_norm[0].item()\n"]},{"cell_type":"markdown","metadata":{"id":"J0ZNZ15TkuP3"},"source":["Conversion PyTorch <-> Numpy"]},{"cell_type":"code","execution_count":34,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":395,"status":"ok","timestamp":1641840395463,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"NNBDopEskus4","outputId":"ae1ce2ee-ac76-404c-c31b-105be8ea403f"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor([[0.1494, 0.1246, 0.3197, 0.6755, 0.6110],\n","        [0.8797, 0.3087, 0.3216, 0.2548, 0.4557],\n","        [0.6909, 0.7239, 0.1488, 0.6752, 0.1511]], dtype=torch.float64) y converted to torch.Tensor\n","[[0.6691805  0.7928066  0.5950892  0.6559825 ]\n"," [0.72723967 0.33440036 0.98243034 0.14510173]\n"," [0.7804562  0.7076425  0.44562387 0.5533622 ]\n"," [0.87600553 0.9286492  0.22740787 0.9207345 ]\n"," [0.25603104 0.73193926 0.64919305 0.23409432]\n"," [0.5695931  0.83621365 0.38729757 0.49458474]] x converted to numpy.ndarray\n"]}],"source":["y_numpy = np.random.rand(3,5)\n","y_torch = torch.from_numpy(y_numpy)\n","print(y_torch, \"y converted to torch.Tensor\")\n","\n","x = torch.rand(6,4)\n","x_numpy = x.numpy()\n","print(x_numpy, \"x converted to numpy.ndarray\")"]},{"cell_type":"markdown","metadata":{"id":"i87vR10Zad20"},"source":["#### Memory on RAM"]},{"cell_type":"markdown","metadata":{"id":"uvw0p8MTPXp6"},"source":["We can get the total number of elements in a Tensor via the `numel()` method\n","\n"]},{"cell_type":"code","execution_count":35,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":593,"status":"ok","timestamp":1641840404314,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"H6Et-O49PbD9","outputId":"28a125b3-faa4-4856-996d-491d363b5e3b"},"outputs":[{"data":{"text/plain":["24"]},"execution_count":35,"metadata":{},"output_type":"execute_result"}],"source":["t3 = torch.tensor([[[0.000001,1,2],[3,4,5]],   [[6,7,8],[9,10,11]],    [[13,14,15],[16,17,18]],     [[19,20,21],[22,23,24]]])\n","t3.numel()"]},{"cell_type":"code","execution_count":36,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1641840405558,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"H3eJFOYwPs87","outputId":"fdd3c52c-cf3c-445c-a7f4-608cf426aceb"},"outputs":[{"data":{"text/plain":["torch.float32"]},"execution_count":36,"metadata":{},"output_type":"execute_result"}],"source":["t3.dtype"]},{"cell_type":"markdown","metadata":{"id":"mGdM32z8SA_K"},"source":["`element_size()` returns the size in bytes of an individual element.\n","\n"]},{"cell_type":"code","execution_count":37,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1641840407403,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"Jw_J4BMcPn5T","outputId":"76ff4603-f318-493d-e75d-cdc7fcb1b85d"},"outputs":[{"data":{"text/plain":["4"]},"execution_count":37,"metadata":{},"output_type":"execute_result"}],"source":["t3.element_size()"]},{"cell_type":"markdown","metadata":{"id":"HJczRblNXV6U"},"source":["Hence, we can quickly calculate the size (byte) of the Tensor within the RAM"]},{"cell_type":"code","execution_count":38,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4,"status":"ok","timestamp":1641840410918,"user":{"displayName":"Cristiano De Nobili","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgZpMUz0UjFumTuheFxMf484NA45i0hBZh7Sahq3Q=s64","userId":"14225405973604893991"},"user_tz":-60},"id":"_RM2VgwJXTFg","outputId":"2c306adf-44dc-4f90-de0f-0ca2ec6d8703"},"outputs":[{"data":{"text/plain":["96"]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["t3.numel() * t3.element_size()"]},{"cell_type":"markdown","metadata":{"id":"hPa71oqwB2Qr"},"source":["### Automatic Differentiation"]},{"cell_type":"markdown","metadata":{"id":"JtSpyB-NPFvn"},"source":["One of the advantage of PyTorch over NumPy is its automatic differentiation which is very useful in optimization applications, such as neural network backpropagation. \n"]},{"cell_type":"markdown","metadata":{"id":"41irroHdPB6y"},"source":["#### Example 1 (simple)"]},{"cell_type":"markdown","metadata":{"id":"qPI3UlMIPJKx"},"source":["Suppose to have a composite function which is a chain of two functions: g(u(x)). To compute the derivative of g with respect to x we can use the chain rule: \n","\n","$$\\frac{dg}{dx} = \\frac{dg}{du} \\cdot \\frac{du}{dx}$$\n","\n","PyTorch can analytically compute the derivatives for us.\n","\n","To compute the derivatives in PyTorch first we create a tensor and set its `requires_grad = true`. We can use tensor operations to define our functions. Let us give the following example"]},{"cell_type":"code","execution_count":35,"metadata":{"executionInfo":{"elapsed":275,"status":"ok","timestamp":1641918780670,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"cHtiQO2cFNRc"},"outputs":[],"source":["x = torch.tensor(0.5, requires_grad=True)\n","\n","def u(x):\n","  return x * x\n","\n","def g(u):\n","  return -2*u"]},{"cell_type":"markdown","metadata":{"id":"ncOlMx8GFfyK"},"source":["Our composite function is $g(x) = -2 x^2$, whose derivative is $dg/dx = - 4 x$. At the point $x = 0.5$ its value is $-2$. Let us check this result"]},{"cell_type":"code","execution_count":40,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":336,"status":"ok","timestamp":1641918799809,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"VrpBOHtYGGiK","outputId":"e7aef065-6245-4941-dc64-1cf4e9aabf98"},"outputs":[{"name":"stdout","output_type":"stream","text":["tensor(-2.)\n"]}],"source":["dg_dx = torch.autograd.grad(g(u(x)), x)[0]\n","print(dg_dx) "]},{"cell_type":"markdown","metadata":{"id":"qejkRnZHGkpo"},"source":["#### Example 2"]},{"cell_type":"markdown","metadata":{"id":"45NkaQiDHQ86"},"source":["Assume that we have samples from a curve (say $f(x) = 3x^2 + 5$) and we want to estimate f(x) based on these samples. We define a parametric function $g(x, w) = w_0 x^2 + w_1 x + w_2$, which is a function of the input x and parameters w. The goal is then to find the parameters such that $g(x, w) ≈ f(x)$. \n","\n","Note that $g(x, w)$ can be written as:\n","$$\n","g(x, w)=\n","\\begin{pmatrix} \n","    x^2 & x & 1\n","\\end{pmatrix} \n","\\cdot\n","\\begin{pmatrix} \n","    w_0 \\\\ w_1 \\\\ w_2\n","\\end{pmatrix} \n","$$"]},{"cell_type":"code","execution_count":41,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":310,"status":"ok","timestamp":1641919270880,"user":{"displayName":"Matteo Saccardi","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"16713918133052906714"},"user_tz":-60},"id":"4lWG9bd1MDba","outputId":"af0f7d40-94f9-4c94-cb39-3fb6f17e3db0"},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/3m/vfsrsg7x1c517wng2_5yjw2w0000gn/T/ipykernel_37000/2726197260.py:4: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  w = torch.tensor(torch.randn([3, 1]), requires_grad=True)\n"]},{"name":"stdout","output_type":"stream","text":["[[ 3.0011978e+00]\n"," [-4.6622014e-04]\n"," [ 4.9313674e+00]]\n"]}],"source":["# Assuming we know that the desired function is a polynomial of 2nd degree, we\n","# allocate a vector of size 3 to hold the coefficients and initialize it with\n","# random noise.\n","w = torch.tensor(torch.randn([3, 1]), requires_grad=True)\n","\n","# We use the Adam optimizer with learning rate set to 0.1 to minimize the loss.\n","opt = torch.optim.Adam([w], 0.1)\n","\n","def model(x):\n","  g = torch.stack([ x*x, x , torch.ones_like(x)], 1)\n","  pred = torch.squeeze(g @ w, 1)\n","  return pred\n","\n","def compute_loss(y, pred):\n","    # The loss is defined to be the mean squared error distance between our\n","    # estimate of y and its true value. \n","    loss = torch.nn.functional.mse_loss(y, pred)\n","    return loss\n","\n","def data_generator():\n","  # Generate some training data (between -10 and 10) based on the true function\n","  x = torch.rand(100) * 20 - 10\n","  y = 3*x*x + 5  \n","  return x, y\n","\n","def train_step():\n","  x, y = data_generator()\n","\n","  pred = model(x) #g(x,w)\n","\n","  loss = compute_loss(y, pred)\n","\n","  # Don't worry! We will see in full details these three lines later.\n","  # For the moment, just know that they are computing derivatives.\n","  opt.zero_grad()\n","  loss.backward()\n","  opt.step()\n","\n","for _ in range(1000):\n","    train_step()\n","\n","print(w.detach().numpy())\n"]},{"cell_type":"markdown","metadata":{"id":"Htb4ies-OHD4"},"source":["##### Exercise\n","\n","Assume that we have samples from a curve (say $f(x) = 1.2x^4 + 4.5x^2 + 2x + 2$) and we want to estimate f(x) based on these samples. We define a parametric function $g(x, w)$, which is a function of the input x and parameters w. The goal is then to find the parameters such that $g(x, w) ≈ f(x)$. Collect and plot loss values during trainig. In addition, plot the value of w_0 during training."]},{"cell_type":"code","execution_count":45,"metadata":{},"outputs":[{"name":"stderr","output_type":"stream","text":["/var/folders/3m/vfsrsg7x1c517wng2_5yjw2w0000gn/T/ipykernel_37000/1425403375.py:1: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n","  w2 = torch.tensor(torch.randn([5, 1]), requires_grad=True)\n"]},{"name":"stdout","output_type":"stream","text":["Training step  0\n","Loss =  tensor(16669938., grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.0488], grad_fn=<SelectBackward0>)\n","\n","Training step  1\n","Loss =  tensor(15675835., grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.1489], grad_fn=<SelectBackward0>)\n","\n","Training step  2\n","Loss =  tensor(18541178., grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.2492], grad_fn=<SelectBackward0>)\n","\n","Training step  3\n","Loss =  tensor(16225729., grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.3497], grad_fn=<SelectBackward0>)\n","\n","Training step  4\n","Loss =  tensor(8629932., grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.4473], grad_fn=<SelectBackward0>)\n","\n","Training step  5\n","Loss =  tensor(5669343.5000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.5410], grad_fn=<SelectBackward0>)\n","\n","Training step  6\n","Loss =  tensor(7943597.5000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.6350], grad_fn=<SelectBackward0>)\n","\n","Training step  7\n","Loss =  tensor(3988407.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.7256], grad_fn=<SelectBackward0>)\n","\n","Training step  8\n","Loss =  tensor(3864343.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.8142], grad_fn=<SelectBackward0>)\n","\n","Training step  9\n","Loss =  tensor(1935111.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.8985], grad_fn=<SelectBackward0>)\n","\n","Training step  10\n","Loss =  tensor(1241517.5000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([0.9786], grad_fn=<SelectBackward0>)\n","\n","Training step  11\n","Loss =  tensor(894730.3750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.0545], grad_fn=<SelectBackward0>)\n","\n","Training step  12\n","Loss =  tensor(509266.8438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1262], grad_fn=<SelectBackward0>)\n","\n","Training step  13\n","Loss =  tensor(215718.7031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1932], grad_fn=<SelectBackward0>)\n","\n","Training step  14\n","Loss =  tensor(55107.8789, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2546], grad_fn=<SelectBackward0>)\n","\n","Training step  15\n","Loss =  tensor(19953.6582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3100], grad_fn=<SelectBackward0>)\n","\n","Training step  16\n","Loss =  tensor(72915.2422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3591], grad_fn=<SelectBackward0>)\n","\n","Training step  17\n","Loss =  tensor(168704.2031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4017], grad_fn=<SelectBackward0>)\n","\n","Training step  18\n","Loss =  tensor(279248.0938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4379], grad_fn=<SelectBackward0>)\n","\n","Training step  19\n","Loss =  tensor(584374.5000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4667], grad_fn=<SelectBackward0>)\n","\n","Training step  20\n","Loss =  tensor(700504.7500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4884], grad_fn=<SelectBackward0>)\n","\n","Training step  21\n","Loss =  tensor(655167.9375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5043], grad_fn=<SelectBackward0>)\n","\n","Training step  22\n","Loss =  tensor(925511.6250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5137], grad_fn=<SelectBackward0>)\n","\n","Training step  23\n","Loss =  tensor(753808.6250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5181], grad_fn=<SelectBackward0>)\n","\n","Training step  24\n","Loss =  tensor(1090242.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5164], grad_fn=<SelectBackward0>)\n","\n","Training step  25\n","Loss =  tensor(563740.8750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5117], grad_fn=<SelectBackward0>)\n","\n","Training step  26\n","Loss =  tensor(1013048.8125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.5019], grad_fn=<SelectBackward0>)\n","\n","Training step  27\n","Loss =  tensor(696203.0625, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4890], grad_fn=<SelectBackward0>)\n","\n","Training step  28\n","Loss =  tensor(731063.8125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4728], grad_fn=<SelectBackward0>)\n","\n","Training step  29\n","Loss =  tensor(541037.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4545], grad_fn=<SelectBackward0>)\n","\n","Training step  30\n","Loss =  tensor(415417.3750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4348], grad_fn=<SelectBackward0>)\n","\n","Training step  31\n","Loss =  tensor(371062.6250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.4139], grad_fn=<SelectBackward0>)\n","\n","Training step  32\n","Loss =  tensor(317256.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3919], grad_fn=<SelectBackward0>)\n","\n","Training step  33\n","Loss =  tensor(319706.7500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3686], grad_fn=<SelectBackward0>)\n","\n","Training step  34\n","Loss =  tensor(190095.6562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3450], grad_fn=<SelectBackward0>)\n","\n","Training step  35\n","Loss =  tensor(103103.5000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.3219], grad_fn=<SelectBackward0>)\n","\n","Training step  36\n","Loss =  tensor(84116.8594, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2992], grad_fn=<SelectBackward0>)\n","\n","Training step  37\n","Loss =  tensor(41745.0547, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2775], grad_fn=<SelectBackward0>)\n","\n","Training step  38\n","Loss =  tensor(14734.3428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2571], grad_fn=<SelectBackward0>)\n","\n","Training step  39\n","Loss =  tensor(6001.0757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  40\n","Loss =  tensor(4622.6401, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2214], grad_fn=<SelectBackward0>)\n","\n","Training step  41\n","Loss =  tensor(12634.8926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  42\n","Loss =  tensor(17478.3848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1934], grad_fn=<SelectBackward0>)\n","\n","Training step  43\n","Loss =  tensor(38600.1445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1827], grad_fn=<SelectBackward0>)\n","\n","Training step  44\n","Loss =  tensor(39576.8164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1739], grad_fn=<SelectBackward0>)\n","\n","Training step  45\n","Loss =  tensor(49439.8906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1671], grad_fn=<SelectBackward0>)\n","\n","Training step  46\n","Loss =  tensor(75589.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1627], grad_fn=<SelectBackward0>)\n","\n","Training step  47\n","Loss =  tensor(61603.1211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1599], grad_fn=<SelectBackward0>)\n","\n","Training step  48\n","Loss =  tensor(79167.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1590], grad_fn=<SelectBackward0>)\n","\n","Training step  49\n","Loss =  tensor(63426.0664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1596], grad_fn=<SelectBackward0>)\n","\n","Training step  50\n","Loss =  tensor(81647.5078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1619], grad_fn=<SelectBackward0>)\n","\n","Training step  51\n","Loss =  tensor(91294.0234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1661], grad_fn=<SelectBackward0>)\n","\n","Training step  52\n","Loss =  tensor(72639.3828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1716], grad_fn=<SelectBackward0>)\n","\n","Training step  53\n","Loss =  tensor(54777.3203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1780], grad_fn=<SelectBackward0>)\n","\n","Training step  54\n","Loss =  tensor(41799.3633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1851], grad_fn=<SelectBackward0>)\n","\n","Training step  55\n","Loss =  tensor(41287.7031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1928], grad_fn=<SelectBackward0>)\n","\n","Training step  56\n","Loss =  tensor(34094.3906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  57\n","Loss =  tensor(24528.4473, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  58\n","Loss =  tensor(13517.6289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  59\n","Loss =  tensor(8521.5059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2266], grad_fn=<SelectBackward0>)\n","\n","Training step  60\n","Loss =  tensor(4582.1274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2346], grad_fn=<SelectBackward0>)\n","\n","Training step  61\n","Loss =  tensor(2409.8496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2420], grad_fn=<SelectBackward0>)\n","\n","Training step  62\n","Loss =  tensor(1877.1746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2488], grad_fn=<SelectBackward0>)\n","\n","Training step  63\n","Loss =  tensor(2368.5046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2547], grad_fn=<SelectBackward0>)\n","\n","Training step  64\n","Loss =  tensor(3409.9287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2598], grad_fn=<SelectBackward0>)\n","\n","Training step  65\n","Loss =  tensor(4971.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2640], grad_fn=<SelectBackward0>)\n","\n","Training step  66\n","Loss =  tensor(6446.0654, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2673], grad_fn=<SelectBackward0>)\n","\n","Training step  67\n","Loss =  tensor(8469.3154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2697], grad_fn=<SelectBackward0>)\n","\n","Training step  68\n","Loss =  tensor(11373.2773, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2711], grad_fn=<SelectBackward0>)\n","\n","Training step  69\n","Loss =  tensor(9764.7861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2718], grad_fn=<SelectBackward0>)\n","\n","Training step  70\n","Loss =  tensor(12447.8438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2715], grad_fn=<SelectBackward0>)\n","\n","Training step  71\n","Loss =  tensor(15186.7012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2703], grad_fn=<SelectBackward0>)\n","\n","Training step  72\n","Loss =  tensor(11417.3799, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2684], grad_fn=<SelectBackward0>)\n","\n","Training step  73\n","Loss =  tensor(11720.3271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2659], grad_fn=<SelectBackward0>)\n","\n","Training step  74\n","Loss =  tensor(7111.8169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2631], grad_fn=<SelectBackward0>)\n","\n","Training step  75\n","Loss =  tensor(4929.6016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2602], grad_fn=<SelectBackward0>)\n","\n","Training step  76\n","Loss =  tensor(6487.5908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2570], grad_fn=<SelectBackward0>)\n","\n","Training step  77\n","Loss =  tensor(4759.0210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2536], grad_fn=<SelectBackward0>)\n","\n","Training step  78\n","Loss =  tensor(2490.4226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2504], grad_fn=<SelectBackward0>)\n","\n","Training step  79\n","Loss =  tensor(3477.8000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2470], grad_fn=<SelectBackward0>)\n","\n","Training step  80\n","Loss =  tensor(1658.2922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2439], grad_fn=<SelectBackward0>)\n","\n","Training step  81\n","Loss =  tensor(1842.6787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2410], grad_fn=<SelectBackward0>)\n","\n","Training step  82\n","Loss =  tensor(1914.5859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  83\n","Loss =  tensor(2021.4272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  84\n","Loss =  tensor(2200.8850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2342], grad_fn=<SelectBackward0>)\n","\n","Training step  85\n","Loss =  tensor(1975.7216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  86\n","Loss =  tensor(2318.5876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  87\n","Loss =  tensor(3722.5891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2308], grad_fn=<SelectBackward0>)\n","\n","Training step  88\n","Loss =  tensor(3387.0879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2306], grad_fn=<SelectBackward0>)\n","\n","Training step  89\n","Loss =  tensor(3266.1428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2307], grad_fn=<SelectBackward0>)\n","\n","Training step  90\n","Loss =  tensor(3889.7979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2313], grad_fn=<SelectBackward0>)\n","\n","Training step  91\n","Loss =  tensor(2954.4553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  92\n","Loss =  tensor(2812.9956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2332], grad_fn=<SelectBackward0>)\n","\n","Training step  93\n","Loss =  tensor(2380.7878, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2345], grad_fn=<SelectBackward0>)\n","\n","Training step  94\n","Loss =  tensor(2531.5469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2357], grad_fn=<SelectBackward0>)\n","\n","Training step  95\n","Loss =  tensor(2327.5447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2371], grad_fn=<SelectBackward0>)\n","\n","Training step  96\n","Loss =  tensor(2328.2043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2385], grad_fn=<SelectBackward0>)\n","\n","Training step  97\n","Loss =  tensor(1533.6229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2399], grad_fn=<SelectBackward0>)\n","\n","Training step  98\n","Loss =  tensor(2069.0488, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  99\n","Loss =  tensor(1827.7334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2425], grad_fn=<SelectBackward0>)\n","\n","Training step  100\n","Loss =  tensor(1977.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2436], grad_fn=<SelectBackward0>)\n","\n","Training step  101\n","Loss =  tensor(1919.0808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2445], grad_fn=<SelectBackward0>)\n","\n","Training step  102\n","Loss =  tensor(1933.7142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2450], grad_fn=<SelectBackward0>)\n","\n","Training step  103\n","Loss =  tensor(1763.6718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2455], grad_fn=<SelectBackward0>)\n","\n","Training step  104\n","Loss =  tensor(1561.3894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2458], grad_fn=<SelectBackward0>)\n","\n","Training step  105\n","Loss =  tensor(1920.2423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2459], grad_fn=<SelectBackward0>)\n","\n","Training step  106\n","Loss =  tensor(1962.5859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2458], grad_fn=<SelectBackward0>)\n","\n","Training step  107\n","Loss =  tensor(2172.1221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2456], grad_fn=<SelectBackward0>)\n","\n","Training step  108\n","Loss =  tensor(2030.6475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2454], grad_fn=<SelectBackward0>)\n","\n","Training step  109\n","Loss =  tensor(1890.3281, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2451], grad_fn=<SelectBackward0>)\n","\n","Training step  110\n","Loss =  tensor(1665.9731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2448], grad_fn=<SelectBackward0>)\n","\n","Training step  111\n","Loss =  tensor(2231.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2443], grad_fn=<SelectBackward0>)\n","\n","Training step  112\n","Loss =  tensor(1767.1340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2438], grad_fn=<SelectBackward0>)\n","\n","Training step  113\n","Loss =  tensor(1687.3755, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2433], grad_fn=<SelectBackward0>)\n","\n","Training step  114\n","Loss =  tensor(1885.9318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2428], grad_fn=<SelectBackward0>)\n","\n","Training step  115\n","Loss =  tensor(1554.4728, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2423], grad_fn=<SelectBackward0>)\n","\n","Training step  116\n","Loss =  tensor(1343.3916, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2419], grad_fn=<SelectBackward0>)\n","\n","Training step  117\n","Loss =  tensor(1790.0643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2415], grad_fn=<SelectBackward0>)\n","\n","Training step  118\n","Loss =  tensor(2044.4712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2414], grad_fn=<SelectBackward0>)\n","\n","Training step  119\n","Loss =  tensor(1688.4231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  120\n","Loss =  tensor(1448.1991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2411], grad_fn=<SelectBackward0>)\n","\n","Training step  121\n","Loss =  tensor(1830.2731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2411], grad_fn=<SelectBackward0>)\n","\n","Training step  122\n","Loss =  tensor(1960.4559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  123\n","Loss =  tensor(1929.4521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  124\n","Loss =  tensor(1668.0889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2415], grad_fn=<SelectBackward0>)\n","\n","Training step  125\n","Loss =  tensor(1482.3828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2416], grad_fn=<SelectBackward0>)\n","\n","Training step  126\n","Loss =  tensor(1632.1272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2415], grad_fn=<SelectBackward0>)\n","\n","Training step  127\n","Loss =  tensor(1691.4313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2416], grad_fn=<SelectBackward0>)\n","\n","Training step  128\n","Loss =  tensor(1719.5458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2417], grad_fn=<SelectBackward0>)\n","\n","Training step  129\n","Loss =  tensor(1933.9153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2419], grad_fn=<SelectBackward0>)\n","\n","Training step  130\n","Loss =  tensor(1645.6194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2420], grad_fn=<SelectBackward0>)\n","\n","Training step  131\n","Loss =  tensor(2099.0310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2420], grad_fn=<SelectBackward0>)\n","\n","Training step  132\n","Loss =  tensor(1644.6611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2418], grad_fn=<SelectBackward0>)\n","\n","Training step  133\n","Loss =  tensor(1759.8981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2417], grad_fn=<SelectBackward0>)\n","\n","Training step  134\n","Loss =  tensor(1816.4921, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2414], grad_fn=<SelectBackward0>)\n","\n","Training step  135\n","Loss =  tensor(1935.1620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  136\n","Loss =  tensor(1837.4020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2409], grad_fn=<SelectBackward0>)\n","\n","Training step  137\n","Loss =  tensor(1345.5350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  138\n","Loss =  tensor(1709.1353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2406], grad_fn=<SelectBackward0>)\n","\n","Training step  139\n","Loss =  tensor(1477.1072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  140\n","Loss =  tensor(1804.1636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  141\n","Loss =  tensor(1891.1913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2403], grad_fn=<SelectBackward0>)\n","\n","Training step  142\n","Loss =  tensor(1685.3208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  143\n","Loss =  tensor(1696.2584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  144\n","Loss =  tensor(1807.9569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  145\n","Loss =  tensor(1468.7557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2406], grad_fn=<SelectBackward0>)\n","\n","Training step  146\n","Loss =  tensor(2001.9750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  147\n","Loss =  tensor(1764.2422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2408], grad_fn=<SelectBackward0>)\n","\n","Training step  148\n","Loss =  tensor(1666.5557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2410], grad_fn=<SelectBackward0>)\n","\n","Training step  149\n","Loss =  tensor(1728.4822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2411], grad_fn=<SelectBackward0>)\n","\n","Training step  150\n","Loss =  tensor(1793.9816, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2411], grad_fn=<SelectBackward0>)\n","\n","Training step  151\n","Loss =  tensor(1259.7421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  152\n","Loss =  tensor(1699.4407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  153\n","Loss =  tensor(2028.2059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  154\n","Loss =  tensor(1738.8699, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  155\n","Loss =  tensor(1924.2611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2413], grad_fn=<SelectBackward0>)\n","\n","Training step  156\n","Loss =  tensor(1587.8807, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  157\n","Loss =  tensor(1663.9006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2412], grad_fn=<SelectBackward0>)\n","\n","Training step  158\n","Loss =  tensor(1590.4600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2410], grad_fn=<SelectBackward0>)\n","\n","Training step  159\n","Loss =  tensor(1925.4553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2410], grad_fn=<SelectBackward0>)\n","\n","Training step  160\n","Loss =  tensor(1791.5813, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2408], grad_fn=<SelectBackward0>)\n","\n","Training step  161\n","Loss =  tensor(1593.0433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  162\n","Loss =  tensor(1407.0709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  163\n","Loss =  tensor(1856.1089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  164\n","Loss =  tensor(1817.3696, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  165\n","Loss =  tensor(1632.8146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2403], grad_fn=<SelectBackward0>)\n","\n","Training step  166\n","Loss =  tensor(1718.6837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2402], grad_fn=<SelectBackward0>)\n","\n","Training step  167\n","Loss =  tensor(1650.7244, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2402], grad_fn=<SelectBackward0>)\n","\n","Training step  168\n","Loss =  tensor(1403.7400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2401], grad_fn=<SelectBackward0>)\n","\n","Training step  169\n","Loss =  tensor(1576.6356, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2399], grad_fn=<SelectBackward0>)\n","\n","Training step  170\n","Loss =  tensor(1702.7828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  171\n","Loss =  tensor(1494.1296, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  172\n","Loss =  tensor(1602.8810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  173\n","Loss =  tensor(1719.2831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2399], grad_fn=<SelectBackward0>)\n","\n","Training step  174\n","Loss =  tensor(1604.3057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2401], grad_fn=<SelectBackward0>)\n","\n","Training step  175\n","Loss =  tensor(1643.6750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2402], grad_fn=<SelectBackward0>)\n","\n","Training step  176\n","Loss =  tensor(1570.6802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  177\n","Loss =  tensor(1694.9243, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  178\n","Loss =  tensor(1914.6790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  179\n","Loss =  tensor(2004.3778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  180\n","Loss =  tensor(1509.4834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  181\n","Loss =  tensor(1446.8883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  182\n","Loss =  tensor(1600.7518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  183\n","Loss =  tensor(1811.2922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2403], grad_fn=<SelectBackward0>)\n","\n","Training step  184\n","Loss =  tensor(1538.3782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2403], grad_fn=<SelectBackward0>)\n","\n","Training step  185\n","Loss =  tensor(1738.0552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  186\n","Loss =  tensor(1880.4220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  187\n","Loss =  tensor(1182.6913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2406], grad_fn=<SelectBackward0>)\n","\n","Training step  188\n","Loss =  tensor(1795.0928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  189\n","Loss =  tensor(1500.6353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2406], grad_fn=<SelectBackward0>)\n","\n","Training step  190\n","Loss =  tensor(1634.7131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  191\n","Loss =  tensor(1891.3141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2401], grad_fn=<SelectBackward0>)\n","\n","Training step  192\n","Loss =  tensor(1815.4437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  193\n","Loss =  tensor(1748.5970, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  194\n","Loss =  tensor(1787.2720, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2393], grad_fn=<SelectBackward0>)\n","\n","Training step  195\n","Loss =  tensor(1542.0917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2391], grad_fn=<SelectBackward0>)\n","\n","Training step  196\n","Loss =  tensor(2020.9843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2390], grad_fn=<SelectBackward0>)\n","\n","Training step  197\n","Loss =  tensor(1777.4764, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2389], grad_fn=<SelectBackward0>)\n","\n","Training step  198\n","Loss =  tensor(1756.1060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2389], grad_fn=<SelectBackward0>)\n","\n","Training step  199\n","Loss =  tensor(1751.5835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2389], grad_fn=<SelectBackward0>)\n","\n","Training step  200\n","Loss =  tensor(1595.3844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2390], grad_fn=<SelectBackward0>)\n","\n","Training step  201\n","Loss =  tensor(1695.9137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2390], grad_fn=<SelectBackward0>)\n","\n","Training step  202\n","Loss =  tensor(1789.6300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2392], grad_fn=<SelectBackward0>)\n","\n","Training step  203\n","Loss =  tensor(1682.7997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2394], grad_fn=<SelectBackward0>)\n","\n","Training step  204\n","Loss =  tensor(1865.3575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  205\n","Loss =  tensor(1715.4856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  206\n","Loss =  tensor(1707.2289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2400], grad_fn=<SelectBackward0>)\n","\n","Training step  207\n","Loss =  tensor(1806.2074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2400], grad_fn=<SelectBackward0>)\n","\n","Training step  208\n","Loss =  tensor(1445.3684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2401], grad_fn=<SelectBackward0>)\n","\n","Training step  209\n","Loss =  tensor(1613.7954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2402], grad_fn=<SelectBackward0>)\n","\n","Training step  210\n","Loss =  tensor(1661.5319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2403], grad_fn=<SelectBackward0>)\n","\n","Training step  211\n","Loss =  tensor(1729.3689, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  212\n","Loss =  tensor(1579.3208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  213\n","Loss =  tensor(1730.7644, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  214\n","Loss =  tensor(1570.7161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  215\n","Loss =  tensor(1569.8695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2407], grad_fn=<SelectBackward0>)\n","\n","Training step  216\n","Loss =  tensor(1698.6516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2406], grad_fn=<SelectBackward0>)\n","\n","Training step  217\n","Loss =  tensor(1446.0100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2405], grad_fn=<SelectBackward0>)\n","\n","Training step  218\n","Loss =  tensor(1689.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2404], grad_fn=<SelectBackward0>)\n","\n","Training step  219\n","Loss =  tensor(1465.9928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2400], grad_fn=<SelectBackward0>)\n","\n","Training step  220\n","Loss =  tensor(1469.3037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2398], grad_fn=<SelectBackward0>)\n","\n","Training step  221\n","Loss =  tensor(1340.0725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  222\n","Loss =  tensor(1506.9554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2395], grad_fn=<SelectBackward0>)\n","\n","Training step  223\n","Loss =  tensor(1637.1796, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2394], grad_fn=<SelectBackward0>)\n","\n","Training step  224\n","Loss =  tensor(1574.9100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2393], grad_fn=<SelectBackward0>)\n","\n","Training step  225\n","Loss =  tensor(1891.9491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2392], grad_fn=<SelectBackward0>)\n","\n","Training step  226\n","Loss =  tensor(1480.5699, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2391], grad_fn=<SelectBackward0>)\n","\n","Training step  227\n","Loss =  tensor(1584.9354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2387], grad_fn=<SelectBackward0>)\n","\n","Training step  228\n","Loss =  tensor(1506.3313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  229\n","Loss =  tensor(1699.5936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2382], grad_fn=<SelectBackward0>)\n","\n","Training step  230\n","Loss =  tensor(1408.8829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  231\n","Loss =  tensor(1516.9000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2380], grad_fn=<SelectBackward0>)\n","\n","Training step  232\n","Loss =  tensor(1254.7588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2380], grad_fn=<SelectBackward0>)\n","\n","Training step  233\n","Loss =  tensor(1588.6481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  234\n","Loss =  tensor(1447.6439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2382], grad_fn=<SelectBackward0>)\n","\n","Training step  235\n","Loss =  tensor(1733.0608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2383], grad_fn=<SelectBackward0>)\n","\n","Training step  236\n","Loss =  tensor(1792.0542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  237\n","Loss =  tensor(1792.4421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  238\n","Loss =  tensor(1422.3978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2389], grad_fn=<SelectBackward0>)\n","\n","Training step  239\n","Loss =  tensor(1240.8898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2392], grad_fn=<SelectBackward0>)\n","\n","Training step  240\n","Loss =  tensor(1482.0698, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2395], grad_fn=<SelectBackward0>)\n","\n","Training step  241\n","Loss =  tensor(1632.1969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  242\n","Loss =  tensor(1566.4719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  243\n","Loss =  tensor(1472.7345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  244\n","Loss =  tensor(1492.2228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  245\n","Loss =  tensor(1353.8107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  246\n","Loss =  tensor(1348.4315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  247\n","Loss =  tensor(1432.4978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  248\n","Loss =  tensor(1296.0701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  249\n","Loss =  tensor(1263.5604, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  250\n","Loss =  tensor(1485.4303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  251\n","Loss =  tensor(1444.9326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2397], grad_fn=<SelectBackward0>)\n","\n","Training step  252\n","Loss =  tensor(1561.6145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2396], grad_fn=<SelectBackward0>)\n","\n","Training step  253\n","Loss =  tensor(1470.7662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2395], grad_fn=<SelectBackward0>)\n","\n","Training step  254\n","Loss =  tensor(1451.1254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2393], grad_fn=<SelectBackward0>)\n","\n","Training step  255\n","Loss =  tensor(1319.5110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2390], grad_fn=<SelectBackward0>)\n","\n","Training step  256\n","Loss =  tensor(1418.3319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  257\n","Loss =  tensor(1433.1338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2383], grad_fn=<SelectBackward0>)\n","\n","Training step  258\n","Loss =  tensor(1444.6261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2379], grad_fn=<SelectBackward0>)\n","\n","Training step  259\n","Loss =  tensor(1662.6382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2375], grad_fn=<SelectBackward0>)\n","\n","Training step  260\n","Loss =  tensor(1439.5518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2372], grad_fn=<SelectBackward0>)\n","\n","Training step  261\n","Loss =  tensor(1339.5403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2371], grad_fn=<SelectBackward0>)\n","\n","Training step  262\n","Loss =  tensor(1603.1346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2372], grad_fn=<SelectBackward0>)\n","\n","Training step  263\n","Loss =  tensor(1470.4684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2374], grad_fn=<SelectBackward0>)\n","\n","Training step  264\n","Loss =  tensor(1426.2549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2376], grad_fn=<SelectBackward0>)\n","\n","Training step  265\n","Loss =  tensor(1419.7164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2378], grad_fn=<SelectBackward0>)\n","\n","Training step  266\n","Loss =  tensor(1419.4937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2379], grad_fn=<SelectBackward0>)\n","\n","Training step  267\n","Loss =  tensor(1512.2195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2382], grad_fn=<SelectBackward0>)\n","\n","Training step  268\n","Loss =  tensor(1191.0137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2383], grad_fn=<SelectBackward0>)\n","\n","Training step  269\n","Loss =  tensor(1292.9430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  270\n","Loss =  tensor(1367.6282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  271\n","Loss =  tensor(1339.0607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2388], grad_fn=<SelectBackward0>)\n","\n","Training step  272\n","Loss =  tensor(1549.8185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2389], grad_fn=<SelectBackward0>)\n","\n","Training step  273\n","Loss =  tensor(1359.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2391], grad_fn=<SelectBackward0>)\n","\n","Training step  274\n","Loss =  tensor(1645.2653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2392], grad_fn=<SelectBackward0>)\n","\n","Training step  275\n","Loss =  tensor(1830.6000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2391], grad_fn=<SelectBackward0>)\n","\n","Training step  276\n","Loss =  tensor(1498.1725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2390], grad_fn=<SelectBackward0>)\n","\n","Training step  277\n","Loss =  tensor(1505.2405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2388], grad_fn=<SelectBackward0>)\n","\n","Training step  278\n","Loss =  tensor(1437.8041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  279\n","Loss =  tensor(1667.5546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2385], grad_fn=<SelectBackward0>)\n","\n","Training step  280\n","Loss =  tensor(1365.0942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2385], grad_fn=<SelectBackward0>)\n","\n","Training step  281\n","Loss =  tensor(1443.8042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  282\n","Loss =  tensor(1240.2506, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2382], grad_fn=<SelectBackward0>)\n","\n","Training step  283\n","Loss =  tensor(1432.4285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  284\n","Loss =  tensor(1398.3544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  285\n","Loss =  tensor(1585.8179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  286\n","Loss =  tensor(1392.4858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2380], grad_fn=<SelectBackward0>)\n","\n","Training step  287\n","Loss =  tensor(1583.2345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  288\n","Loss =  tensor(1320.0632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  289\n","Loss =  tensor(1579.5817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  290\n","Loss =  tensor(1440.8408, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  291\n","Loss =  tensor(1371.3655, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  292\n","Loss =  tensor(1253.9056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  293\n","Loss =  tensor(1446.0306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2383], grad_fn=<SelectBackward0>)\n","\n","Training step  294\n","Loss =  tensor(1277.4460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2385], grad_fn=<SelectBackward0>)\n","\n","Training step  295\n","Loss =  tensor(1544.3175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  296\n","Loss =  tensor(1367.1418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  297\n","Loss =  tensor(1758.9128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  298\n","Loss =  tensor(1409.4578, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  299\n","Loss =  tensor(1141.6862, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2386], grad_fn=<SelectBackward0>)\n","\n","Training step  300\n","Loss =  tensor(1372.6340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2385], grad_fn=<SelectBackward0>)\n","\n","Training step  301\n","Loss =  tensor(1341.4990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2384], grad_fn=<SelectBackward0>)\n","\n","Training step  302\n","Loss =  tensor(1761.2009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2381], grad_fn=<SelectBackward0>)\n","\n","Training step  303\n","Loss =  tensor(1255.8425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2378], grad_fn=<SelectBackward0>)\n","\n","Training step  304\n","Loss =  tensor(1308.5551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2375], grad_fn=<SelectBackward0>)\n","\n","Training step  305\n","Loss =  tensor(1290.5408, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2373], grad_fn=<SelectBackward0>)\n","\n","Training step  306\n","Loss =  tensor(1186.1453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2373], grad_fn=<SelectBackward0>)\n","\n","Training step  307\n","Loss =  tensor(1248.7590, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2373], grad_fn=<SelectBackward0>)\n","\n","Training step  308\n","Loss =  tensor(1594.1473, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2374], grad_fn=<SelectBackward0>)\n","\n","Training step  309\n","Loss =  tensor(1357.2489, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2376], grad_fn=<SelectBackward0>)\n","\n","Training step  310\n","Loss =  tensor(1427.1262, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2377], grad_fn=<SelectBackward0>)\n","\n","Training step  311\n","Loss =  tensor(1458.9159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2377], grad_fn=<SelectBackward0>)\n","\n","Training step  312\n","Loss =  tensor(1195.2858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2378], grad_fn=<SelectBackward0>)\n","\n","Training step  313\n","Loss =  tensor(1437.3778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2378], grad_fn=<SelectBackward0>)\n","\n","Training step  314\n","Loss =  tensor(1299.9530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2379], grad_fn=<SelectBackward0>)\n","\n","Training step  315\n","Loss =  tensor(1416.6747, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2379], grad_fn=<SelectBackward0>)\n","\n","Training step  316\n","Loss =  tensor(1385.1099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2378], grad_fn=<SelectBackward0>)\n","\n","Training step  317\n","Loss =  tensor(1382.9730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2376], grad_fn=<SelectBackward0>)\n","\n","Training step  318\n","Loss =  tensor(1348.2440, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2373], grad_fn=<SelectBackward0>)\n","\n","Training step  319\n","Loss =  tensor(1171.5406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2371], grad_fn=<SelectBackward0>)\n","\n","Training step  320\n","Loss =  tensor(1247.7053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2370], grad_fn=<SelectBackward0>)\n","\n","Training step  321\n","Loss =  tensor(1209.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2368], grad_fn=<SelectBackward0>)\n","\n","Training step  322\n","Loss =  tensor(1335.1161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  323\n","Loss =  tensor(1224.1749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2366], grad_fn=<SelectBackward0>)\n","\n","Training step  324\n","Loss =  tensor(1197.8156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2366], grad_fn=<SelectBackward0>)\n","\n","Training step  325\n","Loss =  tensor(1156.2495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  326\n","Loss =  tensor(1425.0735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  327\n","Loss =  tensor(1120.6022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  328\n","Loss =  tensor(1154.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2368], grad_fn=<SelectBackward0>)\n","\n","Training step  329\n","Loss =  tensor(1352.4307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2369], grad_fn=<SelectBackward0>)\n","\n","Training step  330\n","Loss =  tensor(1196.4615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2370], grad_fn=<SelectBackward0>)\n","\n","Training step  331\n","Loss =  tensor(1414.8129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2370], grad_fn=<SelectBackward0>)\n","\n","Training step  332\n","Loss =  tensor(1511.0889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2370], grad_fn=<SelectBackward0>)\n","\n","Training step  333\n","Loss =  tensor(1141.5618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2370], grad_fn=<SelectBackward0>)\n","\n","Training step  334\n","Loss =  tensor(1331.4144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2369], grad_fn=<SelectBackward0>)\n","\n","Training step  335\n","Loss =  tensor(1307.6278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  336\n","Loss =  tensor(1345.2410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  337\n","Loss =  tensor(1583.6700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  338\n","Loss =  tensor(1470.8445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  339\n","Loss =  tensor(1305.1547, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  340\n","Loss =  tensor(1061.6295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  341\n","Loss =  tensor(1080.9836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  342\n","Loss =  tensor(1314.1910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  343\n","Loss =  tensor(1349.6182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  344\n","Loss =  tensor(1147.2946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  345\n","Loss =  tensor(1348.8075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  346\n","Loss =  tensor(1112.8856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  347\n","Loss =  tensor(1168.7490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  348\n","Loss =  tensor(1584.9906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  349\n","Loss =  tensor(1089.8005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  350\n","Loss =  tensor(1239.9999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2366], grad_fn=<SelectBackward0>)\n","\n","Training step  351\n","Loss =  tensor(1345.4822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  352\n","Loss =  tensor(1123.5927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  353\n","Loss =  tensor(1188.8306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  354\n","Loss =  tensor(1110.0385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  355\n","Loss =  tensor(1116.4602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2362], grad_fn=<SelectBackward0>)\n","\n","Training step  356\n","Loss =  tensor(1137.1221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  357\n","Loss =  tensor(1207.2697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2360], grad_fn=<SelectBackward0>)\n","\n","Training step  358\n","Loss =  tensor(1466.4017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  359\n","Loss =  tensor(1136.5192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  360\n","Loss =  tensor(1290.4540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  361\n","Loss =  tensor(1469.6353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  362\n","Loss =  tensor(1295.9023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2360], grad_fn=<SelectBackward0>)\n","\n","Training step  363\n","Loss =  tensor(1267.9719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  364\n","Loss =  tensor(1256.0922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2362], grad_fn=<SelectBackward0>)\n","\n","Training step  365\n","Loss =  tensor(1479.0737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  366\n","Loss =  tensor(1414.0994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  367\n","Loss =  tensor(1310.4399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  368\n","Loss =  tensor(1391.2601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  369\n","Loss =  tensor(1210.8527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  370\n","Loss =  tensor(1062.1356, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  371\n","Loss =  tensor(1370.7933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2366], grad_fn=<SelectBackward0>)\n","\n","Training step  372\n","Loss =  tensor(1325.0958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  373\n","Loss =  tensor(1187.4407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2369], grad_fn=<SelectBackward0>)\n","\n","Training step  374\n","Loss =  tensor(1131.5969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2369], grad_fn=<SelectBackward0>)\n","\n","Training step  375\n","Loss =  tensor(1391.5696, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2368], grad_fn=<SelectBackward0>)\n","\n","Training step  376\n","Loss =  tensor(1115.7599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  377\n","Loss =  tensor(1287.6333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2367], grad_fn=<SelectBackward0>)\n","\n","Training step  378\n","Loss =  tensor(1363.7623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2366], grad_fn=<SelectBackward0>)\n","\n","Training step  379\n","Loss =  tensor(1114.8851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2365], grad_fn=<SelectBackward0>)\n","\n","Training step  380\n","Loss =  tensor(1150.8942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  381\n","Loss =  tensor(1364.9208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2364], grad_fn=<SelectBackward0>)\n","\n","Training step  382\n","Loss =  tensor(1176.2316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2363], grad_fn=<SelectBackward0>)\n","\n","Training step  383\n","Loss =  tensor(1287.1733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  384\n","Loss =  tensor(1338.5883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  385\n","Loss =  tensor(1172.2533, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  386\n","Loss =  tensor(1326.8202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  387\n","Loss =  tensor(1291.8511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  388\n","Loss =  tensor(1215.2961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  389\n","Loss =  tensor(1273.7699, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2360], grad_fn=<SelectBackward0>)\n","\n","Training step  390\n","Loss =  tensor(1254.6160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  391\n","Loss =  tensor(1184.4624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  392\n","Loss =  tensor(1148.7322, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2356], grad_fn=<SelectBackward0>)\n","\n","Training step  393\n","Loss =  tensor(992.6997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2356], grad_fn=<SelectBackward0>)\n","\n","Training step  394\n","Loss =  tensor(1113.4420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  395\n","Loss =  tensor(1118.5197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  396\n","Loss =  tensor(1103.6702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2355], grad_fn=<SelectBackward0>)\n","\n","Training step  397\n","Loss =  tensor(1279.8989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2356], grad_fn=<SelectBackward0>)\n","\n","Training step  398\n","Loss =  tensor(1141.8833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2357], grad_fn=<SelectBackward0>)\n","\n","Training step  399\n","Loss =  tensor(1188.3855, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2357], grad_fn=<SelectBackward0>)\n","\n","Training step  400\n","Loss =  tensor(1207.3893, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2357], grad_fn=<SelectBackward0>)\n","\n","Training step  401\n","Loss =  tensor(919.6578, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  402\n","Loss =  tensor(1025.1351, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  403\n","Loss =  tensor(1290.4022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  404\n","Loss =  tensor(1242.3080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  405\n","Loss =  tensor(1090.6210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  406\n","Loss =  tensor(1294.6299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  407\n","Loss =  tensor(1182.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2356], grad_fn=<SelectBackward0>)\n","\n","Training step  408\n","Loss =  tensor(1045.2147, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  409\n","Loss =  tensor(1300.9139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2351], grad_fn=<SelectBackward0>)\n","\n","Training step  410\n","Loss =  tensor(1393.7069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2350], grad_fn=<SelectBackward0>)\n","\n","Training step  411\n","Loss =  tensor(1328.8572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2347], grad_fn=<SelectBackward0>)\n","\n","Training step  412\n","Loss =  tensor(1005.5424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2345], grad_fn=<SelectBackward0>)\n","\n","Training step  413\n","Loss =  tensor(1132.7206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2345], grad_fn=<SelectBackward0>)\n","\n","Training step  414\n","Loss =  tensor(1213.2198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2344], grad_fn=<SelectBackward0>)\n","\n","Training step  415\n","Loss =  tensor(1040.4001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2343], grad_fn=<SelectBackward0>)\n","\n","Training step  416\n","Loss =  tensor(1171.9786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2342], grad_fn=<SelectBackward0>)\n","\n","Training step  417\n","Loss =  tensor(1089.7827, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2340], grad_fn=<SelectBackward0>)\n","\n","Training step  418\n","Loss =  tensor(1065.5687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2338], grad_fn=<SelectBackward0>)\n","\n","Training step  419\n","Loss =  tensor(1206.3436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2337], grad_fn=<SelectBackward0>)\n","\n","Training step  420\n","Loss =  tensor(1136.2666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2336], grad_fn=<SelectBackward0>)\n","\n","Training step  421\n","Loss =  tensor(1177.3749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2335], grad_fn=<SelectBackward0>)\n","\n","Training step  422\n","Loss =  tensor(1163.5796, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2334], grad_fn=<SelectBackward0>)\n","\n","Training step  423\n","Loss =  tensor(1368.1875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2336], grad_fn=<SelectBackward0>)\n","\n","Training step  424\n","Loss =  tensor(1122.7462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2338], grad_fn=<SelectBackward0>)\n","\n","Training step  425\n","Loss =  tensor(1278.8744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2340], grad_fn=<SelectBackward0>)\n","\n","Training step  426\n","Loss =  tensor(1226.7122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2344], grad_fn=<SelectBackward0>)\n","\n","Training step  427\n","Loss =  tensor(1148.4468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2348], grad_fn=<SelectBackward0>)\n","\n","Training step  428\n","Loss =  tensor(1217.6384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2351], grad_fn=<SelectBackward0>)\n","\n","Training step  429\n","Loss =  tensor(1147.9224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  430\n","Loss =  tensor(1278.4847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2357], grad_fn=<SelectBackward0>)\n","\n","Training step  431\n","Loss =  tensor(1209.0737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2359], grad_fn=<SelectBackward0>)\n","\n","Training step  432\n","Loss =  tensor(1031.8114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2360], grad_fn=<SelectBackward0>)\n","\n","Training step  433\n","Loss =  tensor(1170.3712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  434\n","Loss =  tensor(982.5971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2361], grad_fn=<SelectBackward0>)\n","\n","Training step  435\n","Loss =  tensor(1284.5299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2358], grad_fn=<SelectBackward0>)\n","\n","Training step  436\n","Loss =  tensor(1076.2395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2356], grad_fn=<SelectBackward0>)\n","\n","Training step  437\n","Loss =  tensor(1078.5815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2353], grad_fn=<SelectBackward0>)\n","\n","Training step  438\n","Loss =  tensor(1238.5095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2348], grad_fn=<SelectBackward0>)\n","\n","Training step  439\n","Loss =  tensor(1079.1512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2343], grad_fn=<SelectBackward0>)\n","\n","Training step  440\n","Loss =  tensor(1145.3079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2339], grad_fn=<SelectBackward0>)\n","\n","Training step  441\n","Loss =  tensor(1116.6890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2335], grad_fn=<SelectBackward0>)\n","\n","Training step  442\n","Loss =  tensor(1380.0922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2330], grad_fn=<SelectBackward0>)\n","\n","Training step  443\n","Loss =  tensor(1027.6364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2326], grad_fn=<SelectBackward0>)\n","\n","Training step  444\n","Loss =  tensor(1296.1445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2324], grad_fn=<SelectBackward0>)\n","\n","Training step  445\n","Loss =  tensor(1077.1876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  446\n","Loss =  tensor(1249.8992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  447\n","Loss =  tensor(1154.2233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2323], grad_fn=<SelectBackward0>)\n","\n","Training step  448\n","Loss =  tensor(1306.6639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2326], grad_fn=<SelectBackward0>)\n","\n","Training step  449\n","Loss =  tensor(1155.5790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2329], grad_fn=<SelectBackward0>)\n","\n","Training step  450\n","Loss =  tensor(1069.6598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2332], grad_fn=<SelectBackward0>)\n","\n","Training step  451\n","Loss =  tensor(1099.0863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2336], grad_fn=<SelectBackward0>)\n","\n","Training step  452\n","Loss =  tensor(1153.6223, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2340], grad_fn=<SelectBackward0>)\n","\n","Training step  453\n","Loss =  tensor(925.7034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2344], grad_fn=<SelectBackward0>)\n","\n","Training step  454\n","Loss =  tensor(1086.2960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2348], grad_fn=<SelectBackward0>)\n","\n","Training step  455\n","Loss =  tensor(897.2386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2352], grad_fn=<SelectBackward0>)\n","\n","Training step  456\n","Loss =  tensor(1008.0923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  457\n","Loss =  tensor(1028.5312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2355], grad_fn=<SelectBackward0>)\n","\n","Training step  458\n","Loss =  tensor(896.5904, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2355], grad_fn=<SelectBackward0>)\n","\n","Training step  459\n","Loss =  tensor(1045.9907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2353], grad_fn=<SelectBackward0>)\n","\n","Training step  460\n","Loss =  tensor(1169.1625, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2351], grad_fn=<SelectBackward0>)\n","\n","Training step  461\n","Loss =  tensor(1036.1388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2348], grad_fn=<SelectBackward0>)\n","\n","Training step  462\n","Loss =  tensor(937.9243, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2346], grad_fn=<SelectBackward0>)\n","\n","Training step  463\n","Loss =  tensor(1011.0675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2343], grad_fn=<SelectBackward0>)\n","\n","Training step  464\n","Loss =  tensor(1016.8990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2340], grad_fn=<SelectBackward0>)\n","\n","Training step  465\n","Loss =  tensor(1126.5149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2335], grad_fn=<SelectBackward0>)\n","\n","Training step  466\n","Loss =  tensor(1010.2020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2331], grad_fn=<SelectBackward0>)\n","\n","Training step  467\n","Loss =  tensor(1294.8839, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2325], grad_fn=<SelectBackward0>)\n","\n","Training step  468\n","Loss =  tensor(861.0969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2321], grad_fn=<SelectBackward0>)\n","\n","Training step  469\n","Loss =  tensor(1131.7416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  470\n","Loss =  tensor(1105.9432, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2316], grad_fn=<SelectBackward0>)\n","\n","Training step  471\n","Loss =  tensor(1103.7765, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2316], grad_fn=<SelectBackward0>)\n","\n","Training step  472\n","Loss =  tensor(1041.7660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  473\n","Loss =  tensor(1094.2148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  474\n","Loss =  tensor(1149.1042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2324], grad_fn=<SelectBackward0>)\n","\n","Training step  475\n","Loss =  tensor(1050.5927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2328], grad_fn=<SelectBackward0>)\n","\n","Training step  476\n","Loss =  tensor(958.1715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2331], grad_fn=<SelectBackward0>)\n","\n","Training step  477\n","Loss =  tensor(1211.6631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2332], grad_fn=<SelectBackward0>)\n","\n","Training step  478\n","Loss =  tensor(831.9161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2334], grad_fn=<SelectBackward0>)\n","\n","Training step  479\n","Loss =  tensor(1194.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2335], grad_fn=<SelectBackward0>)\n","\n","Training step  480\n","Loss =  tensor(892.7869, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2337], grad_fn=<SelectBackward0>)\n","\n","Training step  481\n","Loss =  tensor(949.9202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2337], grad_fn=<SelectBackward0>)\n","\n","Training step  482\n","Loss =  tensor(841.5260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2336], grad_fn=<SelectBackward0>)\n","\n","Training step  483\n","Loss =  tensor(859.8130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2334], grad_fn=<SelectBackward0>)\n","\n","Training step  484\n","Loss =  tensor(1163.6965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2330], grad_fn=<SelectBackward0>)\n","\n","Training step  485\n","Loss =  tensor(1138.4429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2328], grad_fn=<SelectBackward0>)\n","\n","Training step  486\n","Loss =  tensor(1043.8472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2325], grad_fn=<SelectBackward0>)\n","\n","Training step  487\n","Loss =  tensor(920.9758, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2324], grad_fn=<SelectBackward0>)\n","\n","Training step  488\n","Loss =  tensor(1066.4750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  489\n","Loss =  tensor(900.6523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2321], grad_fn=<SelectBackward0>)\n","\n","Training step  490\n","Loss =  tensor(1017.5187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2321], grad_fn=<SelectBackward0>)\n","\n","Training step  491\n","Loss =  tensor(1027.7535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2321], grad_fn=<SelectBackward0>)\n","\n","Training step  492\n","Loss =  tensor(1077.2969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2323], grad_fn=<SelectBackward0>)\n","\n","Training step  493\n","Loss =  tensor(978.1335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2325], grad_fn=<SelectBackward0>)\n","\n","Training step  494\n","Loss =  tensor(884.4359, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  495\n","Loss =  tensor(1062.5916, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2328], grad_fn=<SelectBackward0>)\n","\n","Training step  496\n","Loss =  tensor(1132.9242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2328], grad_fn=<SelectBackward0>)\n","\n","Training step  497\n","Loss =  tensor(1133.5894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2328], grad_fn=<SelectBackward0>)\n","\n","Training step  498\n","Loss =  tensor(882.9269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  499\n","Loss =  tensor(1056.5381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2325], grad_fn=<SelectBackward0>)\n","\n","Training step  500\n","Loss =  tensor(921.1545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  501\n","Loss =  tensor(1113.3600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  502\n","Loss =  tensor(1163.6997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2317], grad_fn=<SelectBackward0>)\n","\n","Training step  503\n","Loss =  tensor(901.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2316], grad_fn=<SelectBackward0>)\n","\n","Training step  504\n","Loss =  tensor(886.0682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  505\n","Loss =  tensor(1002.9132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  506\n","Loss =  tensor(935.8156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  507\n","Loss =  tensor(1111.0193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  508\n","Loss =  tensor(804.9163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  509\n","Loss =  tensor(1082.7983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  510\n","Loss =  tensor(1112.6028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2323], grad_fn=<SelectBackward0>)\n","\n","Training step  511\n","Loss =  tensor(1084.0242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2324], grad_fn=<SelectBackward0>)\n","\n","Training step  512\n","Loss =  tensor(821.4954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2326], grad_fn=<SelectBackward0>)\n","\n","Training step  513\n","Loss =  tensor(1072.4565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  514\n","Loss =  tensor(942.4241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  515\n","Loss =  tensor(914.3180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2327], grad_fn=<SelectBackward0>)\n","\n","Training step  516\n","Loss =  tensor(826.8987, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2326], grad_fn=<SelectBackward0>)\n","\n","Training step  517\n","Loss =  tensor(970.0801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2323], grad_fn=<SelectBackward0>)\n","\n","Training step  518\n","Loss =  tensor(1080.9711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2322], grad_fn=<SelectBackward0>)\n","\n","Training step  519\n","Loss =  tensor(770.7236, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2321], grad_fn=<SelectBackward0>)\n","\n","Training step  520\n","Loss =  tensor(1061.8910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  521\n","Loss =  tensor(1014.8947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  522\n","Loss =  tensor(928.3430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  523\n","Loss =  tensor(899.4783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  524\n","Loss =  tensor(933.4146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2316], grad_fn=<SelectBackward0>)\n","\n","Training step  525\n","Loss =  tensor(1096.7495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  526\n","Loss =  tensor(911.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2314], grad_fn=<SelectBackward0>)\n","\n","Training step  527\n","Loss =  tensor(1010.3267, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2313], grad_fn=<SelectBackward0>)\n","\n","Training step  528\n","Loss =  tensor(808.2544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2311], grad_fn=<SelectBackward0>)\n","\n","Training step  529\n","Loss =  tensor(860.7622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2309], grad_fn=<SelectBackward0>)\n","\n","Training step  530\n","Loss =  tensor(1145.6095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2308], grad_fn=<SelectBackward0>)\n","\n","Training step  531\n","Loss =  tensor(1097.8721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2306], grad_fn=<SelectBackward0>)\n","\n","Training step  532\n","Loss =  tensor(920.6470, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2305], grad_fn=<SelectBackward0>)\n","\n","Training step  533\n","Loss =  tensor(994.3200, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2305], grad_fn=<SelectBackward0>)\n","\n","Training step  534\n","Loss =  tensor(935.6334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2306], grad_fn=<SelectBackward0>)\n","\n","Training step  535\n","Loss =  tensor(1094.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2309], grad_fn=<SelectBackward0>)\n","\n","Training step  536\n","Loss =  tensor(868.3230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2312], grad_fn=<SelectBackward0>)\n","\n","Training step  537\n","Loss =  tensor(912.7214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2314], grad_fn=<SelectBackward0>)\n","\n","Training step  538\n","Loss =  tensor(872.2774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2316], grad_fn=<SelectBackward0>)\n","\n","Training step  539\n","Loss =  tensor(1092.9514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2319], grad_fn=<SelectBackward0>)\n","\n","Training step  540\n","Loss =  tensor(1025.6975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  541\n","Loss =  tensor(932.0823, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  542\n","Loss =  tensor(948.5706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  543\n","Loss =  tensor(879.8409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2320], grad_fn=<SelectBackward0>)\n","\n","Training step  544\n","Loss =  tensor(1058.5007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2318], grad_fn=<SelectBackward0>)\n","\n","Training step  545\n","Loss =  tensor(774.7442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2317], grad_fn=<SelectBackward0>)\n","\n","Training step  546\n","Loss =  tensor(951.4950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2315], grad_fn=<SelectBackward0>)\n","\n","Training step  547\n","Loss =  tensor(863.0882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2314], grad_fn=<SelectBackward0>)\n","\n","Training step  548\n","Loss =  tensor(752.5507, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2312], grad_fn=<SelectBackward0>)\n","\n","Training step  549\n","Loss =  tensor(895.6364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2310], grad_fn=<SelectBackward0>)\n","\n","Training step  550\n","Loss =  tensor(1002.7742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2306], grad_fn=<SelectBackward0>)\n","\n","Training step  551\n","Loss =  tensor(1011.2551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2303], grad_fn=<SelectBackward0>)\n","\n","Training step  552\n","Loss =  tensor(717.6115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2301], grad_fn=<SelectBackward0>)\n","\n","Training step  553\n","Loss =  tensor(919.6990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2298], grad_fn=<SelectBackward0>)\n","\n","Training step  554\n","Loss =  tensor(893.3790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  555\n","Loss =  tensor(920.6708, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2294], grad_fn=<SelectBackward0>)\n","\n","Training step  556\n","Loss =  tensor(814.4409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2293], grad_fn=<SelectBackward0>)\n","\n","Training step  557\n","Loss =  tensor(826.3801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2294], grad_fn=<SelectBackward0>)\n","\n","Training step  558\n","Loss =  tensor(924.1755, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  559\n","Loss =  tensor(1007.2394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2300], grad_fn=<SelectBackward0>)\n","\n","Training step  560\n","Loss =  tensor(904.6702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2302], grad_fn=<SelectBackward0>)\n","\n","Training step  561\n","Loss =  tensor(837.3812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2304], grad_fn=<SelectBackward0>)\n","\n","Training step  562\n","Loss =  tensor(917.2303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2307], grad_fn=<SelectBackward0>)\n","\n","Training step  563\n","Loss =  tensor(815.1144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2309], grad_fn=<SelectBackward0>)\n","\n","Training step  564\n","Loss =  tensor(845.6370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2310], grad_fn=<SelectBackward0>)\n","\n","Training step  565\n","Loss =  tensor(965.4628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2311], grad_fn=<SelectBackward0>)\n","\n","Training step  566\n","Loss =  tensor(830.3973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2310], grad_fn=<SelectBackward0>)\n","\n","Training step  567\n","Loss =  tensor(805.8929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2309], grad_fn=<SelectBackward0>)\n","\n","Training step  568\n","Loss =  tensor(799.7776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2308], grad_fn=<SelectBackward0>)\n","\n","Training step  569\n","Loss =  tensor(918.2073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2307], grad_fn=<SelectBackward0>)\n","\n","Training step  570\n","Loss =  tensor(938.2042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2305], grad_fn=<SelectBackward0>)\n","\n","Training step  571\n","Loss =  tensor(867.6744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2306], grad_fn=<SelectBackward0>)\n","\n","Training step  572\n","Loss =  tensor(818.1778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2305], grad_fn=<SelectBackward0>)\n","\n","Training step  573\n","Loss =  tensor(933.7159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2304], grad_fn=<SelectBackward0>)\n","\n","Training step  574\n","Loss =  tensor(875.4842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2303], grad_fn=<SelectBackward0>)\n","\n","Training step  575\n","Loss =  tensor(822.2054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2302], grad_fn=<SelectBackward0>)\n","\n","Training step  576\n","Loss =  tensor(846.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2301], grad_fn=<SelectBackward0>)\n","\n","Training step  577\n","Loss =  tensor(856.4525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2298], grad_fn=<SelectBackward0>)\n","\n","Training step  578\n","Loss =  tensor(971.3134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2293], grad_fn=<SelectBackward0>)\n","\n","Training step  579\n","Loss =  tensor(769.5455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2290], grad_fn=<SelectBackward0>)\n","\n","Training step  580\n","Loss =  tensor(954.4132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2287], grad_fn=<SelectBackward0>)\n","\n","Training step  581\n","Loss =  tensor(942.9984, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2286], grad_fn=<SelectBackward0>)\n","\n","Training step  582\n","Loss =  tensor(834.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2285], grad_fn=<SelectBackward0>)\n","\n","Training step  583\n","Loss =  tensor(738.3887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2286], grad_fn=<SelectBackward0>)\n","\n","Training step  584\n","Loss =  tensor(861.6396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2288], grad_fn=<SelectBackward0>)\n","\n","Training step  585\n","Loss =  tensor(852.0953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2291], grad_fn=<SelectBackward0>)\n","\n","Training step  586\n","Loss =  tensor(842.2242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2293], grad_fn=<SelectBackward0>)\n","\n","Training step  587\n","Loss =  tensor(938.1004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  588\n","Loss =  tensor(786.5869, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2298], grad_fn=<SelectBackward0>)\n","\n","Training step  589\n","Loss =  tensor(732.1682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2301], grad_fn=<SelectBackward0>)\n","\n","Training step  590\n","Loss =  tensor(1055.6965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2302], grad_fn=<SelectBackward0>)\n","\n","Training step  591\n","Loss =  tensor(834.1247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2300], grad_fn=<SelectBackward0>)\n","\n","Training step  592\n","Loss =  tensor(936.0580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  593\n","Loss =  tensor(745.9038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  594\n","Loss =  tensor(813.5129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  595\n","Loss =  tensor(680.3177, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  596\n","Loss =  tensor(770.7587, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  597\n","Loss =  tensor(791.4335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  598\n","Loss =  tensor(827.4011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  599\n","Loss =  tensor(788.7089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2299], grad_fn=<SelectBackward0>)\n","\n","Training step  600\n","Loss =  tensor(784.5935, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2300], grad_fn=<SelectBackward0>)\n","\n","Training step  601\n","Loss =  tensor(809.2571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2301], grad_fn=<SelectBackward0>)\n","\n","Training step  602\n","Loss =  tensor(724.7751, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2300], grad_fn=<SelectBackward0>)\n","\n","Training step  603\n","Loss =  tensor(890.2875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2298], grad_fn=<SelectBackward0>)\n","\n","Training step  604\n","Loss =  tensor(865.8823, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  605\n","Loss =  tensor(747.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  606\n","Loss =  tensor(853.3822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2294], grad_fn=<SelectBackward0>)\n","\n","Training step  607\n","Loss =  tensor(761.7572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2294], grad_fn=<SelectBackward0>)\n","\n","Training step  608\n","Loss =  tensor(770.4074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2292], grad_fn=<SelectBackward0>)\n","\n","Training step  609\n","Loss =  tensor(757.8957, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2290], grad_fn=<SelectBackward0>)\n","\n","Training step  610\n","Loss =  tensor(882.2293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2287], grad_fn=<SelectBackward0>)\n","\n","Training step  611\n","Loss =  tensor(861.2372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2285], grad_fn=<SelectBackward0>)\n","\n","Training step  612\n","Loss =  tensor(631.7905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2283], grad_fn=<SelectBackward0>)\n","\n","Training step  613\n","Loss =  tensor(682.1939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2281], grad_fn=<SelectBackward0>)\n","\n","Training step  614\n","Loss =  tensor(889.1717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2280], grad_fn=<SelectBackward0>)\n","\n","Training step  615\n","Loss =  tensor(877.5608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2280], grad_fn=<SelectBackward0>)\n","\n","Training step  616\n","Loss =  tensor(608.5862, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2281], grad_fn=<SelectBackward0>)\n","\n","Training step  617\n","Loss =  tensor(722.5499, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2283], grad_fn=<SelectBackward0>)\n","\n","Training step  618\n","Loss =  tensor(957.9484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2284], grad_fn=<SelectBackward0>)\n","\n","Training step  619\n","Loss =  tensor(775.0541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2285], grad_fn=<SelectBackward0>)\n","\n","Training step  620\n","Loss =  tensor(790.4818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2287], grad_fn=<SelectBackward0>)\n","\n","Training step  621\n","Loss =  tensor(755.8242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2290], grad_fn=<SelectBackward0>)\n","\n","Training step  622\n","Loss =  tensor(766.6786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2293], grad_fn=<SelectBackward0>)\n","\n","Training step  623\n","Loss =  tensor(753.2540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  624\n","Loss =  tensor(772.3168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  625\n","Loss =  tensor(761.0399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2296], grad_fn=<SelectBackward0>)\n","\n","Training step  626\n","Loss =  tensor(827.2541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2294], grad_fn=<SelectBackward0>)\n","\n","Training step  627\n","Loss =  tensor(906.1019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2290], grad_fn=<SelectBackward0>)\n","\n","Training step  628\n","Loss =  tensor(882.6245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2287], grad_fn=<SelectBackward0>)\n","\n","Training step  629\n","Loss =  tensor(751.3538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2283], grad_fn=<SelectBackward0>)\n","\n","Training step  630\n","Loss =  tensor(730.7867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2281], grad_fn=<SelectBackward0>)\n","\n","Training step  631\n","Loss =  tensor(654.6708, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2279], grad_fn=<SelectBackward0>)\n","\n","Training step  632\n","Loss =  tensor(757.3777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2276], grad_fn=<SelectBackward0>)\n","\n","Training step  633\n","Loss =  tensor(927.0977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2275], grad_fn=<SelectBackward0>)\n","\n","Training step  634\n","Loss =  tensor(783.1774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2276], grad_fn=<SelectBackward0>)\n","\n","Training step  635\n","Loss =  tensor(798.3508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2277], grad_fn=<SelectBackward0>)\n","\n","Training step  636\n","Loss =  tensor(755.3083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2279], grad_fn=<SelectBackward0>)\n","\n","Training step  637\n","Loss =  tensor(627.8730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2282], grad_fn=<SelectBackward0>)\n","\n","Training step  638\n","Loss =  tensor(710.0240, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2283], grad_fn=<SelectBackward0>)\n","\n","Training step  639\n","Loss =  tensor(762.0419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2286], grad_fn=<SelectBackward0>)\n","\n","Training step  640\n","Loss =  tensor(682.8236, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2287], grad_fn=<SelectBackward0>)\n","\n","Training step  641\n","Loss =  tensor(718.5890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2289], grad_fn=<SelectBackward0>)\n","\n","Training step  642\n","Loss =  tensor(720.5593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2292], grad_fn=<SelectBackward0>)\n","\n","Training step  643\n","Loss =  tensor(695.6294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  644\n","Loss =  tensor(620.4246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  645\n","Loss =  tensor(696.1661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2298], grad_fn=<SelectBackward0>)\n","\n","Training step  646\n","Loss =  tensor(801.6122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  647\n","Loss =  tensor(657.2286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2297], grad_fn=<SelectBackward0>)\n","\n","Training step  648\n","Loss =  tensor(686.0991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2295], grad_fn=<SelectBackward0>)\n","\n","Training step  649\n","Loss =  tensor(698.3395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2293], grad_fn=<SelectBackward0>)\n","\n","Training step  650\n","Loss =  tensor(771.3901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2289], grad_fn=<SelectBackward0>)\n","\n","Training step  651\n","Loss =  tensor(653.8331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2284], grad_fn=<SelectBackward0>)\n","\n","Training step  652\n","Loss =  tensor(789.9085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2278], grad_fn=<SelectBackward0>)\n","\n","Training step  653\n","Loss =  tensor(816.4482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  654\n","Loss =  tensor(673.5132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2271], grad_fn=<SelectBackward0>)\n","\n","Training step  655\n","Loss =  tensor(557.4967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  656\n","Loss =  tensor(763.7763, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  657\n","Loss =  tensor(748.2031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2266], grad_fn=<SelectBackward0>)\n","\n","Training step  658\n","Loss =  tensor(839.3406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2266], grad_fn=<SelectBackward0>)\n","\n","Training step  659\n","Loss =  tensor(702.4984, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  660\n","Loss =  tensor(788.5966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  661\n","Loss =  tensor(816.2031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2270], grad_fn=<SelectBackward0>)\n","\n","Training step  662\n","Loss =  tensor(758.9553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2270], grad_fn=<SelectBackward0>)\n","\n","Training step  663\n","Loss =  tensor(770.3292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2272], grad_fn=<SelectBackward0>)\n","\n","Training step  664\n","Loss =  tensor(765.6570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2272], grad_fn=<SelectBackward0>)\n","\n","Training step  665\n","Loss =  tensor(700.9222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2273], grad_fn=<SelectBackward0>)\n","\n","Training step  666\n","Loss =  tensor(638.9571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2273], grad_fn=<SelectBackward0>)\n","\n","Training step  667\n","Loss =  tensor(631.5673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2273], grad_fn=<SelectBackward0>)\n","\n","Training step  668\n","Loss =  tensor(808.2156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  669\n","Loss =  tensor(803.7261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  670\n","Loss =  tensor(595.7792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  671\n","Loss =  tensor(688.5769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  672\n","Loss =  tensor(746.9336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2273], grad_fn=<SelectBackward0>)\n","\n","Training step  673\n","Loss =  tensor(750.7539, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  674\n","Loss =  tensor(622.1486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  675\n","Loss =  tensor(737.2365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2273], grad_fn=<SelectBackward0>)\n","\n","Training step  676\n","Loss =  tensor(606.7200, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2272], grad_fn=<SelectBackward0>)\n","\n","Training step  677\n","Loss =  tensor(630.0839, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2268], grad_fn=<SelectBackward0>)\n","\n","Training step  678\n","Loss =  tensor(619.5080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  679\n","Loss =  tensor(800.3090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2264], grad_fn=<SelectBackward0>)\n","\n","Training step  680\n","Loss =  tensor(779.2712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2264], grad_fn=<SelectBackward0>)\n","\n","Training step  681\n","Loss =  tensor(610.9165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  682\n","Loss =  tensor(631.0176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2266], grad_fn=<SelectBackward0>)\n","\n","Training step  683\n","Loss =  tensor(656.7441, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2268], grad_fn=<SelectBackward0>)\n","\n","Training step  684\n","Loss =  tensor(724.7150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2271], grad_fn=<SelectBackward0>)\n","\n","Training step  685\n","Loss =  tensor(637.8953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  686\n","Loss =  tensor(564.3127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2277], grad_fn=<SelectBackward0>)\n","\n","Training step  687\n","Loss =  tensor(748.5519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2276], grad_fn=<SelectBackward0>)\n","\n","Training step  688\n","Loss =  tensor(749.8420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2275], grad_fn=<SelectBackward0>)\n","\n","Training step  689\n","Loss =  tensor(534.2289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2274], grad_fn=<SelectBackward0>)\n","\n","Training step  690\n","Loss =  tensor(619.2181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2272], grad_fn=<SelectBackward0>)\n","\n","Training step  691\n","Loss =  tensor(651.8449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  692\n","Loss =  tensor(503.2338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  693\n","Loss =  tensor(727.0914, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  694\n","Loss =  tensor(780.5089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2262], grad_fn=<SelectBackward0>)\n","\n","Training step  695\n","Loss =  tensor(714.4779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  696\n","Loss =  tensor(677.5402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2262], grad_fn=<SelectBackward0>)\n","\n","Training step  697\n","Loss =  tensor(595.2386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2264], grad_fn=<SelectBackward0>)\n","\n","Training step  698\n","Loss =  tensor(563.4691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  699\n","Loss =  tensor(693.5772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  700\n","Loss =  tensor(526.8713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2266], grad_fn=<SelectBackward0>)\n","\n","Training step  701\n","Loss =  tensor(580.9622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  702\n","Loss =  tensor(610.5333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  703\n","Loss =  tensor(756.2062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2271], grad_fn=<SelectBackward0>)\n","\n","Training step  704\n","Loss =  tensor(714.4565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2271], grad_fn=<SelectBackward0>)\n","\n","Training step  705\n","Loss =  tensor(716.4763, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  706\n","Loss =  tensor(667.0643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2269], grad_fn=<SelectBackward0>)\n","\n","Training step  707\n","Loss =  tensor(610.0712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  708\n","Loss =  tensor(670.1093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  709\n","Loss =  tensor(640.2834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2262], grad_fn=<SelectBackward0>)\n","\n","Training step  710\n","Loss =  tensor(623.1675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  711\n","Loss =  tensor(609.0795, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  712\n","Loss =  tensor(612.9647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  713\n","Loss =  tensor(551.1998, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  714\n","Loss =  tensor(566.0341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  715\n","Loss =  tensor(633.2328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2260], grad_fn=<SelectBackward0>)\n","\n","Training step  716\n","Loss =  tensor(624.5942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2259], grad_fn=<SelectBackward0>)\n","\n","Training step  717\n","Loss =  tensor(607.0820, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  718\n","Loss =  tensor(561.3354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  719\n","Loss =  tensor(520.5842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  720\n","Loss =  tensor(609.4326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2263], grad_fn=<SelectBackward0>)\n","\n","Training step  721\n","Loss =  tensor(668.1970, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  722\n","Loss =  tensor(591.5963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  723\n","Loss =  tensor(702.4166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2267], grad_fn=<SelectBackward0>)\n","\n","Training step  724\n","Loss =  tensor(723.7339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2265], grad_fn=<SelectBackward0>)\n","\n","Training step  725\n","Loss =  tensor(641.5215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2262], grad_fn=<SelectBackward0>)\n","\n","Training step  726\n","Loss =  tensor(625.6908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2260], grad_fn=<SelectBackward0>)\n","\n","Training step  727\n","Loss =  tensor(492.6404, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  728\n","Loss =  tensor(576.7625, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  729\n","Loss =  tensor(645.8245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  730\n","Loss =  tensor(630.6206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  731\n","Loss =  tensor(591.9515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2259], grad_fn=<SelectBackward0>)\n","\n","Training step  732\n","Loss =  tensor(689.4756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  733\n","Loss =  tensor(656.4686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  734\n","Loss =  tensor(662.5974, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  735\n","Loss =  tensor(511.5557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2258], grad_fn=<SelectBackward0>)\n","\n","Training step  736\n","Loss =  tensor(532.6860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  737\n","Loss =  tensor(547.8624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  738\n","Loss =  tensor(519.8579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2256], grad_fn=<SelectBackward0>)\n","\n","Training step  739\n","Loss =  tensor(579.9385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  740\n","Loss =  tensor(618.9141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  741\n","Loss =  tensor(674.0317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2255], grad_fn=<SelectBackward0>)\n","\n","Training step  742\n","Loss =  tensor(476.3635, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2254], grad_fn=<SelectBackward0>)\n","\n","Training step  743\n","Loss =  tensor(665.0555, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2253], grad_fn=<SelectBackward0>)\n","\n","Training step  744\n","Loss =  tensor(583.6549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2251], grad_fn=<SelectBackward0>)\n","\n","Training step  745\n","Loss =  tensor(570.8323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2249], grad_fn=<SelectBackward0>)\n","\n","Training step  746\n","Loss =  tensor(715.9813, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2247], grad_fn=<SelectBackward0>)\n","\n","Training step  747\n","Loss =  tensor(531.7491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2247], grad_fn=<SelectBackward0>)\n","\n","Training step  748\n","Loss =  tensor(540.8624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2248], grad_fn=<SelectBackward0>)\n","\n","Training step  749\n","Loss =  tensor(565.1501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2249], grad_fn=<SelectBackward0>)\n","\n","Training step  750\n","Loss =  tensor(527.3016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2250], grad_fn=<SelectBackward0>)\n","\n","Training step  751\n","Loss =  tensor(565.0962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2250], grad_fn=<SelectBackward0>)\n","\n","Training step  752\n","Loss =  tensor(534.2723, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2250], grad_fn=<SelectBackward0>)\n","\n","Training step  753\n","Loss =  tensor(494.2071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2251], grad_fn=<SelectBackward0>)\n","\n","Training step  754\n","Loss =  tensor(647.3932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2252], grad_fn=<SelectBackward0>)\n","\n","Training step  755\n","Loss =  tensor(569.1086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2254], grad_fn=<SelectBackward0>)\n","\n","Training step  756\n","Loss =  tensor(490.7308, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2256], grad_fn=<SelectBackward0>)\n","\n","Training step  757\n","Loss =  tensor(539.6833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2257], grad_fn=<SelectBackward0>)\n","\n","Training step  758\n","Loss =  tensor(543.7353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2256], grad_fn=<SelectBackward0>)\n","\n","Training step  759\n","Loss =  tensor(490.5923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2255], grad_fn=<SelectBackward0>)\n","\n","Training step  760\n","Loss =  tensor(707.8114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2255], grad_fn=<SelectBackward0>)\n","\n","Training step  761\n","Loss =  tensor(553.2609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2254], grad_fn=<SelectBackward0>)\n","\n","Training step  762\n","Loss =  tensor(565.8683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2252], grad_fn=<SelectBackward0>)\n","\n","Training step  763\n","Loss =  tensor(599.1064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2249], grad_fn=<SelectBackward0>)\n","\n","Training step  764\n","Loss =  tensor(593.2264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2246], grad_fn=<SelectBackward0>)\n","\n","Training step  765\n","Loss =  tensor(573.7484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2243], grad_fn=<SelectBackward0>)\n","\n","Training step  766\n","Loss =  tensor(614.4790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2242], grad_fn=<SelectBackward0>)\n","\n","Training step  767\n","Loss =  tensor(576.5425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  768\n","Loss =  tensor(559.5362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  769\n","Loss =  tensor(579.3834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  770\n","Loss =  tensor(513.6783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  771\n","Loss =  tensor(534.8643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  772\n","Loss =  tensor(547.9207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  773\n","Loss =  tensor(585.0647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  774\n","Loss =  tensor(589.4563, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  775\n","Loss =  tensor(590.3300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  776\n","Loss =  tensor(564.5720, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2238], grad_fn=<SelectBackward0>)\n","\n","Training step  777\n","Loss =  tensor(622.8188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2236], grad_fn=<SelectBackward0>)\n","\n","Training step  778\n","Loss =  tensor(474.9672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2236], grad_fn=<SelectBackward0>)\n","\n","Training step  779\n","Loss =  tensor(450.2135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2236], grad_fn=<SelectBackward0>)\n","\n","Training step  780\n","Loss =  tensor(620.2853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2238], grad_fn=<SelectBackward0>)\n","\n","Training step  781\n","Loss =  tensor(549.2340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  782\n","Loss =  tensor(470.2693, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2243], grad_fn=<SelectBackward0>)\n","\n","Training step  783\n","Loss =  tensor(518.2300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2244], grad_fn=<SelectBackward0>)\n","\n","Training step  784\n","Loss =  tensor(624.4729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2244], grad_fn=<SelectBackward0>)\n","\n","Training step  785\n","Loss =  tensor(615.3116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  786\n","Loss =  tensor(522.9544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  787\n","Loss =  tensor(547.5436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2236], grad_fn=<SelectBackward0>)\n","\n","Training step  788\n","Loss =  tensor(505.8050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2235], grad_fn=<SelectBackward0>)\n","\n","Training step  789\n","Loss =  tensor(520.1329, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2234], grad_fn=<SelectBackward0>)\n","\n","Training step  790\n","Loss =  tensor(515.1040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2235], grad_fn=<SelectBackward0>)\n","\n","Training step  791\n","Loss =  tensor(494.5931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2237], grad_fn=<SelectBackward0>)\n","\n","Training step  792\n","Loss =  tensor(503.7071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2238], grad_fn=<SelectBackward0>)\n","\n","Training step  793\n","Loss =  tensor(475.4353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  794\n","Loss =  tensor(519.0502, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2242], grad_fn=<SelectBackward0>)\n","\n","Training step  795\n","Loss =  tensor(480.9559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2244], grad_fn=<SelectBackward0>)\n","\n","Training step  796\n","Loss =  tensor(542.4573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2245], grad_fn=<SelectBackward0>)\n","\n","Training step  797\n","Loss =  tensor(536.8878, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2244], grad_fn=<SelectBackward0>)\n","\n","Training step  798\n","Loss =  tensor(494.1935, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2245], grad_fn=<SelectBackward0>)\n","\n","Training step  799\n","Loss =  tensor(470.4870, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2244], grad_fn=<SelectBackward0>)\n","\n","Training step  800\n","Loss =  tensor(528.4896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2243], grad_fn=<SelectBackward0>)\n","\n","Training step  801\n","Loss =  tensor(503.3483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  802\n","Loss =  tensor(547.5753, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  803\n","Loss =  tensor(437.6180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  804\n","Loss =  tensor(494.4645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  805\n","Loss =  tensor(502.3369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2241], grad_fn=<SelectBackward0>)\n","\n","Training step  806\n","Loss =  tensor(529.1476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2240], grad_fn=<SelectBackward0>)\n","\n","Training step  807\n","Loss =  tensor(470.0311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2238], grad_fn=<SelectBackward0>)\n","\n","Training step  808\n","Loss =  tensor(538.8080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2235], grad_fn=<SelectBackward0>)\n","\n","Training step  809\n","Loss =  tensor(463.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2234], grad_fn=<SelectBackward0>)\n","\n","Training step  810\n","Loss =  tensor(460.7250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  811\n","Loss =  tensor(399.0257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  812\n","Loss =  tensor(487.9130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  813\n","Loss =  tensor(460.8253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2230], grad_fn=<SelectBackward0>)\n","\n","Training step  814\n","Loss =  tensor(479.4089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  815\n","Loss =  tensor(520.2088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2230], grad_fn=<SelectBackward0>)\n","\n","Training step  816\n","Loss =  tensor(429.1500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2227], grad_fn=<SelectBackward0>)\n","\n","Training step  817\n","Loss =  tensor(477.5102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2228], grad_fn=<SelectBackward0>)\n","\n","Training step  818\n","Loss =  tensor(382.0623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2230], grad_fn=<SelectBackward0>)\n","\n","Training step  819\n","Loss =  tensor(429.2079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2230], grad_fn=<SelectBackward0>)\n","\n","Training step  820\n","Loss =  tensor(503.4781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  821\n","Loss =  tensor(453.3352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  822\n","Loss =  tensor(510.8247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2234], grad_fn=<SelectBackward0>)\n","\n","Training step  823\n","Loss =  tensor(492.3591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2234], grad_fn=<SelectBackward0>)\n","\n","Training step  824\n","Loss =  tensor(537.2672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2233], grad_fn=<SelectBackward0>)\n","\n","Training step  825\n","Loss =  tensor(476.2793, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  826\n","Loss =  tensor(510.2462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2229], grad_fn=<SelectBackward0>)\n","\n","Training step  827\n","Loss =  tensor(483.7723, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2227], grad_fn=<SelectBackward0>)\n","\n","Training step  828\n","Loss =  tensor(463.1324, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2225], grad_fn=<SelectBackward0>)\n","\n","Training step  829\n","Loss =  tensor(401.7068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2225], grad_fn=<SelectBackward0>)\n","\n","Training step  830\n","Loss =  tensor(398.3835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2225], grad_fn=<SelectBackward0>)\n","\n","Training step  831\n","Loss =  tensor(442.3492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2224], grad_fn=<SelectBackward0>)\n","\n","Training step  832\n","Loss =  tensor(437.6688, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2224], grad_fn=<SelectBackward0>)\n","\n","Training step  833\n","Loss =  tensor(514.3558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2225], grad_fn=<SelectBackward0>)\n","\n","Training step  834\n","Loss =  tensor(375.3132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2224], grad_fn=<SelectBackward0>)\n","\n","Training step  835\n","Loss =  tensor(478.3680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2224], grad_fn=<SelectBackward0>)\n","\n","Training step  836\n","Loss =  tensor(391.5272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2223], grad_fn=<SelectBackward0>)\n","\n","Training step  837\n","Loss =  tensor(400.0344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2222], grad_fn=<SelectBackward0>)\n","\n","Training step  838\n","Loss =  tensor(449.5853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2222], grad_fn=<SelectBackward0>)\n","\n","Training step  839\n","Loss =  tensor(474.9305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2221], grad_fn=<SelectBackward0>)\n","\n","Training step  840\n","Loss =  tensor(482.6632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2221], grad_fn=<SelectBackward0>)\n","\n","Training step  841\n","Loss =  tensor(452.2065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2222], grad_fn=<SelectBackward0>)\n","\n","Training step  842\n","Loss =  tensor(379.8220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2225], grad_fn=<SelectBackward0>)\n","\n","Training step  843\n","Loss =  tensor(472.0655, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2228], grad_fn=<SelectBackward0>)\n","\n","Training step  844\n","Loss =  tensor(463.2677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  845\n","Loss =  tensor(415.1981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  846\n","Loss =  tensor(445.5483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  847\n","Loss =  tensor(425.7529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  848\n","Loss =  tensor(459.0650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  849\n","Loss =  tensor(377.2359, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  850\n","Loss =  tensor(375.7889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2232], grad_fn=<SelectBackward0>)\n","\n","Training step  851\n","Loss =  tensor(340.1907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2231], grad_fn=<SelectBackward0>)\n","\n","Training step  852\n","Loss =  tensor(421.1386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2229], grad_fn=<SelectBackward0>)\n","\n","Training step  853\n","Loss =  tensor(352.7931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2228], grad_fn=<SelectBackward0>)\n","\n","Training step  854\n","Loss =  tensor(421.8698, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2226], grad_fn=<SelectBackward0>)\n","\n","Training step  855\n","Loss =  tensor(356.2043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2224], grad_fn=<SelectBackward0>)\n","\n","Training step  856\n","Loss =  tensor(413.9690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2220], grad_fn=<SelectBackward0>)\n","\n","Training step  857\n","Loss =  tensor(395.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2216], grad_fn=<SelectBackward0>)\n","\n","Training step  858\n","Loss =  tensor(471.8217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2213], grad_fn=<SelectBackward0>)\n","\n","Training step  859\n","Loss =  tensor(466.6254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  860\n","Loss =  tensor(457.9959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2210], grad_fn=<SelectBackward0>)\n","\n","Training step  861\n","Loss =  tensor(447.2000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2212], grad_fn=<SelectBackward0>)\n","\n","Training step  862\n","Loss =  tensor(321.2478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2213], grad_fn=<SelectBackward0>)\n","\n","Training step  863\n","Loss =  tensor(380.8513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2214], grad_fn=<SelectBackward0>)\n","\n","Training step  864\n","Loss =  tensor(402.1873, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2215], grad_fn=<SelectBackward0>)\n","\n","Training step  865\n","Loss =  tensor(474.2027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2215], grad_fn=<SelectBackward0>)\n","\n","Training step  866\n","Loss =  tensor(356.1182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2215], grad_fn=<SelectBackward0>)\n","\n","Training step  867\n","Loss =  tensor(420.0717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2216], grad_fn=<SelectBackward0>)\n","\n","Training step  868\n","Loss =  tensor(365.4000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2218], grad_fn=<SelectBackward0>)\n","\n","Training step  869\n","Loss =  tensor(448.2417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2220], grad_fn=<SelectBackward0>)\n","\n","Training step  870\n","Loss =  tensor(385.6906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2220], grad_fn=<SelectBackward0>)\n","\n","Training step  871\n","Loss =  tensor(448.9608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2218], grad_fn=<SelectBackward0>)\n","\n","Training step  872\n","Loss =  tensor(369.7943, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2216], grad_fn=<SelectBackward0>)\n","\n","Training step  873\n","Loss =  tensor(434.0887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2213], grad_fn=<SelectBackward0>)\n","\n","Training step  874\n","Loss =  tensor(451.1917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  875\n","Loss =  tensor(409.2597, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  876\n","Loss =  tensor(435.7917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2206], grad_fn=<SelectBackward0>)\n","\n","Training step  877\n","Loss =  tensor(409.9203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2206], grad_fn=<SelectBackward0>)\n","\n","Training step  878\n","Loss =  tensor(413.6319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2206], grad_fn=<SelectBackward0>)\n","\n","Training step  879\n","Loss =  tensor(417.3715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  880\n","Loss =  tensor(434.2993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2213], grad_fn=<SelectBackward0>)\n","\n","Training step  881\n","Loss =  tensor(419.5206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2216], grad_fn=<SelectBackward0>)\n","\n","Training step  882\n","Loss =  tensor(372.2105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2218], grad_fn=<SelectBackward0>)\n","\n","Training step  883\n","Loss =  tensor(425.6484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2219], grad_fn=<SelectBackward0>)\n","\n","Training step  884\n","Loss =  tensor(372.8849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2219], grad_fn=<SelectBackward0>)\n","\n","Training step  885\n","Loss =  tensor(380.2636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2217], grad_fn=<SelectBackward0>)\n","\n","Training step  886\n","Loss =  tensor(398.3934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2214], grad_fn=<SelectBackward0>)\n","\n","Training step  887\n","Loss =  tensor(406.2925, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2212], grad_fn=<SelectBackward0>)\n","\n","Training step  888\n","Loss =  tensor(303.4491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  889\n","Loss =  tensor(374.6364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  890\n","Loss =  tensor(367.0335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2210], grad_fn=<SelectBackward0>)\n","\n","Training step  891\n","Loss =  tensor(369.8986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2210], grad_fn=<SelectBackward0>)\n","\n","Training step  892\n","Loss =  tensor(399.5222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  893\n","Loss =  tensor(311.4571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2212], grad_fn=<SelectBackward0>)\n","\n","Training step  894\n","Loss =  tensor(350.4371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2212], grad_fn=<SelectBackward0>)\n","\n","Training step  895\n","Loss =  tensor(408.6278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2212], grad_fn=<SelectBackward0>)\n","\n","Training step  896\n","Loss =  tensor(465.5883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2210], grad_fn=<SelectBackward0>)\n","\n","Training step  897\n","Loss =  tensor(415.8661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2209], grad_fn=<SelectBackward0>)\n","\n","Training step  898\n","Loss =  tensor(415.0436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  899\n","Loss =  tensor(328.1067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2203], grad_fn=<SelectBackward0>)\n","\n","Training step  900\n","Loss =  tensor(371.4524, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  901\n","Loss =  tensor(369.3618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2197], grad_fn=<SelectBackward0>)\n","\n","Training step  902\n","Loss =  tensor(281.0292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2197], grad_fn=<SelectBackward0>)\n","\n","Training step  903\n","Loss =  tensor(408.9333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2198], grad_fn=<SelectBackward0>)\n","\n","Training step  904\n","Loss =  tensor(417.9462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  905\n","Loss =  tensor(416.6756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2203], grad_fn=<SelectBackward0>)\n","\n","Training step  906\n","Loss =  tensor(365.2373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  907\n","Loss =  tensor(403.2284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2211], grad_fn=<SelectBackward0>)\n","\n","Training step  908\n","Loss =  tensor(266.8932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2215], grad_fn=<SelectBackward0>)\n","\n","Training step  909\n","Loss =  tensor(423.0360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2219], grad_fn=<SelectBackward0>)\n","\n","Training step  910\n","Loss =  tensor(398.7775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2220], grad_fn=<SelectBackward0>)\n","\n","Training step  911\n","Loss =  tensor(363.8977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2220], grad_fn=<SelectBackward0>)\n","\n","Training step  912\n","Loss =  tensor(335.7059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2219], grad_fn=<SelectBackward0>)\n","\n","Training step  913\n","Loss =  tensor(319.4965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2216], grad_fn=<SelectBackward0>)\n","\n","Training step  914\n","Loss =  tensor(312.4884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2214], grad_fn=<SelectBackward0>)\n","\n","Training step  915\n","Loss =  tensor(415.1663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2209], grad_fn=<SelectBackward0>)\n","\n","Training step  916\n","Loss =  tensor(307.4552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2203], grad_fn=<SelectBackward0>)\n","\n","Training step  917\n","Loss =  tensor(364.4973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  918\n","Loss =  tensor(310.6381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2198], grad_fn=<SelectBackward0>)\n","\n","Training step  919\n","Loss =  tensor(321.9045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2196], grad_fn=<SelectBackward0>)\n","\n","Training step  920\n","Loss =  tensor(330.5573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2195], grad_fn=<SelectBackward0>)\n","\n","Training step  921\n","Loss =  tensor(376.0993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2195], grad_fn=<SelectBackward0>)\n","\n","Training step  922\n","Loss =  tensor(354.8911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2197], grad_fn=<SelectBackward0>)\n","\n","Training step  923\n","Loss =  tensor(321.0575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  924\n","Loss =  tensor(352.7968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2202], grad_fn=<SelectBackward0>)\n","\n","Training step  925\n","Loss =  tensor(265.4890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2205], grad_fn=<SelectBackward0>)\n","\n","Training step  926\n","Loss =  tensor(356.0120, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  927\n","Loss =  tensor(320.8529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2209], grad_fn=<SelectBackward0>)\n","\n","Training step  928\n","Loss =  tensor(356.6048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2209], grad_fn=<SelectBackward0>)\n","\n","Training step  929\n","Loss =  tensor(326.8156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  930\n","Loss =  tensor(366.1896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  931\n","Loss =  tensor(302.3938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  932\n","Loss =  tensor(299.6798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2206], grad_fn=<SelectBackward0>)\n","\n","Training step  933\n","Loss =  tensor(307.7690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  934\n","Loss =  tensor(331.3112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  935\n","Loss =  tensor(337.6552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2208], grad_fn=<SelectBackward0>)\n","\n","Training step  936\n","Loss =  tensor(411.2848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2207], grad_fn=<SelectBackward0>)\n","\n","Training step  937\n","Loss =  tensor(307.3872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2204], grad_fn=<SelectBackward0>)\n","\n","Training step  938\n","Loss =  tensor(281.0306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2202], grad_fn=<SelectBackward0>)\n","\n","Training step  939\n","Loss =  tensor(296.7116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  940\n","Loss =  tensor(345.2771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  941\n","Loss =  tensor(308.9842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  942\n","Loss =  tensor(339.4637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  943\n","Loss =  tensor(340.4323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  944\n","Loss =  tensor(382.3022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  945\n","Loss =  tensor(326.1880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  946\n","Loss =  tensor(372.4501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  947\n","Loss =  tensor(342.4434, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  948\n","Loss =  tensor(378.7050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  949\n","Loss =  tensor(339.3123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  950\n","Loss =  tensor(331.6530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  951\n","Loss =  tensor(307.0745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  952\n","Loss =  tensor(295.7637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  953\n","Loss =  tensor(310.6519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  954\n","Loss =  tensor(278.0251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  955\n","Loss =  tensor(330.9067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  956\n","Loss =  tensor(302.7025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  957\n","Loss =  tensor(272.8158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  958\n","Loss =  tensor(341.2011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2200], grad_fn=<SelectBackward0>)\n","\n","Training step  959\n","Loss =  tensor(375.7127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2198], grad_fn=<SelectBackward0>)\n","\n","Training step  960\n","Loss =  tensor(285.3144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2195], grad_fn=<SelectBackward0>)\n","\n","Training step  961\n","Loss =  tensor(310.5237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2193], grad_fn=<SelectBackward0>)\n","\n","Training step  962\n","Loss =  tensor(344.8534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2189], grad_fn=<SelectBackward0>)\n","\n","Training step  963\n","Loss =  tensor(340.4808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  964\n","Loss =  tensor(306.6719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  965\n","Loss =  tensor(321.3891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2189], grad_fn=<SelectBackward0>)\n","\n","Training step  966\n","Loss =  tensor(310.8259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2191], grad_fn=<SelectBackward0>)\n","\n","Training step  967\n","Loss =  tensor(318.2704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2192], grad_fn=<SelectBackward0>)\n","\n","Training step  968\n","Loss =  tensor(347.1344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2194], grad_fn=<SelectBackward0>)\n","\n","Training step  969\n","Loss =  tensor(277.3900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2197], grad_fn=<SelectBackward0>)\n","\n","Training step  970\n","Loss =  tensor(274.3936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2198], grad_fn=<SelectBackward0>)\n","\n","Training step  971\n","Loss =  tensor(337.7954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  972\n","Loss =  tensor(329.1314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  973\n","Loss =  tensor(318.6879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  974\n","Loss =  tensor(292.1531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2199], grad_fn=<SelectBackward0>)\n","\n","Training step  975\n","Loss =  tensor(345.8182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2198], grad_fn=<SelectBackward0>)\n","\n","Training step  976\n","Loss =  tensor(290.6039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2197], grad_fn=<SelectBackward0>)\n","\n","Training step  977\n","Loss =  tensor(361.9043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2194], grad_fn=<SelectBackward0>)\n","\n","Training step  978\n","Loss =  tensor(311.3287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2190], grad_fn=<SelectBackward0>)\n","\n","Training step  979\n","Loss =  tensor(271.8628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2187], grad_fn=<SelectBackward0>)\n","\n","Training step  980\n","Loss =  tensor(249.7131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2185], grad_fn=<SelectBackward0>)\n","\n","Training step  981\n","Loss =  tensor(316.6283, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  982\n","Loss =  tensor(265.1596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  983\n","Loss =  tensor(335.4569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2185], grad_fn=<SelectBackward0>)\n","\n","Training step  984\n","Loss =  tensor(281.6604, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2187], grad_fn=<SelectBackward0>)\n","\n","Training step  985\n","Loss =  tensor(295.1105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2190], grad_fn=<SelectBackward0>)\n","\n","Training step  986\n","Loss =  tensor(283.5881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2192], grad_fn=<SelectBackward0>)\n","\n","Training step  987\n","Loss =  tensor(291.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2193], grad_fn=<SelectBackward0>)\n","\n","Training step  988\n","Loss =  tensor(271.9046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2194], grad_fn=<SelectBackward0>)\n","\n","Training step  989\n","Loss =  tensor(306.1250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2193], grad_fn=<SelectBackward0>)\n","\n","Training step  990\n","Loss =  tensor(256.5370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2192], grad_fn=<SelectBackward0>)\n","\n","Training step  991\n","Loss =  tensor(272.1974, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2191], grad_fn=<SelectBackward0>)\n","\n","Training step  992\n","Loss =  tensor(333.4350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  993\n","Loss =  tensor(264.8121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2186], grad_fn=<SelectBackward0>)\n","\n","Training step  994\n","Loss =  tensor(247.4374, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  995\n","Loss =  tensor(277.1705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  996\n","Loss =  tensor(292.0105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  997\n","Loss =  tensor(307.3955, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  998\n","Loss =  tensor(252.2685, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  999\n","Loss =  tensor(293.2585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  1000\n","Loss =  tensor(280.1475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  1001\n","Loss =  tensor(272.4952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2186], grad_fn=<SelectBackward0>)\n","\n","Training step  1002\n","Loss =  tensor(311.3298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2187], grad_fn=<SelectBackward0>)\n","\n","Training step  1003\n","Loss =  tensor(335.3968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  1004\n","Loss =  tensor(288.8069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  1005\n","Loss =  tensor(275.4737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2187], grad_fn=<SelectBackward0>)\n","\n","Training step  1006\n","Loss =  tensor(273.2929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2186], grad_fn=<SelectBackward0>)\n","\n","Training step  1007\n","Loss =  tensor(256.8126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  1008\n","Loss =  tensor(215.2214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  1009\n","Loss =  tensor(287.9267, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2181], grad_fn=<SelectBackward0>)\n","\n","Training step  1010\n","Loss =  tensor(228.7188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2180], grad_fn=<SelectBackward0>)\n","\n","Training step  1011\n","Loss =  tensor(285.7659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2180], grad_fn=<SelectBackward0>)\n","\n","Training step  1012\n","Loss =  tensor(257.6033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  1013\n","Loss =  tensor(239.2115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  1014\n","Loss =  tensor(298.0849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  1015\n","Loss =  tensor(270.7411, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2185], grad_fn=<SelectBackward0>)\n","\n","Training step  1016\n","Loss =  tensor(298.2770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2185], grad_fn=<SelectBackward0>)\n","\n","Training step  1017\n","Loss =  tensor(264.8026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2184], grad_fn=<SelectBackward0>)\n","\n","Training step  1018\n","Loss =  tensor(244.9232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  1019\n","Loss =  tensor(251.4297, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  1020\n","Loss =  tensor(230.0725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2181], grad_fn=<SelectBackward0>)\n","\n","Training step  1021\n","Loss =  tensor(262.8772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2181], grad_fn=<SelectBackward0>)\n","\n","Training step  1022\n","Loss =  tensor(288.5570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2181], grad_fn=<SelectBackward0>)\n","\n","Training step  1023\n","Loss =  tensor(218.3994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  1024\n","Loss =  tensor(256.2834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  1025\n","Loss =  tensor(198.5018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  1026\n","Loss =  tensor(278.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2182], grad_fn=<SelectBackward0>)\n","\n","Training step  1027\n","Loss =  tensor(236.5620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2181], grad_fn=<SelectBackward0>)\n","\n","Training step  1028\n","Loss =  tensor(292.6729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2180], grad_fn=<SelectBackward0>)\n","\n","Training step  1029\n","Loss =  tensor(273.4204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1030\n","Loss =  tensor(262.7045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2176], grad_fn=<SelectBackward0>)\n","\n","Training step  1031\n","Loss =  tensor(265.1239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2175], grad_fn=<SelectBackward0>)\n","\n","Training step  1032\n","Loss =  tensor(209.1480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2176], grad_fn=<SelectBackward0>)\n","\n","Training step  1033\n","Loss =  tensor(215.4865, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2176], grad_fn=<SelectBackward0>)\n","\n","Training step  1034\n","Loss =  tensor(254.5296, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1035\n","Loss =  tensor(288.1526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2178], grad_fn=<SelectBackward0>)\n","\n","Training step  1036\n","Loss =  tensor(305.2094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2179], grad_fn=<SelectBackward0>)\n","\n","Training step  1037\n","Loss =  tensor(201.6365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2180], grad_fn=<SelectBackward0>)\n","\n","Training step  1038\n","Loss =  tensor(265.5536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2180], grad_fn=<SelectBackward0>)\n","\n","Training step  1039\n","Loss =  tensor(238.4452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2179], grad_fn=<SelectBackward0>)\n","\n","Training step  1040\n","Loss =  tensor(229.6761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2178], grad_fn=<SelectBackward0>)\n","\n","Training step  1041\n","Loss =  tensor(218.6221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1042\n","Loss =  tensor(268.9993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1043\n","Loss =  tensor(307.9589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2176], grad_fn=<SelectBackward0>)\n","\n","Training step  1044\n","Loss =  tensor(228.7779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1045\n","Loss =  tensor(265.5656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1046\n","Loss =  tensor(236.2779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2177], grad_fn=<SelectBackward0>)\n","\n","Training step  1047\n","Loss =  tensor(216.2745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2175], grad_fn=<SelectBackward0>)\n","\n","Training step  1048\n","Loss =  tensor(264.6610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2173], grad_fn=<SelectBackward0>)\n","\n","Training step  1049\n","Loss =  tensor(222.1355, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1050\n","Loss =  tensor(210.1740, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2170], grad_fn=<SelectBackward0>)\n","\n","Training step  1051\n","Loss =  tensor(237.6609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2170], grad_fn=<SelectBackward0>)\n","\n","Training step  1052\n","Loss =  tensor(268.8734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1053\n","Loss =  tensor(244.4130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1054\n","Loss =  tensor(240.9781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1055\n","Loss =  tensor(258.5721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1056\n","Loss =  tensor(219.4139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2170], grad_fn=<SelectBackward0>)\n","\n","Training step  1057\n","Loss =  tensor(223.4092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1058\n","Loss =  tensor(216.4895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1059\n","Loss =  tensor(225.4460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2173], grad_fn=<SelectBackward0>)\n","\n","Training step  1060\n","Loss =  tensor(197.7596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2175], grad_fn=<SelectBackward0>)\n","\n","Training step  1061\n","Loss =  tensor(246.3232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2175], grad_fn=<SelectBackward0>)\n","\n","Training step  1062\n","Loss =  tensor(244.7616, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2175], grad_fn=<SelectBackward0>)\n","\n","Training step  1063\n","Loss =  tensor(234.0519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2173], grad_fn=<SelectBackward0>)\n","\n","Training step  1064\n","Loss =  tensor(188.6619, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1065\n","Loss =  tensor(211.9889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2169], grad_fn=<SelectBackward0>)\n","\n","Training step  1066\n","Loss =  tensor(211.8765, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2166], grad_fn=<SelectBackward0>)\n","\n","Training step  1067\n","Loss =  tensor(221.0601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  1068\n","Loss =  tensor(216.6023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  1069\n","Loss =  tensor(225.1586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  1070\n","Loss =  tensor(205.2903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2166], grad_fn=<SelectBackward0>)\n","\n","Training step  1071\n","Loss =  tensor(211.8988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  1072\n","Loss =  tensor(219.7522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2169], grad_fn=<SelectBackward0>)\n","\n","Training step  1073\n","Loss =  tensor(228.7686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2170], grad_fn=<SelectBackward0>)\n","\n","Training step  1074\n","Loss =  tensor(226.8777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1075\n","Loss =  tensor(226.3098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1076\n","Loss =  tensor(210.7637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2174], grad_fn=<SelectBackward0>)\n","\n","Training step  1077\n","Loss =  tensor(224.4741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2174], grad_fn=<SelectBackward0>)\n","\n","Training step  1078\n","Loss =  tensor(222.2626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2173], grad_fn=<SelectBackward0>)\n","\n","Training step  1079\n","Loss =  tensor(206.5651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2172], grad_fn=<SelectBackward0>)\n","\n","Training step  1080\n","Loss =  tensor(236.6031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2171], grad_fn=<SelectBackward0>)\n","\n","Training step  1081\n","Loss =  tensor(254.5435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2169], grad_fn=<SelectBackward0>)\n","\n","Training step  1082\n","Loss =  tensor(203.8197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2168], grad_fn=<SelectBackward0>)\n","\n","Training step  1083\n","Loss =  tensor(213.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  1084\n","Loss =  tensor(242.4868, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  1085\n","Loss =  tensor(212.6314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2163], grad_fn=<SelectBackward0>)\n","\n","Training step  1086\n","Loss =  tensor(216.6341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2162], grad_fn=<SelectBackward0>)\n","\n","Training step  1087\n","Loss =  tensor(173.6875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1088\n","Loss =  tensor(183.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1089\n","Loss =  tensor(215.7023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1090\n","Loss =  tensor(237.8749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2162], grad_fn=<SelectBackward0>)\n","\n","Training step  1091\n","Loss =  tensor(250.7193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1092\n","Loss =  tensor(227.9442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1093\n","Loss =  tensor(187.0336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1094\n","Loss =  tensor(194.3405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1095\n","Loss =  tensor(212.3188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1096\n","Loss =  tensor(191.9014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1097\n","Loss =  tensor(187.2236, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  1098\n","Loss =  tensor(194.9867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2162], grad_fn=<SelectBackward0>)\n","\n","Training step  1099\n","Loss =  tensor(206.6704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2164], grad_fn=<SelectBackward0>)\n","\n","Training step  1100\n","Loss =  tensor(207.3161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2164], grad_fn=<SelectBackward0>)\n","\n","Training step  1101\n","Loss =  tensor(198.9750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  1102\n","Loss =  tensor(177.7413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  1103\n","Loss =  tensor(216.4826, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  1104\n","Loss =  tensor(183.1856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  1105\n","Loss =  tensor(193.7695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2164], grad_fn=<SelectBackward0>)\n","\n","Training step  1106\n","Loss =  tensor(198.2833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1107\n","Loss =  tensor(185.8989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2157], grad_fn=<SelectBackward0>)\n","\n","Training step  1108\n","Loss =  tensor(183.7627, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1109\n","Loss =  tensor(221.8001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1110\n","Loss =  tensor(198.6005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1111\n","Loss =  tensor(205.3407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1112\n","Loss =  tensor(231.6319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1113\n","Loss =  tensor(206.8168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2157], grad_fn=<SelectBackward0>)\n","\n","Training step  1114\n","Loss =  tensor(187.8627, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2157], grad_fn=<SelectBackward0>)\n","\n","Training step  1115\n","Loss =  tensor(170.4504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2158], grad_fn=<SelectBackward0>)\n","\n","Training step  1116\n","Loss =  tensor(179.6983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2158], grad_fn=<SelectBackward0>)\n","\n","Training step  1117\n","Loss =  tensor(252.1626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1118\n","Loss =  tensor(196.6484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1119\n","Loss =  tensor(175.4894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1120\n","Loss =  tensor(178.7472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1121\n","Loss =  tensor(181.8621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2158], grad_fn=<SelectBackward0>)\n","\n","Training step  1122\n","Loss =  tensor(208.6628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1123\n","Loss =  tensor(232.8934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1124\n","Loss =  tensor(164.7791, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1125\n","Loss =  tensor(184.3726, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1126\n","Loss =  tensor(213.8768, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1127\n","Loss =  tensor(175.4743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2160], grad_fn=<SelectBackward0>)\n","\n","Training step  1128\n","Loss =  tensor(198.8902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2159], grad_fn=<SelectBackward0>)\n","\n","Training step  1129\n","Loss =  tensor(179.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2157], grad_fn=<SelectBackward0>)\n","\n","Training step  1130\n","Loss =  tensor(202.9309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1131\n","Loss =  tensor(145.1800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2154], grad_fn=<SelectBackward0>)\n","\n","Training step  1132\n","Loss =  tensor(171.9572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1133\n","Loss =  tensor(216.6388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1134\n","Loss =  tensor(168.9095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2151], grad_fn=<SelectBackward0>)\n","\n","Training step  1135\n","Loss =  tensor(165.8815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1136\n","Loss =  tensor(178.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1137\n","Loss =  tensor(198.9065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2154], grad_fn=<SelectBackward0>)\n","\n","Training step  1138\n","Loss =  tensor(200.4009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2154], grad_fn=<SelectBackward0>)\n","\n","Training step  1139\n","Loss =  tensor(159.5968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2154], grad_fn=<SelectBackward0>)\n","\n","Training step  1140\n","Loss =  tensor(176.6667, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1141\n","Loss =  tensor(191.5137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2156], grad_fn=<SelectBackward0>)\n","\n","Training step  1142\n","Loss =  tensor(188.5781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2156], grad_fn=<SelectBackward0>)\n","\n","Training step  1143\n","Loss =  tensor(170.6232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1144\n","Loss =  tensor(158.2311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2155], grad_fn=<SelectBackward0>)\n","\n","Training step  1145\n","Loss =  tensor(169.5945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1146\n","Loss =  tensor(196.6384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1147\n","Loss =  tensor(154.9596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1148\n","Loss =  tensor(160.8942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1149\n","Loss =  tensor(173.8800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1150\n","Loss =  tensor(192.7965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1151\n","Loss =  tensor(163.8265, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1152\n","Loss =  tensor(153.6531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1153\n","Loss =  tensor(183.9720, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1154\n","Loss =  tensor(173.8839, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1155\n","Loss =  tensor(228.8631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1156\n","Loss =  tensor(135.2361, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1157\n","Loss =  tensor(157.8710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1158\n","Loss =  tensor(177.0894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1159\n","Loss =  tensor(201.4409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2151], grad_fn=<SelectBackward0>)\n","\n","Training step  1160\n","Loss =  tensor(164.4515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2151], grad_fn=<SelectBackward0>)\n","\n","Training step  1161\n","Loss =  tensor(146.6945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1162\n","Loss =  tensor(180.5396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1163\n","Loss =  tensor(165.6294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1164\n","Loss =  tensor(182.3872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1165\n","Loss =  tensor(149.1120, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1166\n","Loss =  tensor(153.8761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1167\n","Loss =  tensor(184.0237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1168\n","Loss =  tensor(174.9662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1169\n","Loss =  tensor(174.5990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2151], grad_fn=<SelectBackward0>)\n","\n","Training step  1170\n","Loss =  tensor(147.9792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1171\n","Loss =  tensor(153.4672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1172\n","Loss =  tensor(144.0346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2153], grad_fn=<SelectBackward0>)\n","\n","Training step  1173\n","Loss =  tensor(187.3250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  1174\n","Loss =  tensor(201.2724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1175\n","Loss =  tensor(150.6653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2146], grad_fn=<SelectBackward0>)\n","\n","Training step  1176\n","Loss =  tensor(145.5734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2143], grad_fn=<SelectBackward0>)\n","\n","Training step  1177\n","Loss =  tensor(177.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1178\n","Loss =  tensor(178.7437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1179\n","Loss =  tensor(190.3077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2137], grad_fn=<SelectBackward0>)\n","\n","Training step  1180\n","Loss =  tensor(125.6399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2137], grad_fn=<SelectBackward0>)\n","\n","Training step  1181\n","Loss =  tensor(177.9484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1182\n","Loss =  tensor(155.7518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1183\n","Loss =  tensor(144.6842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2143], grad_fn=<SelectBackward0>)\n","\n","Training step  1184\n","Loss =  tensor(153.7805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2145], grad_fn=<SelectBackward0>)\n","\n","Training step  1185\n","Loss =  tensor(163.7575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2148], grad_fn=<SelectBackward0>)\n","\n","Training step  1186\n","Loss =  tensor(164.5863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1187\n","Loss =  tensor(160.4449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  1188\n","Loss =  tensor(150.4756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  1189\n","Loss =  tensor(182.6845, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  1190\n","Loss =  tensor(162.2436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2144], grad_fn=<SelectBackward0>)\n","\n","Training step  1191\n","Loss =  tensor(149.3952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2141], grad_fn=<SelectBackward0>)\n","\n","Training step  1192\n","Loss =  tensor(137.2246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1193\n","Loss =  tensor(161.8641, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1194\n","Loss =  tensor(140.3022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1195\n","Loss =  tensor(144.3736, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1196\n","Loss =  tensor(135.0353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1197\n","Loss =  tensor(149.7267, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1198\n","Loss =  tensor(137.5674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1199\n","Loss =  tensor(171.9607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2142], grad_fn=<SelectBackward0>)\n","\n","Training step  1200\n","Loss =  tensor(151.5915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2143], grad_fn=<SelectBackward0>)\n","\n","Training step  1201\n","Loss =  tensor(113.5469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2143], grad_fn=<SelectBackward0>)\n","\n","Training step  1202\n","Loss =  tensor(145.1881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2144], grad_fn=<SelectBackward0>)\n","\n","Training step  1203\n","Loss =  tensor(133.3482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2145], grad_fn=<SelectBackward0>)\n","\n","Training step  1204\n","Loss =  tensor(145.3564, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2145], grad_fn=<SelectBackward0>)\n","\n","Training step  1205\n","Loss =  tensor(157.1337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2145], grad_fn=<SelectBackward0>)\n","\n","Training step  1206\n","Loss =  tensor(127.5287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2145], grad_fn=<SelectBackward0>)\n","\n","Training step  1207\n","Loss =  tensor(156.4479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2143], grad_fn=<SelectBackward0>)\n","\n","Training step  1208\n","Loss =  tensor(158.5518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2141], grad_fn=<SelectBackward0>)\n","\n","Training step  1209\n","Loss =  tensor(153.8352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1210\n","Loss =  tensor(136.5819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2136], grad_fn=<SelectBackward0>)\n","\n","Training step  1211\n","Loss =  tensor(145.5679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2134], grad_fn=<SelectBackward0>)\n","\n","Training step  1212\n","Loss =  tensor(153.6336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1213\n","Loss =  tensor(130.7333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  1214\n","Loss =  tensor(122.9399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  1215\n","Loss =  tensor(163.8933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1216\n","Loss =  tensor(148.1342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2135], grad_fn=<SelectBackward0>)\n","\n","Training step  1217\n","Loss =  tensor(142.3025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2135], grad_fn=<SelectBackward0>)\n","\n","Training step  1218\n","Loss =  tensor(145.0156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2136], grad_fn=<SelectBackward0>)\n","\n","Training step  1219\n","Loss =  tensor(151.7856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2135], grad_fn=<SelectBackward0>)\n","\n","Training step  1220\n","Loss =  tensor(126.8431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2134], grad_fn=<SelectBackward0>)\n","\n","Training step  1221\n","Loss =  tensor(157.5946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2134], grad_fn=<SelectBackward0>)\n","\n","Training step  1222\n","Loss =  tensor(138.7766, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2134], grad_fn=<SelectBackward0>)\n","\n","Training step  1223\n","Loss =  tensor(115.6295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2136], grad_fn=<SelectBackward0>)\n","\n","Training step  1224\n","Loss =  tensor(142.1046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1225\n","Loss =  tensor(125.3742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1226\n","Loss =  tensor(155.3907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1227\n","Loss =  tensor(126.0965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2140], grad_fn=<SelectBackward0>)\n","\n","Training step  1228\n","Loss =  tensor(131.1033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  1229\n","Loss =  tensor(128.4132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1230\n","Loss =  tensor(113.0887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2138], grad_fn=<SelectBackward0>)\n","\n","Training step  1231\n","Loss =  tensor(118.5745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2137], grad_fn=<SelectBackward0>)\n","\n","Training step  1232\n","Loss =  tensor(106.9947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2136], grad_fn=<SelectBackward0>)\n","\n","Training step  1233\n","Loss =  tensor(133.3383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2136], grad_fn=<SelectBackward0>)\n","\n","Training step  1234\n","Loss =  tensor(130.1277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2135], grad_fn=<SelectBackward0>)\n","\n","Training step  1235\n","Loss =  tensor(143.8196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2135], grad_fn=<SelectBackward0>)\n","\n","Training step  1236\n","Loss =  tensor(135.5174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2134], grad_fn=<SelectBackward0>)\n","\n","Training step  1237\n","Loss =  tensor(115.7588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  1238\n","Loss =  tensor(133.6504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1239\n","Loss =  tensor(130.3652, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1240\n","Loss =  tensor(126.9144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1241\n","Loss =  tensor(129.0901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1242\n","Loss =  tensor(114.4783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1243\n","Loss =  tensor(117.9783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1244\n","Loss =  tensor(136.3047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1245\n","Loss =  tensor(128.9312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1246\n","Loss =  tensor(136.3633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  1247\n","Loss =  tensor(115.7020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1248\n","Loss =  tensor(122.6429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1249\n","Loss =  tensor(150.0512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1250\n","Loss =  tensor(137.9487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1251\n","Loss =  tensor(135.5360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1252\n","Loss =  tensor(155.5868, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1253\n","Loss =  tensor(107.3390, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1254\n","Loss =  tensor(123.3405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1255\n","Loss =  tensor(93.5530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1256\n","Loss =  tensor(134.4246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1257\n","Loss =  tensor(115.6624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1258\n","Loss =  tensor(116.5271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1259\n","Loss =  tensor(132.3730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1260\n","Loss =  tensor(120.6283, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1261\n","Loss =  tensor(134.6692, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1262\n","Loss =  tensor(126.2613, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1263\n","Loss =  tensor(156.9785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1264\n","Loss =  tensor(112.4191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1265\n","Loss =  tensor(107.8500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1266\n","Loss =  tensor(133.8037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1267\n","Loss =  tensor(96.8169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1268\n","Loss =  tensor(138.6889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1269\n","Loss =  tensor(115.1539, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1270\n","Loss =  tensor(125.1707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2128], grad_fn=<SelectBackward0>)\n","\n","Training step  1271\n","Loss =  tensor(103.7960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1272\n","Loss =  tensor(115.0662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1273\n","Loss =  tensor(119.1716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1274\n","Loss =  tensor(130.3389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1275\n","Loss =  tensor(126.7298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2129], grad_fn=<SelectBackward0>)\n","\n","Training step  1276\n","Loss =  tensor(100.8041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  1277\n","Loss =  tensor(135.2337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1278\n","Loss =  tensor(109.3128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2133], grad_fn=<SelectBackward0>)\n","\n","Training step  1279\n","Loss =  tensor(98.4941, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  1280\n","Loss =  tensor(134.6546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2130], grad_fn=<SelectBackward0>)\n","\n","Training step  1281\n","Loss =  tensor(114.4021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  1282\n","Loss =  tensor(134.5708, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1283\n","Loss =  tensor(121.8279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  1284\n","Loss =  tensor(117.2723, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1285\n","Loss =  tensor(118.2036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1286\n","Loss =  tensor(113.8576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1287\n","Loss =  tensor(123.9448, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1288\n","Loss =  tensor(112.4455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2122], grad_fn=<SelectBackward0>)\n","\n","Training step  1289\n","Loss =  tensor(105.0557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1290\n","Loss =  tensor(101.7327, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  1291\n","Loss =  tensor(89.5668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  1292\n","Loss =  tensor(99.7745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  1293\n","Loss =  tensor(122.2435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1294\n","Loss =  tensor(113.4738, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  1295\n","Loss =  tensor(101.6218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1296\n","Loss =  tensor(100.1733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1297\n","Loss =  tensor(123.2225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1298\n","Loss =  tensor(108.1260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1299\n","Loss =  tensor(98.4919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2122], grad_fn=<SelectBackward0>)\n","\n","Training step  1300\n","Loss =  tensor(100.7431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  1301\n","Loss =  tensor(101.1756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1302\n","Loss =  tensor(97.5309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1303\n","Loss =  tensor(94.4504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2126], grad_fn=<SelectBackward0>)\n","\n","Training step  1304\n","Loss =  tensor(108.2592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  1305\n","Loss =  tensor(93.7158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  1306\n","Loss =  tensor(105.6026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1307\n","Loss =  tensor(102.4996, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1308\n","Loss =  tensor(105.2024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1309\n","Loss =  tensor(105.1961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1310\n","Loss =  tensor(119.0821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1311\n","Loss =  tensor(94.5799, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1312\n","Loss =  tensor(109.3188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1313\n","Loss =  tensor(93.5048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1314\n","Loss =  tensor(89.0112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2122], grad_fn=<SelectBackward0>)\n","\n","Training step  1315\n","Loss =  tensor(91.2567, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1316\n","Loss =  tensor(114.8148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1317\n","Loss =  tensor(95.6370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2123], grad_fn=<SelectBackward0>)\n","\n","Training step  1318\n","Loss =  tensor(109.9867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  1319\n","Loss =  tensor(93.7228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1320\n","Loss =  tensor(81.4585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1321\n","Loss =  tensor(99.1881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2116], grad_fn=<SelectBackward0>)\n","\n","Training step  1322\n","Loss =  tensor(113.4277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2115], grad_fn=<SelectBackward0>)\n","\n","Training step  1323\n","Loss =  tensor(76.6349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2114], grad_fn=<SelectBackward0>)\n","\n","Training step  1324\n","Loss =  tensor(99.8929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2115], grad_fn=<SelectBackward0>)\n","\n","Training step  1325\n","Loss =  tensor(81.8759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2115], grad_fn=<SelectBackward0>)\n","\n","Training step  1326\n","Loss =  tensor(106.5303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1327\n","Loss =  tensor(113.6352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1328\n","Loss =  tensor(84.1117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1329\n","Loss =  tensor(78.1985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2122], grad_fn=<SelectBackward0>)\n","\n","Training step  1330\n","Loss =  tensor(106.4332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2122], grad_fn=<SelectBackward0>)\n","\n","Training step  1331\n","Loss =  tensor(115.1723, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2120], grad_fn=<SelectBackward0>)\n","\n","Training step  1332\n","Loss =  tensor(101.3539, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1333\n","Loss =  tensor(116.6707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2114], grad_fn=<SelectBackward0>)\n","\n","Training step  1334\n","Loss =  tensor(77.2715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1335\n","Loss =  tensor(85.9497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1336\n","Loss =  tensor(100.3388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1337\n","Loss =  tensor(91.1613, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1338\n","Loss =  tensor(82.3948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2115], grad_fn=<SelectBackward0>)\n","\n","Training step  1339\n","Loss =  tensor(92.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1340\n","Loss =  tensor(91.6658, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1341\n","Loss =  tensor(86.6476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1342\n","Loss =  tensor(97.0900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1343\n","Loss =  tensor(87.6417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1344\n","Loss =  tensor(91.1226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2116], grad_fn=<SelectBackward0>)\n","\n","Training step  1345\n","Loss =  tensor(83.4840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2114], grad_fn=<SelectBackward0>)\n","\n","Training step  1346\n","Loss =  tensor(83.4760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1347\n","Loss =  tensor(80.0375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1348\n","Loss =  tensor(76.5278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1349\n","Loss =  tensor(90.8718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1350\n","Loss =  tensor(88.5718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1351\n","Loss =  tensor(82.6255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1352\n","Loss =  tensor(100.6287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1353\n","Loss =  tensor(92.8310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2114], grad_fn=<SelectBackward0>)\n","\n","Training step  1354\n","Loss =  tensor(74.7808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2116], grad_fn=<SelectBackward0>)\n","\n","Training step  1355\n","Loss =  tensor(76.8335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1356\n","Loss =  tensor(74.5021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  1357\n","Loss =  tensor(81.5116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1358\n","Loss =  tensor(97.9140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2119], grad_fn=<SelectBackward0>)\n","\n","Training step  1359\n","Loss =  tensor(95.2989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  1360\n","Loss =  tensor(89.9297, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2115], grad_fn=<SelectBackward0>)\n","\n","Training step  1361\n","Loss =  tensor(90.8292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1362\n","Loss =  tensor(83.3829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1363\n","Loss =  tensor(82.4552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2109], grad_fn=<SelectBackward0>)\n","\n","Training step  1364\n","Loss =  tensor(74.5442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1365\n","Loss =  tensor(72.3997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1366\n","Loss =  tensor(91.4074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1367\n","Loss =  tensor(85.2692, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1368\n","Loss =  tensor(81.7887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  1369\n","Loss =  tensor(115.2514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1370\n","Loss =  tensor(88.9423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1371\n","Loss =  tensor(60.5830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1372\n","Loss =  tensor(67.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1373\n","Loss =  tensor(84.8569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1374\n","Loss =  tensor(84.4196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1375\n","Loss =  tensor(91.1581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1376\n","Loss =  tensor(79.8037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1377\n","Loss =  tensor(70.8309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1378\n","Loss =  tensor(84.7922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  1379\n","Loss =  tensor(77.9695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  1380\n","Loss =  tensor(75.1393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  1381\n","Loss =  tensor(80.5307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1382\n","Loss =  tensor(95.4086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1383\n","Loss =  tensor(77.8237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1384\n","Loss =  tensor(74.4496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1385\n","Loss =  tensor(86.1303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1386\n","Loss =  tensor(73.1475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  1387\n","Loss =  tensor(79.7781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  1388\n","Loss =  tensor(69.1797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1389\n","Loss =  tensor(82.2294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1390\n","Loss =  tensor(81.6733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2109], grad_fn=<SelectBackward0>)\n","\n","Training step  1391\n","Loss =  tensor(55.3947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1392\n","Loss =  tensor(81.5843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1393\n","Loss =  tensor(89.3668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2112], grad_fn=<SelectBackward0>)\n","\n","Training step  1394\n","Loss =  tensor(82.1457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1395\n","Loss =  tensor(62.4840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1396\n","Loss =  tensor(54.5039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1397\n","Loss =  tensor(61.5785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2111], grad_fn=<SelectBackward0>)\n","\n","Training step  1398\n","Loss =  tensor(78.1380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1399\n","Loss =  tensor(68.0774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2110], grad_fn=<SelectBackward0>)\n","\n","Training step  1400\n","Loss =  tensor(76.3251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1401\n","Loss =  tensor(72.9603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1402\n","Loss =  tensor(66.3072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  1403\n","Loss =  tensor(72.6311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  1404\n","Loss =  tensor(90.7476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  1405\n","Loss =  tensor(62.4785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2103], grad_fn=<SelectBackward0>)\n","\n","Training step  1406\n","Loss =  tensor(76.0212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2103], grad_fn=<SelectBackward0>)\n","\n","Training step  1407\n","Loss =  tensor(70.6928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1408\n","Loss =  tensor(70.1130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1409\n","Loss =  tensor(65.8213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2103], grad_fn=<SelectBackward0>)\n","\n","Training step  1410\n","Loss =  tensor(67.0915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  1411\n","Loss =  tensor(75.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2105], grad_fn=<SelectBackward0>)\n","\n","Training step  1412\n","Loss =  tensor(63.2061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  1413\n","Loss =  tensor(68.0810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2108], grad_fn=<SelectBackward0>)\n","\n","Training step  1414\n","Loss =  tensor(81.4074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  1415\n","Loss =  tensor(75.2596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  1416\n","Loss =  tensor(63.5059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1417\n","Loss =  tensor(65.1762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1418\n","Loss =  tensor(69.1193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1419\n","Loss =  tensor(67.6830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1420\n","Loss =  tensor(85.2143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1421\n","Loss =  tensor(73.2682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1422\n","Loss =  tensor(75.8661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2103], grad_fn=<SelectBackward0>)\n","\n","Training step  1423\n","Loss =  tensor(67.3016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  1424\n","Loss =  tensor(68.7363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2105], grad_fn=<SelectBackward0>)\n","\n","Training step  1425\n","Loss =  tensor(72.5276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2105], grad_fn=<SelectBackward0>)\n","\n","Training step  1426\n","Loss =  tensor(56.9340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2105], grad_fn=<SelectBackward0>)\n","\n","Training step  1427\n","Loss =  tensor(79.4980, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  1428\n","Loss =  tensor(65.2130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2103], grad_fn=<SelectBackward0>)\n","\n","Training step  1429\n","Loss =  tensor(64.1433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1430\n","Loss =  tensor(66.8416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1431\n","Loss =  tensor(69.9260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1432\n","Loss =  tensor(68.4977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1433\n","Loss =  tensor(69.8628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1434\n","Loss =  tensor(68.5865, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1435\n","Loss =  tensor(65.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1436\n","Loss =  tensor(67.4391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1437\n","Loss =  tensor(66.5038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1438\n","Loss =  tensor(69.8593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1439\n","Loss =  tensor(57.9420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2102], grad_fn=<SelectBackward0>)\n","\n","Training step  1440\n","Loss =  tensor(66.0798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1441\n","Loss =  tensor(65.5744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1442\n","Loss =  tensor(66.5920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1443\n","Loss =  tensor(56.1372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1444\n","Loss =  tensor(68.9366, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1445\n","Loss =  tensor(64.2312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1446\n","Loss =  tensor(59.4088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1447\n","Loss =  tensor(66.9235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1448\n","Loss =  tensor(63.3071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1449\n","Loss =  tensor(55.2225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1450\n","Loss =  tensor(59.3134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1451\n","Loss =  tensor(55.5956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1452\n","Loss =  tensor(66.8483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1453\n","Loss =  tensor(46.7939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1454\n","Loss =  tensor(59.3484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1455\n","Loss =  tensor(70.1506, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  1456\n","Loss =  tensor(52.0683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1457\n","Loss =  tensor(58.0383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1458\n","Loss =  tensor(64.1037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1459\n","Loss =  tensor(58.2018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2096], grad_fn=<SelectBackward0>)\n","\n","Training step  1460\n","Loss =  tensor(68.5386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1461\n","Loss =  tensor(59.9035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2094], grad_fn=<SelectBackward0>)\n","\n","Training step  1462\n","Loss =  tensor(67.3088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2094], grad_fn=<SelectBackward0>)\n","\n","Training step  1463\n","Loss =  tensor(60.8337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2094], grad_fn=<SelectBackward0>)\n","\n","Training step  1464\n","Loss =  tensor(60.9479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1465\n","Loss =  tensor(68.6213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1466\n","Loss =  tensor(65.4517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2096], grad_fn=<SelectBackward0>)\n","\n","Training step  1467\n","Loss =  tensor(55.5649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1468\n","Loss =  tensor(52.9817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1469\n","Loss =  tensor(67.2137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  1470\n","Loss =  tensor(72.2130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2099], grad_fn=<SelectBackward0>)\n","\n","Training step  1471\n","Loss =  tensor(63.4985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1472\n","Loss =  tensor(53.4709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1473\n","Loss =  tensor(53.0623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1474\n","Loss =  tensor(54.3542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2094], grad_fn=<SelectBackward0>)\n","\n","Training step  1475\n","Loss =  tensor(67.0945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1476\n","Loss =  tensor(59.1599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1477\n","Loss =  tensor(63.5257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1478\n","Loss =  tensor(66.0709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1479\n","Loss =  tensor(76.4070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1480\n","Loss =  tensor(62.4704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1481\n","Loss =  tensor(49.6155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1482\n","Loss =  tensor(51.7268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2096], grad_fn=<SelectBackward0>)\n","\n","Training step  1483\n","Loss =  tensor(55.9400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  1484\n","Loss =  tensor(62.3286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  1485\n","Loss =  tensor(75.3487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1486\n","Loss =  tensor(63.7114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1487\n","Loss =  tensor(57.6319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1488\n","Loss =  tensor(54.7304, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1489\n","Loss =  tensor(47.6103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1490\n","Loss =  tensor(50.8849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1491\n","Loss =  tensor(54.4623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1492\n","Loss =  tensor(55.4266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1493\n","Loss =  tensor(58.3962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1494\n","Loss =  tensor(47.7762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1495\n","Loss =  tensor(47.8463, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1496\n","Loss =  tensor(56.8123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1497\n","Loss =  tensor(54.0382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2095], grad_fn=<SelectBackward0>)\n","\n","Training step  1498\n","Loss =  tensor(69.6465, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1499\n","Loss =  tensor(58.7345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1500\n","Loss =  tensor(58.9046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1501\n","Loss =  tensor(55.1454, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1502\n","Loss =  tensor(67.3527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1503\n","Loss =  tensor(62.3800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1504\n","Loss =  tensor(59.3718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1505\n","Loss =  tensor(51.9835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1506\n","Loss =  tensor(49.6812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1507\n","Loss =  tensor(58.2527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1508\n","Loss =  tensor(52.3651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1509\n","Loss =  tensor(52.3779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1510\n","Loss =  tensor(55.4723, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2093], grad_fn=<SelectBackward0>)\n","\n","Training step  1511\n","Loss =  tensor(64.1395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1512\n","Loss =  tensor(43.2519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1513\n","Loss =  tensor(46.7041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1514\n","Loss =  tensor(49.0784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1515\n","Loss =  tensor(48.4915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1516\n","Loss =  tensor(42.0920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1517\n","Loss =  tensor(48.2428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1518\n","Loss =  tensor(50.2607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1519\n","Loss =  tensor(45.5109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  1520\n","Loss =  tensor(53.6650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1521\n","Loss =  tensor(34.7671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1522\n","Loss =  tensor(46.5717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1523\n","Loss =  tensor(59.0259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1524\n","Loss =  tensor(45.6589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1525\n","Loss =  tensor(43.1838, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1526\n","Loss =  tensor(54.2685, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1527\n","Loss =  tensor(49.7431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1528\n","Loss =  tensor(60.9946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1529\n","Loss =  tensor(48.2354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1530\n","Loss =  tensor(48.4085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1531\n","Loss =  tensor(43.3213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1532\n","Loss =  tensor(42.7520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1533\n","Loss =  tensor(42.6888, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1534\n","Loss =  tensor(57.8247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2091], grad_fn=<SelectBackward0>)\n","\n","Training step  1535\n","Loss =  tensor(60.3149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  1536\n","Loss =  tensor(45.4272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1537\n","Loss =  tensor(52.3801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1538\n","Loss =  tensor(33.4986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1539\n","Loss =  tensor(50.7068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1540\n","Loss =  tensor(48.6338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1541\n","Loss =  tensor(44.6149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1542\n","Loss =  tensor(46.2777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1543\n","Loss =  tensor(48.6743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2084], grad_fn=<SelectBackward0>)\n","\n","Training step  1544\n","Loss =  tensor(42.8623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2084], grad_fn=<SelectBackward0>)\n","\n","Training step  1545\n","Loss =  tensor(39.4527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2084], grad_fn=<SelectBackward0>)\n","\n","Training step  1546\n","Loss =  tensor(43.1218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1547\n","Loss =  tensor(45.8157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1548\n","Loss =  tensor(41.4920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1549\n","Loss =  tensor(47.6011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1550\n","Loss =  tensor(46.2450, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2086], grad_fn=<SelectBackward0>)\n","\n","Training step  1551\n","Loss =  tensor(48.3475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1552\n","Loss =  tensor(43.1715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1553\n","Loss =  tensor(44.0085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1554\n","Loss =  tensor(46.9425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1555\n","Loss =  tensor(42.0314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1556\n","Loss =  tensor(46.8136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1557\n","Loss =  tensor(43.3366, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1558\n","Loss =  tensor(43.2792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1559\n","Loss =  tensor(41.4070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1560\n","Loss =  tensor(47.1045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  1561\n","Loss =  tensor(50.4095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1562\n","Loss =  tensor(44.8731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1563\n","Loss =  tensor(47.8934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1564\n","Loss =  tensor(40.0767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1565\n","Loss =  tensor(37.7019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1566\n","Loss =  tensor(38.9827, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1567\n","Loss =  tensor(48.6686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1568\n","Loss =  tensor(44.5441, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1569\n","Loss =  tensor(42.0735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1570\n","Loss =  tensor(41.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1571\n","Loss =  tensor(31.3686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1572\n","Loss =  tensor(42.7269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  1573\n","Loss =  tensor(54.4835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  1574\n","Loss =  tensor(47.4412, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2085], grad_fn=<SelectBackward0>)\n","\n","Training step  1575\n","Loss =  tensor(40.4874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1576\n","Loss =  tensor(42.3187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2082], grad_fn=<SelectBackward0>)\n","\n","Training step  1577\n","Loss =  tensor(39.6074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1578\n","Loss =  tensor(36.2915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1579\n","Loss =  tensor(38.1055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1580\n","Loss =  tensor(35.3056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1581\n","Loss =  tensor(39.3199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1582\n","Loss =  tensor(40.4675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1583\n","Loss =  tensor(38.1289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2082], grad_fn=<SelectBackward0>)\n","\n","Training step  1584\n","Loss =  tensor(44.2153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2082], grad_fn=<SelectBackward0>)\n","\n","Training step  1585\n","Loss =  tensor(42.5960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1586\n","Loss =  tensor(46.5777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1587\n","Loss =  tensor(38.6842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2083], grad_fn=<SelectBackward0>)\n","\n","Training step  1588\n","Loss =  tensor(47.7372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2082], grad_fn=<SelectBackward0>)\n","\n","Training step  1589\n","Loss =  tensor(42.3135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2081], grad_fn=<SelectBackward0>)\n","\n","Training step  1590\n","Loss =  tensor(42.0474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1591\n","Loss =  tensor(35.9138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1592\n","Loss =  tensor(36.5483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1593\n","Loss =  tensor(39.4419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1594\n","Loss =  tensor(43.5500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1595\n","Loss =  tensor(39.4577, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1596\n","Loss =  tensor(37.3676, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1597\n","Loss =  tensor(38.2684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1598\n","Loss =  tensor(41.6084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1599\n","Loss =  tensor(40.3430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1600\n","Loss =  tensor(40.8046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  1601\n","Loss =  tensor(40.0822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1602\n","Loss =  tensor(43.3251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1603\n","Loss =  tensor(30.7125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1604\n","Loss =  tensor(38.5817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1605\n","Loss =  tensor(33.3263, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1606\n","Loss =  tensor(35.3612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1607\n","Loss =  tensor(39.7261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1608\n","Loss =  tensor(32.6281, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1609\n","Loss =  tensor(41.2714, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1610\n","Loss =  tensor(40.0623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1611\n","Loss =  tensor(43.2992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1612\n","Loss =  tensor(36.7920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1613\n","Loss =  tensor(34.8809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1614\n","Loss =  tensor(36.5406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1615\n","Loss =  tensor(42.2061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1616\n","Loss =  tensor(34.5125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1617\n","Loss =  tensor(35.7028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1618\n","Loss =  tensor(34.4305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1619\n","Loss =  tensor(32.7133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1620\n","Loss =  tensor(36.3395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1621\n","Loss =  tensor(39.2579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2079], grad_fn=<SelectBackward0>)\n","\n","Training step  1622\n","Loss =  tensor(37.0239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2078], grad_fn=<SelectBackward0>)\n","\n","Training step  1623\n","Loss =  tensor(35.4682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1624\n","Loss =  tensor(35.4614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1625\n","Loss =  tensor(34.1155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1626\n","Loss =  tensor(41.1141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1627\n","Loss =  tensor(39.9789, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1628\n","Loss =  tensor(38.5418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1629\n","Loss =  tensor(38.3928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1630\n","Loss =  tensor(34.3828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1631\n","Loss =  tensor(33.6900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1632\n","Loss =  tensor(38.0365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1633\n","Loss =  tensor(37.8313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  1634\n","Loss =  tensor(37.5128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1635\n","Loss =  tensor(36.5729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1636\n","Loss =  tensor(35.4552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1637\n","Loss =  tensor(36.2419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1638\n","Loss =  tensor(34.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1639\n","Loss =  tensor(33.1028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1640\n","Loss =  tensor(35.7523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2074], grad_fn=<SelectBackward0>)\n","\n","Training step  1641\n","Loss =  tensor(37.8575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2074], grad_fn=<SelectBackward0>)\n","\n","Training step  1642\n","Loss =  tensor(34.2691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1643\n","Loss =  tensor(32.1407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1644\n","Loss =  tensor(34.5754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1645\n","Loss =  tensor(35.9664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1646\n","Loss =  tensor(38.2097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1647\n","Loss =  tensor(33.5178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1648\n","Loss =  tensor(36.6659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1649\n","Loss =  tensor(35.7373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1650\n","Loss =  tensor(35.3688, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1651\n","Loss =  tensor(34.1011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1652\n","Loss =  tensor(33.9181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2074], grad_fn=<SelectBackward0>)\n","\n","Training step  1653\n","Loss =  tensor(32.2252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1654\n","Loss =  tensor(29.6381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1655\n","Loss =  tensor(34.3314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1656\n","Loss =  tensor(30.1964, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  1657\n","Loss =  tensor(32.0688, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1658\n","Loss =  tensor(34.0383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  1659\n","Loss =  tensor(30.5851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2074], grad_fn=<SelectBackward0>)\n","\n","Training step  1660\n","Loss =  tensor(33.2933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1661\n","Loss =  tensor(31.0890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1662\n","Loss =  tensor(30.9684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1663\n","Loss =  tensor(31.0493, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1664\n","Loss =  tensor(32.3794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1665\n","Loss =  tensor(36.9857, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1666\n","Loss =  tensor(32.3721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1667\n","Loss =  tensor(33.2943, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1668\n","Loss =  tensor(29.6882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1669\n","Loss =  tensor(24.9361, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1670\n","Loss =  tensor(31.0545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2073], grad_fn=<SelectBackward0>)\n","\n","Training step  1671\n","Loss =  tensor(32.6675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1672\n","Loss =  tensor(29.5552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1673\n","Loss =  tensor(31.1733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1674\n","Loss =  tensor(31.8693, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1675\n","Loss =  tensor(29.7284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1676\n","Loss =  tensor(31.5454, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1677\n","Loss =  tensor(27.9008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1678\n","Loss =  tensor(30.2119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1679\n","Loss =  tensor(28.3306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1680\n","Loss =  tensor(37.6154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  1681\n","Loss =  tensor(32.1391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1682\n","Loss =  tensor(29.6724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1683\n","Loss =  tensor(29.5143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1684\n","Loss =  tensor(34.5203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1685\n","Loss =  tensor(29.9815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1686\n","Loss =  tensor(33.8010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1687\n","Loss =  tensor(32.6582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1688\n","Loss =  tensor(34.9220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1689\n","Loss =  tensor(32.6885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1690\n","Loss =  tensor(31.2314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1691\n","Loss =  tensor(28.9022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1692\n","Loss =  tensor(31.2438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1693\n","Loss =  tensor(32.1394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1694\n","Loss =  tensor(29.9973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1695\n","Loss =  tensor(27.6263, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1696\n","Loss =  tensor(27.5546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  1697\n","Loss =  tensor(34.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1698\n","Loss =  tensor(27.5160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1699\n","Loss =  tensor(30.7388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1700\n","Loss =  tensor(24.8201, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1701\n","Loss =  tensor(28.4316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1702\n","Loss =  tensor(28.0556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1703\n","Loss =  tensor(30.2668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1704\n","Loss =  tensor(27.7750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1705\n","Loss =  tensor(24.6216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1706\n","Loss =  tensor(30.9564, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1707\n","Loss =  tensor(26.8205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1708\n","Loss =  tensor(30.9418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1709\n","Loss =  tensor(25.0874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  1710\n","Loss =  tensor(31.6284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1711\n","Loss =  tensor(29.4382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1712\n","Loss =  tensor(29.9526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1713\n","Loss =  tensor(31.7459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  1714\n","Loss =  tensor(31.9092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1715\n","Loss =  tensor(27.8807, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1716\n","Loss =  tensor(27.8278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1717\n","Loss =  tensor(30.4100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1718\n","Loss =  tensor(28.6982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1719\n","Loss =  tensor(32.6638, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1720\n","Loss =  tensor(29.6783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1721\n","Loss =  tensor(26.0128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1722\n","Loss =  tensor(23.6927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1723\n","Loss =  tensor(28.7734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1724\n","Loss =  tensor(27.4640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1725\n","Loss =  tensor(28.6617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1726\n","Loss =  tensor(32.1797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1727\n","Loss =  tensor(25.1197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1728\n","Loss =  tensor(28.7517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1729\n","Loss =  tensor(33.0326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1730\n","Loss =  tensor(26.7822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1731\n","Loss =  tensor(29.3066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1732\n","Loss =  tensor(29.4254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1733\n","Loss =  tensor(28.7894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1734\n","Loss =  tensor(30.6719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1735\n","Loss =  tensor(29.9858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1736\n","Loss =  tensor(30.4577, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1737\n","Loss =  tensor(30.4696, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1738\n","Loss =  tensor(29.6174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  1739\n","Loss =  tensor(29.2538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1740\n","Loss =  tensor(27.3465, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1741\n","Loss =  tensor(28.2992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  1742\n","Loss =  tensor(33.2033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1743\n","Loss =  tensor(32.7080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1744\n","Loss =  tensor(25.9087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1745\n","Loss =  tensor(25.3437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1746\n","Loss =  tensor(29.2576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1747\n","Loss =  tensor(25.7255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1748\n","Loss =  tensor(27.4831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1749\n","Loss =  tensor(27.0315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1750\n","Loss =  tensor(27.3647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1751\n","Loss =  tensor(28.2571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1752\n","Loss =  tensor(27.6699, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1753\n","Loss =  tensor(26.6731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1754\n","Loss =  tensor(27.6784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1755\n","Loss =  tensor(28.4966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1756\n","Loss =  tensor(27.0572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1757\n","Loss =  tensor(29.7421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1758\n","Loss =  tensor(25.7574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1759\n","Loss =  tensor(27.6794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1760\n","Loss =  tensor(25.1453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1761\n","Loss =  tensor(23.6912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1762\n","Loss =  tensor(24.1396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1763\n","Loss =  tensor(19.9888, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1764\n","Loss =  tensor(29.2166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1765\n","Loss =  tensor(26.1560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1766\n","Loss =  tensor(22.9771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1767\n","Loss =  tensor(27.7084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1768\n","Loss =  tensor(29.0863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1769\n","Loss =  tensor(24.1979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1770\n","Loss =  tensor(25.0938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1771\n","Loss =  tensor(25.2972, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1772\n","Loss =  tensor(26.2967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1773\n","Loss =  tensor(25.8252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1774\n","Loss =  tensor(23.6879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1775\n","Loss =  tensor(25.0433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1776\n","Loss =  tensor(26.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1777\n","Loss =  tensor(27.3254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1778\n","Loss =  tensor(27.6880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2063], grad_fn=<SelectBackward0>)\n","\n","Training step  1779\n","Loss =  tensor(28.6364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1780\n","Loss =  tensor(24.2371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1781\n","Loss =  tensor(23.8157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1782\n","Loss =  tensor(26.0497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1783\n","Loss =  tensor(25.8449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1784\n","Loss =  tensor(26.3133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1785\n","Loss =  tensor(20.9517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1786\n","Loss =  tensor(24.2208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1787\n","Loss =  tensor(24.0941, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1788\n","Loss =  tensor(22.5981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1789\n","Loss =  tensor(24.1886, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2066], grad_fn=<SelectBackward0>)\n","\n","Training step  1790\n","Loss =  tensor(27.4866, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  1791\n","Loss =  tensor(23.7423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2064], grad_fn=<SelectBackward0>)\n","\n","Training step  1792\n","Loss =  tensor(28.2215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1793\n","Loss =  tensor(23.1622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1794\n","Loss =  tensor(27.5216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1795\n","Loss =  tensor(24.5344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1796\n","Loss =  tensor(25.7594, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1797\n","Loss =  tensor(27.1989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1798\n","Loss =  tensor(25.4043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1799\n","Loss =  tensor(22.3574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1800\n","Loss =  tensor(23.6731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1801\n","Loss =  tensor(25.3178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1802\n","Loss =  tensor(23.7342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1803\n","Loss =  tensor(22.9501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1804\n","Loss =  tensor(20.7582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1805\n","Loss =  tensor(22.3820, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2062], grad_fn=<SelectBackward0>)\n","\n","Training step  1806\n","Loss =  tensor(20.7504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  1807\n","Loss =  tensor(23.0527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1808\n","Loss =  tensor(23.7429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1809\n","Loss =  tensor(25.7204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1810\n","Loss =  tensor(23.9360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1811\n","Loss =  tensor(23.3744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1812\n","Loss =  tensor(23.4261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1813\n","Loss =  tensor(27.6142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1814\n","Loss =  tensor(24.3172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1815\n","Loss =  tensor(22.8994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1816\n","Loss =  tensor(21.8930, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1817\n","Loss =  tensor(24.7661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1818\n","Loss =  tensor(24.3266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1819\n","Loss =  tensor(23.5819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1820\n","Loss =  tensor(24.5323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1821\n","Loss =  tensor(19.6817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1822\n","Loss =  tensor(22.1829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1823\n","Loss =  tensor(22.5310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1824\n","Loss =  tensor(21.3300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1825\n","Loss =  tensor(20.5275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1826\n","Loss =  tensor(21.7580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1827\n","Loss =  tensor(23.1550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1828\n","Loss =  tensor(21.0341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1829\n","Loss =  tensor(23.2531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1830\n","Loss =  tensor(21.7328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1831\n","Loss =  tensor(25.9545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1832\n","Loss =  tensor(21.5888, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1833\n","Loss =  tensor(21.8103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1834\n","Loss =  tensor(21.2554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1835\n","Loss =  tensor(23.1724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1836\n","Loss =  tensor(23.1049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1837\n","Loss =  tensor(23.2670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1838\n","Loss =  tensor(20.9471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1839\n","Loss =  tensor(21.1917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1840\n","Loss =  tensor(20.4235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1841\n","Loss =  tensor(23.6018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1842\n","Loss =  tensor(21.7602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1843\n","Loss =  tensor(23.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1844\n","Loss =  tensor(23.8707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1845\n","Loss =  tensor(26.1438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1846\n","Loss =  tensor(18.8040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1847\n","Loss =  tensor(21.2803, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1848\n","Loss =  tensor(21.9556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1849\n","Loss =  tensor(24.4641, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1850\n","Loss =  tensor(18.6301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1851\n","Loss =  tensor(18.6155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1852\n","Loss =  tensor(20.9205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1853\n","Loss =  tensor(25.1128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2060], grad_fn=<SelectBackward0>)\n","\n","Training step  1854\n","Loss =  tensor(24.9307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1855\n","Loss =  tensor(18.2679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1856\n","Loss =  tensor(19.0729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1857\n","Loss =  tensor(17.6422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1858\n","Loss =  tensor(18.7939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1859\n","Loss =  tensor(22.5832, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1860\n","Loss =  tensor(22.7445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1861\n","Loss =  tensor(23.8492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1862\n","Loss =  tensor(23.0990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1863\n","Loss =  tensor(20.8277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1864\n","Loss =  tensor(18.3772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1865\n","Loss =  tensor(20.7798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  1866\n","Loss =  tensor(26.4595, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1867\n","Loss =  tensor(20.6192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1868\n","Loss =  tensor(21.0827, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1869\n","Loss =  tensor(19.4164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1870\n","Loss =  tensor(22.4704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1871\n","Loss =  tensor(21.7647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1872\n","Loss =  tensor(23.1739, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1873\n","Loss =  tensor(23.6700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1874\n","Loss =  tensor(19.5934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1875\n","Loss =  tensor(20.2558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1876\n","Loss =  tensor(19.9090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1877\n","Loss =  tensor(21.5868, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1878\n","Loss =  tensor(20.8060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1879\n","Loss =  tensor(18.4554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  1880\n","Loss =  tensor(18.6529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1881\n","Loss =  tensor(23.3284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1882\n","Loss =  tensor(16.7165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1883\n","Loss =  tensor(19.7377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1884\n","Loss =  tensor(23.6322, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1885\n","Loss =  tensor(21.2928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1886\n","Loss =  tensor(18.5887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1887\n","Loss =  tensor(20.0908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1888\n","Loss =  tensor(19.8284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1889\n","Loss =  tensor(20.0885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1890\n","Loss =  tensor(17.8378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1891\n","Loss =  tensor(20.6952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1892\n","Loss =  tensor(23.7199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1893\n","Loss =  tensor(20.3107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1894\n","Loss =  tensor(19.3310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1895\n","Loss =  tensor(21.3516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1896\n","Loss =  tensor(22.3520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1897\n","Loss =  tensor(19.5942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1898\n","Loss =  tensor(19.9831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1899\n","Loss =  tensor(20.4858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1900\n","Loss =  tensor(20.8659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1901\n","Loss =  tensor(18.6104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1902\n","Loss =  tensor(18.4876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1903\n","Loss =  tensor(18.7395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1904\n","Loss =  tensor(19.7592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  1905\n","Loss =  tensor(21.5490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  1906\n","Loss =  tensor(19.9871, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1907\n","Loss =  tensor(20.1802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1908\n","Loss =  tensor(19.5444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1909\n","Loss =  tensor(19.0131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1910\n","Loss =  tensor(22.7849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1911\n","Loss =  tensor(19.1206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1912\n","Loss =  tensor(21.5549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1913\n","Loss =  tensor(21.3806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1914\n","Loss =  tensor(21.3561, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1915\n","Loss =  tensor(19.2975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  1916\n","Loss =  tensor(18.5425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1917\n","Loss =  tensor(20.8052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1918\n","Loss =  tensor(21.3257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1919\n","Loss =  tensor(17.6750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1920\n","Loss =  tensor(19.3151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1921\n","Loss =  tensor(18.4554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1922\n","Loss =  tensor(17.6343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1923\n","Loss =  tensor(18.1801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1924\n","Loss =  tensor(19.1213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1925\n","Loss =  tensor(20.5237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1926\n","Loss =  tensor(18.8811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1927\n","Loss =  tensor(18.7402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1928\n","Loss =  tensor(16.5427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1929\n","Loss =  tensor(20.5707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1930\n","Loss =  tensor(16.3697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1931\n","Loss =  tensor(20.1117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1932\n","Loss =  tensor(20.6600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1933\n","Loss =  tensor(20.3213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1934\n","Loss =  tensor(22.1761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1935\n","Loss =  tensor(18.8948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1936\n","Loss =  tensor(16.5266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1937\n","Loss =  tensor(19.6187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1938\n","Loss =  tensor(19.2479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  1939\n","Loss =  tensor(18.5903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1940\n","Loss =  tensor(17.9886, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1941\n","Loss =  tensor(16.2093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  1942\n","Loss =  tensor(19.6415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2052], grad_fn=<SelectBackward0>)\n","\n","Training step  1943\n","Loss =  tensor(18.6045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1944\n","Loss =  tensor(20.0862, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1945\n","Loss =  tensor(17.1133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1946\n","Loss =  tensor(17.9710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1947\n","Loss =  tensor(15.9292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1948\n","Loss =  tensor(20.5541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1949\n","Loss =  tensor(18.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1950\n","Loss =  tensor(20.1333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1951\n","Loss =  tensor(18.3207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1952\n","Loss =  tensor(15.7309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1953\n","Loss =  tensor(16.8027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1954\n","Loss =  tensor(18.7632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1955\n","Loss =  tensor(19.1313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1956\n","Loss =  tensor(18.7778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1957\n","Loss =  tensor(16.6805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1958\n","Loss =  tensor(16.3702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1959\n","Loss =  tensor(20.1069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1960\n","Loss =  tensor(19.6496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1961\n","Loss =  tensor(18.5197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1962\n","Loss =  tensor(16.4829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1963\n","Loss =  tensor(17.1084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1964\n","Loss =  tensor(16.9471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1965\n","Loss =  tensor(16.8385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1966\n","Loss =  tensor(15.8042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1967\n","Loss =  tensor(17.5710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1968\n","Loss =  tensor(16.0579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1969\n","Loss =  tensor(20.0116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1970\n","Loss =  tensor(15.2661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1971\n","Loss =  tensor(15.6324, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  1972\n","Loss =  tensor(20.3384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2050], grad_fn=<SelectBackward0>)\n","\n","Training step  1973\n","Loss =  tensor(14.5661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1974\n","Loss =  tensor(18.5258, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1975\n","Loss =  tensor(16.6113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1976\n","Loss =  tensor(16.8637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1977\n","Loss =  tensor(16.9626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1978\n","Loss =  tensor(15.9770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1979\n","Loss =  tensor(18.3840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1980\n","Loss =  tensor(18.4707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1981\n","Loss =  tensor(14.8398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1982\n","Loss =  tensor(18.9268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1983\n","Loss =  tensor(14.8495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1984\n","Loss =  tensor(17.4982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1985\n","Loss =  tensor(17.8880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1986\n","Loss =  tensor(17.1284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1987\n","Loss =  tensor(17.2583, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1988\n","Loss =  tensor(16.7700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1989\n","Loss =  tensor(20.2966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1990\n","Loss =  tensor(18.0109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1991\n","Loss =  tensor(16.3857, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1992\n","Loss =  tensor(18.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1993\n","Loss =  tensor(17.3532, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1994\n","Loss =  tensor(14.3461, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  1995\n","Loss =  tensor(15.9645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1996\n","Loss =  tensor(17.0811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1997\n","Loss =  tensor(16.7903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1998\n","Loss =  tensor(14.6422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  1999\n","Loss =  tensor(17.1294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2000\n","Loss =  tensor(16.9961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2001\n","Loss =  tensor(16.6585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2002\n","Loss =  tensor(17.8198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2003\n","Loss =  tensor(17.3708, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2004\n","Loss =  tensor(17.6328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  2005\n","Loss =  tensor(18.6849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2006\n","Loss =  tensor(17.2824, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2007\n","Loss =  tensor(16.0281, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2008\n","Loss =  tensor(18.6305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2009\n","Loss =  tensor(17.3759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2010\n","Loss =  tensor(18.9820, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  2011\n","Loss =  tensor(19.6911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2012\n","Loss =  tensor(16.9711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2013\n","Loss =  tensor(15.3080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2014\n","Loss =  tensor(16.1904, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2015\n","Loss =  tensor(15.1356, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2016\n","Loss =  tensor(16.7884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2017\n","Loss =  tensor(15.7733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2018\n","Loss =  tensor(17.5986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2019\n","Loss =  tensor(16.6487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2020\n","Loss =  tensor(19.8386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2021\n","Loss =  tensor(15.1294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2022\n","Loss =  tensor(16.8889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2023\n","Loss =  tensor(13.6951, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2024\n","Loss =  tensor(18.4469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2025\n","Loss =  tensor(18.4052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2026\n","Loss =  tensor(15.6899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2027\n","Loss =  tensor(16.2829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2028\n","Loss =  tensor(17.7809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2029\n","Loss =  tensor(17.4554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2030\n","Loss =  tensor(15.5358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2031\n","Loss =  tensor(15.0527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2032\n","Loss =  tensor(13.9835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2033\n","Loss =  tensor(17.6067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2034\n","Loss =  tensor(16.1955, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2035\n","Loss =  tensor(14.1972, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  2036\n","Loss =  tensor(23.1074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  2037\n","Loss =  tensor(16.7373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2038\n","Loss =  tensor(14.4228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2039\n","Loss =  tensor(16.3896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2040\n","Loss =  tensor(15.9551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2041\n","Loss =  tensor(15.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2042\n","Loss =  tensor(17.3045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2043\n","Loss =  tensor(15.4559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2044\n","Loss =  tensor(15.5545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2045\n","Loss =  tensor(16.3392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2046\n","Loss =  tensor(15.9623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2047\n","Loss =  tensor(13.5912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2048\n","Loss =  tensor(16.4706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  2049\n","Loss =  tensor(17.2987, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2048], grad_fn=<SelectBackward0>)\n","\n","Training step  2050\n","Loss =  tensor(15.6784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  2051\n","Loss =  tensor(15.0089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2052\n","Loss =  tensor(17.3424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2053\n","Loss =  tensor(16.7558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2054\n","Loss =  tensor(16.0613, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2055\n","Loss =  tensor(15.8101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2056\n","Loss =  tensor(15.9736, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2057\n","Loss =  tensor(15.1158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2058\n","Loss =  tensor(19.4433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2059\n","Loss =  tensor(15.1952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2060\n","Loss =  tensor(17.7702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2061\n","Loss =  tensor(15.6313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2046], grad_fn=<SelectBackward0>)\n","\n","Training step  2062\n","Loss =  tensor(14.0190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2063\n","Loss =  tensor(14.2659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2064\n","Loss =  tensor(14.8762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2065\n","Loss =  tensor(14.6768, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2066\n","Loss =  tensor(15.3375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2067\n","Loss =  tensor(17.0568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2068\n","Loss =  tensor(14.4961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2069\n","Loss =  tensor(15.9250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2070\n","Loss =  tensor(16.8683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2071\n","Loss =  tensor(16.9062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2072\n","Loss =  tensor(16.3474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2073\n","Loss =  tensor(17.0786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2074\n","Loss =  tensor(17.7811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2075\n","Loss =  tensor(14.8057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2076\n","Loss =  tensor(17.9812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2077\n","Loss =  tensor(14.1548, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2078\n","Loss =  tensor(15.6175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2079\n","Loss =  tensor(16.4989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2080\n","Loss =  tensor(12.9293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2081\n","Loss =  tensor(16.4544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2082\n","Loss =  tensor(17.2551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2083\n","Loss =  tensor(14.2494, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2084\n","Loss =  tensor(15.9495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2085\n","Loss =  tensor(15.0570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2086\n","Loss =  tensor(14.1333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2087\n","Loss =  tensor(15.7358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2088\n","Loss =  tensor(16.9944, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2089\n","Loss =  tensor(18.1444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2090\n","Loss =  tensor(16.1548, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2091\n","Loss =  tensor(13.9856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2092\n","Loss =  tensor(14.4591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2093\n","Loss =  tensor(14.7569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2094\n","Loss =  tensor(13.0953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2095\n","Loss =  tensor(16.5830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2096\n","Loss =  tensor(14.5759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2097\n","Loss =  tensor(13.6911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2098\n","Loss =  tensor(15.4896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2099\n","Loss =  tensor(15.4272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2100\n","Loss =  tensor(17.7195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2101\n","Loss =  tensor(16.6165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2102\n","Loss =  tensor(15.0336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2103\n","Loss =  tensor(15.4826, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2104\n","Loss =  tensor(16.0567, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2105\n","Loss =  tensor(12.6376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2106\n","Loss =  tensor(14.9866, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2107\n","Loss =  tensor(17.0905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2108\n","Loss =  tensor(17.5272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2109\n","Loss =  tensor(16.4732, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2110\n","Loss =  tensor(18.5008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2111\n","Loss =  tensor(13.4132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2112\n","Loss =  tensor(19.1268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2113\n","Loss =  tensor(14.6088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2114\n","Loss =  tensor(15.8003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2115\n","Loss =  tensor(15.6950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2116\n","Loss =  tensor(16.6417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2117\n","Loss =  tensor(14.3208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2118\n","Loss =  tensor(18.1897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2119\n","Loss =  tensor(12.3295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2120\n","Loss =  tensor(15.4248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2121\n","Loss =  tensor(14.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2122\n","Loss =  tensor(14.3240, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2123\n","Loss =  tensor(12.8448, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2124\n","Loss =  tensor(14.6400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2125\n","Loss =  tensor(11.8503, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2126\n","Loss =  tensor(17.2842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2127\n","Loss =  tensor(14.3006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2128\n","Loss =  tensor(14.3393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2129\n","Loss =  tensor(13.2480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2130\n","Loss =  tensor(16.7299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2131\n","Loss =  tensor(15.0964, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2132\n","Loss =  tensor(11.0611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2133\n","Loss =  tensor(14.6269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2134\n","Loss =  tensor(14.9099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2135\n","Loss =  tensor(14.4560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2136\n","Loss =  tensor(14.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2137\n","Loss =  tensor(10.6962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2138\n","Loss =  tensor(15.5758, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2139\n","Loss =  tensor(14.8786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2140\n","Loss =  tensor(12.1674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2141\n","Loss =  tensor(13.9922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2142\n","Loss =  tensor(14.6653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2143\n","Loss =  tensor(14.9264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2144\n","Loss =  tensor(14.5885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2145\n","Loss =  tensor(15.9649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2146\n","Loss =  tensor(13.3040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2147\n","Loss =  tensor(15.4251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2148\n","Loss =  tensor(14.3313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2149\n","Loss =  tensor(17.4550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2150\n","Loss =  tensor(14.8175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2151\n","Loss =  tensor(14.1037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2152\n","Loss =  tensor(14.8875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2153\n","Loss =  tensor(14.5899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2154\n","Loss =  tensor(15.6283, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2155\n","Loss =  tensor(17.4510, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2156\n","Loss =  tensor(15.1212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2157\n","Loss =  tensor(13.3835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2158\n","Loss =  tensor(14.0160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2159\n","Loss =  tensor(19.0897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2160\n","Loss =  tensor(13.4024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2161\n","Loss =  tensor(13.7284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2162\n","Loss =  tensor(14.3526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2163\n","Loss =  tensor(17.2189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2164\n","Loss =  tensor(16.8406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2165\n","Loss =  tensor(15.3392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2166\n","Loss =  tensor(12.6633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2167\n","Loss =  tensor(11.5645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  2168\n","Loss =  tensor(12.2934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2169\n","Loss =  tensor(15.0762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  2170\n","Loss =  tensor(17.3989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  2171\n","Loss =  tensor(17.1950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  2172\n","Loss =  tensor(15.4129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2173\n","Loss =  tensor(14.0224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2174\n","Loss =  tensor(12.3280, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2175\n","Loss =  tensor(17.9098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2176\n","Loss =  tensor(14.8609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2177\n","Loss =  tensor(15.7310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2178\n","Loss =  tensor(12.7440, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2179\n","Loss =  tensor(11.9466, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2180\n","Loss =  tensor(14.4465, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2181\n","Loss =  tensor(13.5632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2182\n","Loss =  tensor(15.1766, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2183\n","Loss =  tensor(15.4418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2184\n","Loss =  tensor(13.4200, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2185\n","Loss =  tensor(14.0651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2186\n","Loss =  tensor(12.3144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2187\n","Loss =  tensor(10.9732, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2188\n","Loss =  tensor(14.3210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2189\n","Loss =  tensor(11.3110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2190\n","Loss =  tensor(12.3767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2191\n","Loss =  tensor(13.4959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2192\n","Loss =  tensor(17.1095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  2193\n","Loss =  tensor(13.9014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2194\n","Loss =  tensor(12.4970, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2195\n","Loss =  tensor(12.2656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2196\n","Loss =  tensor(13.2165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2197\n","Loss =  tensor(12.5729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2198\n","Loss =  tensor(12.8475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2199\n","Loss =  tensor(13.4051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2200\n","Loss =  tensor(13.2215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2201\n","Loss =  tensor(15.8592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2202\n","Loss =  tensor(13.5155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2203\n","Loss =  tensor(13.0836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2204\n","Loss =  tensor(13.7543, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2205\n","Loss =  tensor(11.9003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2206\n","Loss =  tensor(13.9492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2207\n","Loss =  tensor(10.9889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2208\n","Loss =  tensor(13.4906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2209\n","Loss =  tensor(12.5066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2210\n","Loss =  tensor(13.2111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2211\n","Loss =  tensor(12.5172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2212\n","Loss =  tensor(11.9601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2213\n","Loss =  tensor(13.7148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2214\n","Loss =  tensor(12.3180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  2215\n","Loss =  tensor(10.4540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2216\n","Loss =  tensor(12.7639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2217\n","Loss =  tensor(14.1770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2218\n","Loss =  tensor(10.7897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2219\n","Loss =  tensor(14.3853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2220\n","Loss =  tensor(13.6992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2221\n","Loss =  tensor(15.1639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2222\n","Loss =  tensor(15.6370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2223\n","Loss =  tensor(12.6020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2224\n","Loss =  tensor(14.6731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2225\n","Loss =  tensor(15.5016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2226\n","Loss =  tensor(13.1276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2227\n","Loss =  tensor(14.7114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2228\n","Loss =  tensor(10.3639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2229\n","Loss =  tensor(14.1417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2230\n","Loss =  tensor(12.5801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2231\n","Loss =  tensor(11.2910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2232\n","Loss =  tensor(12.7065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2233\n","Loss =  tensor(12.1330, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2234\n","Loss =  tensor(12.4815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2235\n","Loss =  tensor(13.6654, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2236\n","Loss =  tensor(13.2266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2237\n","Loss =  tensor(12.8648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2238\n","Loss =  tensor(12.8040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2239\n","Loss =  tensor(13.6472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2240\n","Loss =  tensor(13.2617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2241\n","Loss =  tensor(13.1581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2242\n","Loss =  tensor(15.3319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2243\n","Loss =  tensor(13.8245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2244\n","Loss =  tensor(12.7632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2245\n","Loss =  tensor(12.2690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2246\n","Loss =  tensor(13.6573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2247\n","Loss =  tensor(13.2468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2248\n","Loss =  tensor(9.2783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2249\n","Loss =  tensor(13.1492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  2250\n","Loss =  tensor(13.3734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2251\n","Loss =  tensor(12.6314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2252\n","Loss =  tensor(12.2653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2253\n","Loss =  tensor(11.9482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2254\n","Loss =  tensor(14.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2255\n","Loss =  tensor(13.2480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2256\n","Loss =  tensor(16.4273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2257\n","Loss =  tensor(10.1651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2258\n","Loss =  tensor(12.4701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2259\n","Loss =  tensor(12.2352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2260\n","Loss =  tensor(12.8226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2261\n","Loss =  tensor(14.0292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2262\n","Loss =  tensor(13.3402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2263\n","Loss =  tensor(13.3268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2264\n","Loss =  tensor(11.0559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2265\n","Loss =  tensor(13.5413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2266\n","Loss =  tensor(13.4691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2267\n","Loss =  tensor(12.0240, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2268\n","Loss =  tensor(14.9860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2269\n","Loss =  tensor(15.8133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2270\n","Loss =  tensor(12.1924, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2271\n","Loss =  tensor(12.6433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2272\n","Loss =  tensor(12.3585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2273\n","Loss =  tensor(11.5354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2274\n","Loss =  tensor(15.2528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2275\n","Loss =  tensor(12.6380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2276\n","Loss =  tensor(14.2083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2277\n","Loss =  tensor(12.5376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2278\n","Loss =  tensor(14.2370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2279\n","Loss =  tensor(11.6995, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2280\n","Loss =  tensor(10.6251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2281\n","Loss =  tensor(15.2483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2282\n","Loss =  tensor(13.3717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2283\n","Loss =  tensor(14.0194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2284\n","Loss =  tensor(12.7673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2285\n","Loss =  tensor(10.9982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2286\n","Loss =  tensor(12.6556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2287\n","Loss =  tensor(12.5291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2288\n","Loss =  tensor(13.3441, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2289\n","Loss =  tensor(13.1040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2290\n","Loss =  tensor(14.1194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2291\n","Loss =  tensor(13.4102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2292\n","Loss =  tensor(14.1829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2293\n","Loss =  tensor(13.5627, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2294\n","Loss =  tensor(12.5210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2295\n","Loss =  tensor(13.6615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2296\n","Loss =  tensor(14.0605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2297\n","Loss =  tensor(11.5383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2298\n","Loss =  tensor(10.8949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2299\n","Loss =  tensor(12.4118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2300\n","Loss =  tensor(13.5840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2301\n","Loss =  tensor(13.4055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  2302\n","Loss =  tensor(13.4771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2303\n","Loss =  tensor(11.2005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2304\n","Loss =  tensor(13.1858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2305\n","Loss =  tensor(12.8853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2306\n","Loss =  tensor(13.2127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2307\n","Loss =  tensor(12.7967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2308\n","Loss =  tensor(13.4415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2309\n","Loss =  tensor(10.7953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2310\n","Loss =  tensor(14.1038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2311\n","Loss =  tensor(12.8397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2312\n","Loss =  tensor(12.9221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2313\n","Loss =  tensor(12.7034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2314\n","Loss =  tensor(12.6053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2315\n","Loss =  tensor(11.0853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2316\n","Loss =  tensor(10.6187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2317\n","Loss =  tensor(12.4910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2318\n","Loss =  tensor(12.0581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2319\n","Loss =  tensor(11.7645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2320\n","Loss =  tensor(12.5487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2321\n","Loss =  tensor(12.7933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2322\n","Loss =  tensor(13.5631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2323\n","Loss =  tensor(12.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2324\n","Loss =  tensor(13.4249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2325\n","Loss =  tensor(11.6376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2326\n","Loss =  tensor(11.0856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2327\n","Loss =  tensor(11.1982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2328\n","Loss =  tensor(11.3584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2329\n","Loss =  tensor(11.8517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2330\n","Loss =  tensor(13.3651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2331\n","Loss =  tensor(12.7224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2332\n","Loss =  tensor(11.1455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2333\n","Loss =  tensor(13.5815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2334\n","Loss =  tensor(11.7070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2335\n","Loss =  tensor(13.0967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2336\n","Loss =  tensor(12.3472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2337\n","Loss =  tensor(13.2607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2338\n","Loss =  tensor(11.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2339\n","Loss =  tensor(13.6660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2340\n","Loss =  tensor(12.8179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2341\n","Loss =  tensor(14.1665, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2342\n","Loss =  tensor(12.2350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2343\n","Loss =  tensor(11.5013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2344\n","Loss =  tensor(12.4621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2345\n","Loss =  tensor(11.3405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2346\n","Loss =  tensor(12.8415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2347\n","Loss =  tensor(10.4279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2348\n","Loss =  tensor(12.9504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2349\n","Loss =  tensor(14.7133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2350\n","Loss =  tensor(13.8935, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2351\n","Loss =  tensor(12.2588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2352\n","Loss =  tensor(13.4854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2353\n","Loss =  tensor(11.1663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2354\n","Loss =  tensor(11.5686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2355\n","Loss =  tensor(14.3773, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2356\n","Loss =  tensor(12.6067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2357\n","Loss =  tensor(11.4847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2358\n","Loss =  tensor(12.0847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2359\n","Loss =  tensor(11.8347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2360\n","Loss =  tensor(13.3810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2361\n","Loss =  tensor(12.2687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2362\n","Loss =  tensor(10.1217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2363\n","Loss =  tensor(11.4855, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2364\n","Loss =  tensor(11.8732, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2365\n","Loss =  tensor(11.6332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2366\n","Loss =  tensor(13.5420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2367\n","Loss =  tensor(12.0496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2368\n","Loss =  tensor(9.4215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2369\n","Loss =  tensor(10.8969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2370\n","Loss =  tensor(14.6719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2371\n","Loss =  tensor(11.3696, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2372\n","Loss =  tensor(9.8876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2373\n","Loss =  tensor(12.1649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2374\n","Loss =  tensor(11.9880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2375\n","Loss =  tensor(11.3664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2376\n","Loss =  tensor(12.5557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2377\n","Loss =  tensor(12.2881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2378\n","Loss =  tensor(10.7925, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2379\n","Loss =  tensor(11.8459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2380\n","Loss =  tensor(10.6848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2381\n","Loss =  tensor(11.3393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2382\n","Loss =  tensor(10.7234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2383\n","Loss =  tensor(11.0352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2384\n","Loss =  tensor(14.1453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2385\n","Loss =  tensor(10.0886, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2386\n","Loss =  tensor(11.0161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2387\n","Loss =  tensor(10.9722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2388\n","Loss =  tensor(11.7136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2389\n","Loss =  tensor(13.2496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2390\n","Loss =  tensor(11.7853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2391\n","Loss =  tensor(9.3554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2392\n","Loss =  tensor(14.6409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  2393\n","Loss =  tensor(10.2199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2394\n","Loss =  tensor(11.8446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2395\n","Loss =  tensor(11.6611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2396\n","Loss =  tensor(11.4825, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2397\n","Loss =  tensor(12.9207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2398\n","Loss =  tensor(12.7092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2399\n","Loss =  tensor(10.7152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2400\n","Loss =  tensor(10.5093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2401\n","Loss =  tensor(10.2598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2402\n","Loss =  tensor(10.1748, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2403\n","Loss =  tensor(11.7195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  2404\n","Loss =  tensor(14.3506, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2405\n","Loss =  tensor(12.4315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2406\n","Loss =  tensor(10.6650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2407\n","Loss =  tensor(9.9726, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2408\n","Loss =  tensor(12.3559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2409\n","Loss =  tensor(11.7202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2410\n","Loss =  tensor(9.3431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2411\n","Loss =  tensor(12.2045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2412\n","Loss =  tensor(11.7707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2413\n","Loss =  tensor(9.6939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2414\n","Loss =  tensor(10.6583, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2415\n","Loss =  tensor(9.3171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2416\n","Loss =  tensor(13.3879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2417\n","Loss =  tensor(11.2145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2418\n","Loss =  tensor(13.1419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2419\n","Loss =  tensor(12.2833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2420\n","Loss =  tensor(11.8560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2421\n","Loss =  tensor(12.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2422\n","Loss =  tensor(13.4092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2423\n","Loss =  tensor(11.6438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2424\n","Loss =  tensor(10.4132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2425\n","Loss =  tensor(12.2247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2426\n","Loss =  tensor(9.9044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2427\n","Loss =  tensor(11.2803, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2428\n","Loss =  tensor(13.5184, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2429\n","Loss =  tensor(12.7851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2430\n","Loss =  tensor(12.3900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2431\n","Loss =  tensor(8.9354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2432\n","Loss =  tensor(10.3213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2433\n","Loss =  tensor(11.7598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2434\n","Loss =  tensor(12.4642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2435\n","Loss =  tensor(11.9481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2436\n","Loss =  tensor(12.1753, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2437\n","Loss =  tensor(12.3712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2438\n","Loss =  tensor(13.4666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2439\n","Loss =  tensor(12.4789, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2440\n","Loss =  tensor(10.5270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2441\n","Loss =  tensor(11.4197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2442\n","Loss =  tensor(11.9169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2443\n","Loss =  tensor(12.0501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2444\n","Loss =  tensor(12.5580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2445\n","Loss =  tensor(10.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2446\n","Loss =  tensor(11.4831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  2447\n","Loss =  tensor(15.4976, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2448\n","Loss =  tensor(10.3525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2449\n","Loss =  tensor(10.9229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2450\n","Loss =  tensor(12.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2451\n","Loss =  tensor(9.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2452\n","Loss =  tensor(9.9968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2453\n","Loss =  tensor(10.8301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2454\n","Loss =  tensor(8.6091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2455\n","Loss =  tensor(10.3325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2456\n","Loss =  tensor(12.0841, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2457\n","Loss =  tensor(10.3206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2458\n","Loss =  tensor(11.8680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2459\n","Loss =  tensor(10.3018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2460\n","Loss =  tensor(12.0558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2461\n","Loss =  tensor(10.1431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2462\n","Loss =  tensor(10.2348, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2463\n","Loss =  tensor(10.8838, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2464\n","Loss =  tensor(11.3170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2465\n","Loss =  tensor(10.3163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2466\n","Loss =  tensor(10.8301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2467\n","Loss =  tensor(11.2424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2468\n","Loss =  tensor(11.3331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2469\n","Loss =  tensor(12.3280, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2470\n","Loss =  tensor(10.5991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2471\n","Loss =  tensor(13.8138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2472\n","Loss =  tensor(10.9566, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2473\n","Loss =  tensor(12.4603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2474\n","Loss =  tensor(11.3354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2475\n","Loss =  tensor(11.5581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2476\n","Loss =  tensor(10.4541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2477\n","Loss =  tensor(10.4679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2478\n","Loss =  tensor(13.2102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2479\n","Loss =  tensor(11.4965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  2480\n","Loss =  tensor(11.3267, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2481\n","Loss =  tensor(11.7882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2482\n","Loss =  tensor(11.8376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2483\n","Loss =  tensor(10.5314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2484\n","Loss =  tensor(9.6936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2485\n","Loss =  tensor(9.9214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2486\n","Loss =  tensor(12.0534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2487\n","Loss =  tensor(12.3294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2488\n","Loss =  tensor(11.0753, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2489\n","Loss =  tensor(11.2640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2490\n","Loss =  tensor(11.0564, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2491\n","Loss =  tensor(10.2991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2492\n","Loss =  tensor(10.7468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  2493\n","Loss =  tensor(10.5464, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2494\n","Loss =  tensor(12.4738, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2495\n","Loss =  tensor(11.1096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2496\n","Loss =  tensor(11.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2497\n","Loss =  tensor(11.5536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2498\n","Loss =  tensor(11.2809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2499\n","Loss =  tensor(11.0686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2500\n","Loss =  tensor(11.4154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2501\n","Loss =  tensor(10.2476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2502\n","Loss =  tensor(10.9656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2503\n","Loss =  tensor(10.4322, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2504\n","Loss =  tensor(10.0610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2505\n","Loss =  tensor(9.1786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2506\n","Loss =  tensor(13.0958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2507\n","Loss =  tensor(10.5121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2508\n","Loss =  tensor(11.4807, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2509\n","Loss =  tensor(10.4656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2510\n","Loss =  tensor(11.5939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2511\n","Loss =  tensor(11.2431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2512\n","Loss =  tensor(9.8209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2513\n","Loss =  tensor(9.1956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2514\n","Loss =  tensor(8.8123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2515\n","Loss =  tensor(11.1779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2516\n","Loss =  tensor(11.0318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2517\n","Loss =  tensor(11.8894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2518\n","Loss =  tensor(11.0448, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2519\n","Loss =  tensor(12.5190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2520\n","Loss =  tensor(10.2682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2521\n","Loss =  tensor(9.1024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2522\n","Loss =  tensor(10.3957, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2523\n","Loss =  tensor(12.3512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2524\n","Loss =  tensor(11.8495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2525\n","Loss =  tensor(11.7208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2526\n","Loss =  tensor(10.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2527\n","Loss =  tensor(11.1598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2528\n","Loss =  tensor(12.3928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2529\n","Loss =  tensor(9.0154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2530\n","Loss =  tensor(10.9043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2531\n","Loss =  tensor(8.0327, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2532\n","Loss =  tensor(10.3841, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2533\n","Loss =  tensor(9.8905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2534\n","Loss =  tensor(9.7174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2535\n","Loss =  tensor(10.6647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2536\n","Loss =  tensor(11.9863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2537\n","Loss =  tensor(12.4479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2538\n","Loss =  tensor(10.9166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2539\n","Loss =  tensor(9.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2540\n","Loss =  tensor(10.3755, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2541\n","Loss =  tensor(10.5019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2542\n","Loss =  tensor(11.2496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2543\n","Loss =  tensor(10.3802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2544\n","Loss =  tensor(9.6197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2545\n","Loss =  tensor(12.0654, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2546\n","Loss =  tensor(9.5496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2547\n","Loss =  tensor(12.5941, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2548\n","Loss =  tensor(12.2220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2549\n","Loss =  tensor(11.5403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2550\n","Loss =  tensor(9.4122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2551\n","Loss =  tensor(11.5903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2552\n","Loss =  tensor(10.0398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2553\n","Loss =  tensor(10.5981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2554\n","Loss =  tensor(11.9425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2555\n","Loss =  tensor(10.4228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2556\n","Loss =  tensor(11.4007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2557\n","Loss =  tensor(11.0888, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2558\n","Loss =  tensor(12.5115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2559\n","Loss =  tensor(8.9368, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2560\n","Loss =  tensor(11.7310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2561\n","Loss =  tensor(9.8626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2562\n","Loss =  tensor(9.9314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2563\n","Loss =  tensor(8.8794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2564\n","Loss =  tensor(7.8333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2565\n","Loss =  tensor(9.9127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2566\n","Loss =  tensor(9.8089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2567\n","Loss =  tensor(10.4036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2568\n","Loss =  tensor(11.1537, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2569\n","Loss =  tensor(10.6734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2570\n","Loss =  tensor(8.8786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2571\n","Loss =  tensor(11.2029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2572\n","Loss =  tensor(10.9598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2573\n","Loss =  tensor(9.7093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2574\n","Loss =  tensor(10.3179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2575\n","Loss =  tensor(10.5926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2576\n","Loss =  tensor(10.8196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2577\n","Loss =  tensor(10.7521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2578\n","Loss =  tensor(9.5516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2579\n","Loss =  tensor(9.3312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2580\n","Loss =  tensor(11.7562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2581\n","Loss =  tensor(10.4494, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2582\n","Loss =  tensor(10.6406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2583\n","Loss =  tensor(11.5532, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2584\n","Loss =  tensor(10.2798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2585\n","Loss =  tensor(9.4885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2586\n","Loss =  tensor(11.2325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2587\n","Loss =  tensor(9.2769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2588\n","Loss =  tensor(10.6140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2589\n","Loss =  tensor(8.2791, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2590\n","Loss =  tensor(9.7812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2591\n","Loss =  tensor(9.8426, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2592\n","Loss =  tensor(11.9992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2593\n","Loss =  tensor(9.6880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2594\n","Loss =  tensor(10.7460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2595\n","Loss =  tensor(9.6565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2596\n","Loss =  tensor(9.1495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2597\n","Loss =  tensor(10.9947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2598\n","Loss =  tensor(11.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2599\n","Loss =  tensor(9.6205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2600\n","Loss =  tensor(7.7115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2601\n","Loss =  tensor(10.2111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2602\n","Loss =  tensor(10.1171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2603\n","Loss =  tensor(9.3038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2604\n","Loss =  tensor(9.8636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2605\n","Loss =  tensor(10.8374, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2606\n","Loss =  tensor(9.5089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2607\n","Loss =  tensor(8.4325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2608\n","Loss =  tensor(12.3138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2609\n","Loss =  tensor(9.6080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2610\n","Loss =  tensor(8.4259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2611\n","Loss =  tensor(9.2270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2612\n","Loss =  tensor(8.4080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2613\n","Loss =  tensor(9.3588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2614\n","Loss =  tensor(8.7588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2615\n","Loss =  tensor(9.6487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2616\n","Loss =  tensor(9.2526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2617\n","Loss =  tensor(6.9077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2618\n","Loss =  tensor(10.1194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2619\n","Loss =  tensor(9.7910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2620\n","Loss =  tensor(11.7888, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2621\n","Loss =  tensor(7.8743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2622\n","Loss =  tensor(10.2588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2623\n","Loss =  tensor(9.1172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2624\n","Loss =  tensor(10.6795, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2625\n","Loss =  tensor(10.5856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2626\n","Loss =  tensor(11.1073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2627\n","Loss =  tensor(10.0623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2628\n","Loss =  tensor(8.7128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2629\n","Loss =  tensor(9.4392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2630\n","Loss =  tensor(10.0934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2631\n","Loss =  tensor(9.5678, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2632\n","Loss =  tensor(8.7663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2633\n","Loss =  tensor(8.8745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2634\n","Loss =  tensor(10.3525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2635\n","Loss =  tensor(12.6800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2636\n","Loss =  tensor(10.2598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  2637\n","Loss =  tensor(10.5214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2638\n","Loss =  tensor(8.3620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2639\n","Loss =  tensor(10.3694, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2640\n","Loss =  tensor(7.6859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2641\n","Loss =  tensor(10.2861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2642\n","Loss =  tensor(9.1718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2643\n","Loss =  tensor(9.9904, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2644\n","Loss =  tensor(9.8195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2645\n","Loss =  tensor(8.1639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2646\n","Loss =  tensor(9.1093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2647\n","Loss =  tensor(9.6047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2648\n","Loss =  tensor(9.9106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2649\n","Loss =  tensor(8.8266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2650\n","Loss =  tensor(8.6754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2651\n","Loss =  tensor(8.2882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2652\n","Loss =  tensor(9.7109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2653\n","Loss =  tensor(8.7520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2654\n","Loss =  tensor(9.8038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2655\n","Loss =  tensor(8.9189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2656\n","Loss =  tensor(10.3855, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2657\n","Loss =  tensor(8.6153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2658\n","Loss =  tensor(10.4653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2659\n","Loss =  tensor(9.5649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2660\n","Loss =  tensor(10.5041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2661\n","Loss =  tensor(10.8018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2662\n","Loss =  tensor(7.6489, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2663\n","Loss =  tensor(8.4852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2664\n","Loss =  tensor(9.0207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2665\n","Loss =  tensor(9.0713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2666\n","Loss =  tensor(9.7415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2667\n","Loss =  tensor(9.0963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2668\n","Loss =  tensor(8.8642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2669\n","Loss =  tensor(9.6202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2670\n","Loss =  tensor(11.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2671\n","Loss =  tensor(7.5994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2672\n","Loss =  tensor(9.7407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2673\n","Loss =  tensor(10.4968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2674\n","Loss =  tensor(10.2295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2675\n","Loss =  tensor(9.4278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2676\n","Loss =  tensor(9.1086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2677\n","Loss =  tensor(9.3660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2678\n","Loss =  tensor(10.7550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2679\n","Loss =  tensor(11.0175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2680\n","Loss =  tensor(9.4776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2681\n","Loss =  tensor(8.0621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2682\n","Loss =  tensor(10.2567, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2683\n","Loss =  tensor(8.9950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2684\n","Loss =  tensor(9.2452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2685\n","Loss =  tensor(9.2447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2686\n","Loss =  tensor(8.3630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2687\n","Loss =  tensor(9.5256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2688\n","Loss =  tensor(8.1036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2689\n","Loss =  tensor(9.1161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2690\n","Loss =  tensor(9.1143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  2691\n","Loss =  tensor(8.4733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  2692\n","Loss =  tensor(7.7508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2693\n","Loss =  tensor(8.5102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2694\n","Loss =  tensor(8.5568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2695\n","Loss =  tensor(7.7140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2696\n","Loss =  tensor(7.9868, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2697\n","Loss =  tensor(8.8507, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2698\n","Loss =  tensor(10.2844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2699\n","Loss =  tensor(9.1753, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2700\n","Loss =  tensor(9.3999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2701\n","Loss =  tensor(11.6207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2702\n","Loss =  tensor(8.8212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2703\n","Loss =  tensor(7.4081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2704\n","Loss =  tensor(9.3781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2705\n","Loss =  tensor(9.0155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2706\n","Loss =  tensor(9.8198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2707\n","Loss =  tensor(8.8487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2708\n","Loss =  tensor(10.6564, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2709\n","Loss =  tensor(7.9502, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2710\n","Loss =  tensor(8.6977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2711\n","Loss =  tensor(8.6500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2712\n","Loss =  tensor(8.7520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2713\n","Loss =  tensor(9.9218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2714\n","Loss =  tensor(8.8178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2715\n","Loss =  tensor(9.8313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2716\n","Loss =  tensor(9.0848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2717\n","Loss =  tensor(9.3338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2718\n","Loss =  tensor(8.5616, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2719\n","Loss =  tensor(9.2099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2720\n","Loss =  tensor(8.5522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2721\n","Loss =  tensor(7.9278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2722\n","Loss =  tensor(9.4810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2723\n","Loss =  tensor(8.5785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2724\n","Loss =  tensor(7.6771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2725\n","Loss =  tensor(9.9034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2726\n","Loss =  tensor(9.2936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2727\n","Loss =  tensor(9.4126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2728\n","Loss =  tensor(8.3613, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2729\n","Loss =  tensor(9.5029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2730\n","Loss =  tensor(10.2341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2731\n","Loss =  tensor(8.1655, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2732\n","Loss =  tensor(8.4525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2733\n","Loss =  tensor(8.8948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2734\n","Loss =  tensor(8.8600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2735\n","Loss =  tensor(7.4105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2736\n","Loss =  tensor(9.3741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2737\n","Loss =  tensor(8.7867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2738\n","Loss =  tensor(10.2902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2739\n","Loss =  tensor(8.8309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2740\n","Loss =  tensor(9.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2741\n","Loss =  tensor(9.4718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2742\n","Loss =  tensor(7.7192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2743\n","Loss =  tensor(8.8470, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2744\n","Loss =  tensor(9.4273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2745\n","Loss =  tensor(8.3116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2746\n","Loss =  tensor(9.0231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2747\n","Loss =  tensor(8.5438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2748\n","Loss =  tensor(7.7334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2749\n","Loss =  tensor(10.0726, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2750\n","Loss =  tensor(7.9648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2751\n","Loss =  tensor(8.4327, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2752\n","Loss =  tensor(10.0293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2753\n","Loss =  tensor(9.4283, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2754\n","Loss =  tensor(6.4552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2755\n","Loss =  tensor(8.9732, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2756\n","Loss =  tensor(9.5896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2757\n","Loss =  tensor(8.0089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2758\n","Loss =  tensor(9.2464, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2759\n","Loss =  tensor(9.4198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2760\n","Loss =  tensor(8.8808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2761\n","Loss =  tensor(9.7068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2762\n","Loss =  tensor(9.2382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2763\n","Loss =  tensor(10.2799, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2764\n","Loss =  tensor(9.9402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2765\n","Loss =  tensor(9.5609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2766\n","Loss =  tensor(9.6121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2767\n","Loss =  tensor(8.7659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2768\n","Loss =  tensor(7.2298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2769\n","Loss =  tensor(7.9140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2770\n","Loss =  tensor(8.5305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2771\n","Loss =  tensor(7.0998, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2772\n","Loss =  tensor(7.6772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2773\n","Loss =  tensor(6.9873, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2774\n","Loss =  tensor(9.1628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2775\n","Loss =  tensor(9.2983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2776\n","Loss =  tensor(7.2885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2777\n","Loss =  tensor(9.3919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2778\n","Loss =  tensor(7.7808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2779\n","Loss =  tensor(8.3844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2780\n","Loss =  tensor(8.3849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2781\n","Loss =  tensor(8.3927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2782\n","Loss =  tensor(9.2329, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2783\n","Loss =  tensor(7.7188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2784\n","Loss =  tensor(8.4488, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2785\n","Loss =  tensor(9.8371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2786\n","Loss =  tensor(8.5029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2787\n","Loss =  tensor(8.9994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  2788\n","Loss =  tensor(7.6343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2789\n","Loss =  tensor(8.6279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2790\n","Loss =  tensor(9.9176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2791\n","Loss =  tensor(10.4478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2792\n","Loss =  tensor(8.9462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2793\n","Loss =  tensor(9.2431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2794\n","Loss =  tensor(8.7777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2795\n","Loss =  tensor(8.6793, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2796\n","Loss =  tensor(7.5413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2797\n","Loss =  tensor(8.0362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2798\n","Loss =  tensor(8.1291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2799\n","Loss =  tensor(8.1328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2800\n","Loss =  tensor(8.6615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2801\n","Loss =  tensor(8.2572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2802\n","Loss =  tensor(7.8953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2803\n","Loss =  tensor(8.0276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2804\n","Loss =  tensor(8.7899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2805\n","Loss =  tensor(9.4835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2806\n","Loss =  tensor(7.3136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2807\n","Loss =  tensor(8.3786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2808\n","Loss =  tensor(8.1401, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2809\n","Loss =  tensor(10.4297, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2810\n","Loss =  tensor(8.3711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2811\n","Loss =  tensor(7.8731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2812\n","Loss =  tensor(7.9670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2813\n","Loss =  tensor(8.1368, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2814\n","Loss =  tensor(6.6305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2815\n","Loss =  tensor(9.5596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2816\n","Loss =  tensor(7.8269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2817\n","Loss =  tensor(7.8778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2818\n","Loss =  tensor(7.6365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2819\n","Loss =  tensor(8.1680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2820\n","Loss =  tensor(8.1317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2821\n","Loss =  tensor(6.5314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2822\n","Loss =  tensor(5.9284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2823\n","Loss =  tensor(9.3375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2824\n","Loss =  tensor(8.8287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2825\n","Loss =  tensor(7.6164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2826\n","Loss =  tensor(8.5504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2827\n","Loss =  tensor(9.4008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2828\n","Loss =  tensor(7.5468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2829\n","Loss =  tensor(8.2961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2830\n","Loss =  tensor(8.7024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2831\n","Loss =  tensor(7.0851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2832\n","Loss =  tensor(8.1833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2833\n","Loss =  tensor(8.5290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2834\n","Loss =  tensor(8.7152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2835\n","Loss =  tensor(9.4282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2836\n","Loss =  tensor(8.0264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2837\n","Loss =  tensor(6.6565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2838\n","Loss =  tensor(9.2062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2839\n","Loss =  tensor(8.5100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2840\n","Loss =  tensor(7.4805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2841\n","Loss =  tensor(10.0985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2842\n","Loss =  tensor(6.9583, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2843\n","Loss =  tensor(8.6576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2844\n","Loss =  tensor(8.7757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2845\n","Loss =  tensor(6.2619, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2846\n","Loss =  tensor(8.2716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2847\n","Loss =  tensor(7.5636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2848\n","Loss =  tensor(7.7261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2849\n","Loss =  tensor(9.0325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2850\n","Loss =  tensor(9.9442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2851\n","Loss =  tensor(8.6156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2852\n","Loss =  tensor(6.5385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2853\n","Loss =  tensor(6.6327, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2854\n","Loss =  tensor(8.9539, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2855\n","Loss =  tensor(7.2458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2856\n","Loss =  tensor(7.5848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2857\n","Loss =  tensor(8.9228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2858\n","Loss =  tensor(8.6637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2859\n","Loss =  tensor(7.5075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2860\n","Loss =  tensor(7.5601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2861\n","Loss =  tensor(7.4424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2862\n","Loss =  tensor(8.5044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2863\n","Loss =  tensor(8.6169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2864\n","Loss =  tensor(6.7197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2865\n","Loss =  tensor(7.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2866\n","Loss =  tensor(8.4662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2867\n","Loss =  tensor(7.6131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2868\n","Loss =  tensor(6.9428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2869\n","Loss =  tensor(8.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2870\n","Loss =  tensor(8.1993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2871\n","Loss =  tensor(8.6406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2872\n","Loss =  tensor(7.4039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2873\n","Loss =  tensor(8.0521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2874\n","Loss =  tensor(8.9247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2875\n","Loss =  tensor(8.4282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2876\n","Loss =  tensor(9.6354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2877\n","Loss =  tensor(5.3776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2878\n","Loss =  tensor(9.3731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2879\n","Loss =  tensor(7.3176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2880\n","Loss =  tensor(7.6358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2881\n","Loss =  tensor(6.9042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2882\n","Loss =  tensor(7.5101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2883\n","Loss =  tensor(6.2870, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2884\n","Loss =  tensor(8.3447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2885\n","Loss =  tensor(8.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2886\n","Loss =  tensor(8.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2887\n","Loss =  tensor(7.9589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2888\n","Loss =  tensor(7.6260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2889\n","Loss =  tensor(7.1351, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2890\n","Loss =  tensor(6.7356, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2891\n","Loss =  tensor(8.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2892\n","Loss =  tensor(8.2814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2893\n","Loss =  tensor(8.5474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2894\n","Loss =  tensor(8.1370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2895\n","Loss =  tensor(6.5248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2896\n","Loss =  tensor(6.7595, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2897\n","Loss =  tensor(8.0649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2898\n","Loss =  tensor(7.3386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2899\n","Loss =  tensor(7.2586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2900\n","Loss =  tensor(7.3027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2901\n","Loss =  tensor(5.4937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2902\n","Loss =  tensor(6.5958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2903\n","Loss =  tensor(5.6210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2904\n","Loss =  tensor(8.1028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2905\n","Loss =  tensor(6.6834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2906\n","Loss =  tensor(7.0602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2907\n","Loss =  tensor(7.8946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2908\n","Loss =  tensor(6.8856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2909\n","Loss =  tensor(7.4721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2910\n","Loss =  tensor(7.4159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2911\n","Loss =  tensor(7.4075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2912\n","Loss =  tensor(7.9214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2913\n","Loss =  tensor(8.5593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2914\n","Loss =  tensor(7.9412, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2915\n","Loss =  tensor(7.5311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2916\n","Loss =  tensor(8.1252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2917\n","Loss =  tensor(6.6670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2918\n","Loss =  tensor(9.3172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2919\n","Loss =  tensor(9.2582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2920\n","Loss =  tensor(6.9869, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2921\n","Loss =  tensor(7.7840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2922\n","Loss =  tensor(8.6290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2923\n","Loss =  tensor(7.4630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2924\n","Loss =  tensor(9.2942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2925\n","Loss =  tensor(7.5682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2926\n","Loss =  tensor(6.6845, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2927\n","Loss =  tensor(7.8681, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  2928\n","Loss =  tensor(8.3576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2929\n","Loss =  tensor(8.3832, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  2930\n","Loss =  tensor(6.5556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2931\n","Loss =  tensor(7.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2932\n","Loss =  tensor(7.5926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2933\n","Loss =  tensor(7.9897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2934\n","Loss =  tensor(8.1692, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2935\n","Loss =  tensor(7.6046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2936\n","Loss =  tensor(7.8059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2937\n","Loss =  tensor(7.5937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2938\n","Loss =  tensor(7.7227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2939\n","Loss =  tensor(6.8376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2940\n","Loss =  tensor(7.7513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2941\n","Loss =  tensor(7.3117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2942\n","Loss =  tensor(7.6593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2943\n","Loss =  tensor(6.2087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2944\n","Loss =  tensor(6.8963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2945\n","Loss =  tensor(7.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2946\n","Loss =  tensor(7.0431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2947\n","Loss =  tensor(7.5423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2948\n","Loss =  tensor(7.0960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2949\n","Loss =  tensor(7.4172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2950\n","Loss =  tensor(7.5046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2951\n","Loss =  tensor(8.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  2952\n","Loss =  tensor(6.6177, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2953\n","Loss =  tensor(7.7523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2954\n","Loss =  tensor(7.2608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2955\n","Loss =  tensor(7.6260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2956\n","Loss =  tensor(6.6985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2957\n","Loss =  tensor(7.4648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2958\n","Loss =  tensor(6.5692, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2959\n","Loss =  tensor(6.5059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2960\n","Loss =  tensor(8.4116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2961\n","Loss =  tensor(7.5098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2962\n","Loss =  tensor(9.5447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2963\n","Loss =  tensor(6.8525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2964\n","Loss =  tensor(8.1422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2026], grad_fn=<SelectBackward0>)\n","\n","Training step  2965\n","Loss =  tensor(8.2188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2966\n","Loss =  tensor(7.7703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2967\n","Loss =  tensor(7.1822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2968\n","Loss =  tensor(7.7514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2969\n","Loss =  tensor(5.9505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2970\n","Loss =  tensor(6.5956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2971\n","Loss =  tensor(7.1429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2972\n","Loss =  tensor(7.4187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2973\n","Loss =  tensor(7.6677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2974\n","Loss =  tensor(7.9049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2975\n","Loss =  tensor(6.9969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2976\n","Loss =  tensor(7.4167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2977\n","Loss =  tensor(6.7161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2978\n","Loss =  tensor(6.4797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2979\n","Loss =  tensor(7.9703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2980\n","Loss =  tensor(6.9153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2981\n","Loss =  tensor(7.9373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2982\n","Loss =  tensor(6.0403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2983\n","Loss =  tensor(6.9673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2984\n","Loss =  tensor(7.4521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2985\n","Loss =  tensor(7.8032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2986\n","Loss =  tensor(6.7999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2987\n","Loss =  tensor(6.4049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2988\n","Loss =  tensor(7.6714, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2989\n","Loss =  tensor(7.0433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2990\n","Loss =  tensor(7.0232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  2991\n","Loss =  tensor(5.6290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2992\n","Loss =  tensor(7.3933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2993\n","Loss =  tensor(5.6069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2994\n","Loss =  tensor(7.9951, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2995\n","Loss =  tensor(6.5413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2996\n","Loss =  tensor(7.0863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2997\n","Loss =  tensor(7.0812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2998\n","Loss =  tensor(8.0911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  2999\n","Loss =  tensor(8.0747, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3000\n","Loss =  tensor(5.8993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3001\n","Loss =  tensor(7.6964, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3002\n","Loss =  tensor(6.6257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3003\n","Loss =  tensor(5.6504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3004\n","Loss =  tensor(6.9936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3005\n","Loss =  tensor(7.8610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3006\n","Loss =  tensor(7.5237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3007\n","Loss =  tensor(7.3048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3008\n","Loss =  tensor(7.6021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3009\n","Loss =  tensor(6.0635, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3010\n","Loss =  tensor(6.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3011\n","Loss =  tensor(7.6409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3012\n","Loss =  tensor(6.5094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3013\n","Loss =  tensor(7.1913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3014\n","Loss =  tensor(7.0847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3015\n","Loss =  tensor(6.6181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3016\n","Loss =  tensor(8.5248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3017\n","Loss =  tensor(7.5775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3018\n","Loss =  tensor(5.8298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3019\n","Loss =  tensor(7.0297, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3020\n","Loss =  tensor(6.6774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3021\n","Loss =  tensor(7.5665, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3022\n","Loss =  tensor(7.0331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3023\n","Loss =  tensor(7.4251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3024\n","Loss =  tensor(6.6684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3025\n","Loss =  tensor(6.8615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3026\n","Loss =  tensor(5.8883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3027\n","Loss =  tensor(7.3364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3028\n","Loss =  tensor(8.5500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  3029\n","Loss =  tensor(6.8294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3030\n","Loss =  tensor(6.6770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3031\n","Loss =  tensor(7.7633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3032\n","Loss =  tensor(7.5310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3033\n","Loss =  tensor(5.7674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3034\n","Loss =  tensor(7.5298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3035\n","Loss =  tensor(6.5994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3036\n","Loss =  tensor(5.1825, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3037\n","Loss =  tensor(5.8159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3038\n","Loss =  tensor(5.8203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3039\n","Loss =  tensor(6.1181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3040\n","Loss =  tensor(6.7285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3041\n","Loss =  tensor(6.5819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3042\n","Loss =  tensor(4.9926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3043\n","Loss =  tensor(7.7228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3044\n","Loss =  tensor(6.3578, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3045\n","Loss =  tensor(5.7386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3046\n","Loss =  tensor(5.5170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3047\n","Loss =  tensor(6.1766, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3048\n","Loss =  tensor(7.1687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3049\n","Loss =  tensor(6.2743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3050\n","Loss =  tensor(7.9880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3051\n","Loss =  tensor(6.8436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3052\n","Loss =  tensor(6.5769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3053\n","Loss =  tensor(6.6109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3054\n","Loss =  tensor(6.6806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3055\n","Loss =  tensor(7.0800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3056\n","Loss =  tensor(6.7190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3057\n","Loss =  tensor(5.7180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3058\n","Loss =  tensor(7.9910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3059\n","Loss =  tensor(6.9982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3060\n","Loss =  tensor(7.4983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3061\n","Loss =  tensor(6.4411, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3062\n","Loss =  tensor(7.1371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3063\n","Loss =  tensor(6.3704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3064\n","Loss =  tensor(6.3481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3065\n","Loss =  tensor(5.9128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3066\n","Loss =  tensor(6.0781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3067\n","Loss =  tensor(6.3304, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3068\n","Loss =  tensor(6.9133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3069\n","Loss =  tensor(6.0211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3070\n","Loss =  tensor(6.2633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3071\n","Loss =  tensor(6.2768, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3072\n","Loss =  tensor(7.8144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3073\n","Loss =  tensor(7.0314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3074\n","Loss =  tensor(5.7480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3075\n","Loss =  tensor(6.2845, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3076\n","Loss =  tensor(5.9614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3077\n","Loss =  tensor(5.8116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3078\n","Loss =  tensor(6.0155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3079\n","Loss =  tensor(6.3829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3080\n","Loss =  tensor(6.7964, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3081\n","Loss =  tensor(5.7664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3082\n","Loss =  tensor(7.1214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3083\n","Loss =  tensor(6.9977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3084\n","Loss =  tensor(5.6711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3085\n","Loss =  tensor(6.0452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3086\n","Loss =  tensor(7.0874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3087\n","Loss =  tensor(6.7621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3088\n","Loss =  tensor(6.9949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3089\n","Loss =  tensor(6.2992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3090\n","Loss =  tensor(5.8753, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3091\n","Loss =  tensor(6.3449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3092\n","Loss =  tensor(6.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3093\n","Loss =  tensor(6.5815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3094\n","Loss =  tensor(6.3843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3095\n","Loss =  tensor(5.6095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3096\n","Loss =  tensor(6.6448, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3097\n","Loss =  tensor(6.5331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3098\n","Loss =  tensor(5.8207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3099\n","Loss =  tensor(7.0436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3100\n","Loss =  tensor(5.2599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3101\n","Loss =  tensor(7.0893, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3102\n","Loss =  tensor(6.2486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3103\n","Loss =  tensor(6.0443, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3104\n","Loss =  tensor(7.1363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3105\n","Loss =  tensor(5.9574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3106\n","Loss =  tensor(5.8803, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3107\n","Loss =  tensor(6.7959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3108\n","Loss =  tensor(4.8802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3109\n","Loss =  tensor(5.4989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3110\n","Loss =  tensor(5.9377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3111\n","Loss =  tensor(6.3842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3112\n","Loss =  tensor(5.6351, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3113\n","Loss =  tensor(6.4060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3114\n","Loss =  tensor(6.1009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3115\n","Loss =  tensor(6.3910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3116\n","Loss =  tensor(5.0722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3117\n","Loss =  tensor(7.9549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3118\n","Loss =  tensor(5.7124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3119\n","Loss =  tensor(5.8965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3120\n","Loss =  tensor(5.3927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3121\n","Loss =  tensor(5.8494, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3122\n","Loss =  tensor(6.1454, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3123\n","Loss =  tensor(5.6407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3124\n","Loss =  tensor(6.4232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3125\n","Loss =  tensor(5.1750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3126\n","Loss =  tensor(6.1382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3127\n","Loss =  tensor(6.3355, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3128\n","Loss =  tensor(5.8931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3129\n","Loss =  tensor(6.2590, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3130\n","Loss =  tensor(5.6209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3131\n","Loss =  tensor(5.2570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3132\n","Loss =  tensor(7.3752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3133\n","Loss =  tensor(5.5119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3134\n","Loss =  tensor(4.9608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3135\n","Loss =  tensor(7.0939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3136\n","Loss =  tensor(6.3276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3137\n","Loss =  tensor(7.4716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3138\n","Loss =  tensor(7.2247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3139\n","Loss =  tensor(6.3326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3140\n","Loss =  tensor(6.0814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3141\n","Loss =  tensor(5.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3142\n","Loss =  tensor(5.3420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3143\n","Loss =  tensor(5.9859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3144\n","Loss =  tensor(5.7673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3145\n","Loss =  tensor(5.4907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3146\n","Loss =  tensor(5.5577, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3147\n","Loss =  tensor(6.0116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3148\n","Loss =  tensor(2.8966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3149\n","Loss =  tensor(5.6085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3150\n","Loss =  tensor(5.1620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3151\n","Loss =  tensor(6.2598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3152\n","Loss =  tensor(5.5391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3153\n","Loss =  tensor(5.1362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3154\n","Loss =  tensor(5.5505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3155\n","Loss =  tensor(5.7404, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3156\n","Loss =  tensor(6.1223, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3157\n","Loss =  tensor(6.5678, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3158\n","Loss =  tensor(6.7241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3159\n","Loss =  tensor(4.7297, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3160\n","Loss =  tensor(5.8781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3161\n","Loss =  tensor(7.4882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3162\n","Loss =  tensor(4.4853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3163\n","Loss =  tensor(6.1839, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3164\n","Loss =  tensor(5.5579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3165\n","Loss =  tensor(5.3457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3166\n","Loss =  tensor(5.4393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3167\n","Loss =  tensor(5.8486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3168\n","Loss =  tensor(6.9471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3169\n","Loss =  tensor(5.5800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3170\n","Loss =  tensor(5.4015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3171\n","Loss =  tensor(5.0877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3172\n","Loss =  tensor(6.3162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3173\n","Loss =  tensor(5.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3174\n","Loss =  tensor(4.9705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3175\n","Loss =  tensor(6.4784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3176\n","Loss =  tensor(5.6964, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3177\n","Loss =  tensor(6.7526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3178\n","Loss =  tensor(5.2914, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3179\n","Loss =  tensor(5.8504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3180\n","Loss =  tensor(5.9294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3181\n","Loss =  tensor(5.6817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3182\n","Loss =  tensor(6.8941, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3183\n","Loss =  tensor(6.3560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3184\n","Loss =  tensor(5.2118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3185\n","Loss =  tensor(4.9626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3186\n","Loss =  tensor(5.9232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3187\n","Loss =  tensor(5.8126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3188\n","Loss =  tensor(6.1095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3189\n","Loss =  tensor(6.5859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3190\n","Loss =  tensor(6.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3191\n","Loss =  tensor(5.8881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3192\n","Loss =  tensor(5.2487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3193\n","Loss =  tensor(5.7059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3194\n","Loss =  tensor(5.7746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3195\n","Loss =  tensor(5.6705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3196\n","Loss =  tensor(5.4099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3197\n","Loss =  tensor(5.4301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3198\n","Loss =  tensor(4.1624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3199\n","Loss =  tensor(6.4296, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3200\n","Loss =  tensor(6.3226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3201\n","Loss =  tensor(5.6827, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3202\n","Loss =  tensor(5.2610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3203\n","Loss =  tensor(5.2924, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3204\n","Loss =  tensor(5.7873, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3205\n","Loss =  tensor(6.2019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3206\n","Loss =  tensor(4.8790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3207\n","Loss =  tensor(6.0133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3208\n","Loss =  tensor(5.5051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3209\n","Loss =  tensor(5.1748, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3210\n","Loss =  tensor(4.9474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3211\n","Loss =  tensor(5.5190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3212\n","Loss =  tensor(5.7919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3213\n","Loss =  tensor(5.8581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3214\n","Loss =  tensor(4.9843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3215\n","Loss =  tensor(6.1684, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3216\n","Loss =  tensor(5.2599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3217\n","Loss =  tensor(5.8028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3218\n","Loss =  tensor(6.0811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3219\n","Loss =  tensor(5.9822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3220\n","Loss =  tensor(5.0247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3221\n","Loss =  tensor(6.8389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3222\n","Loss =  tensor(5.7817, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3223\n","Loss =  tensor(6.2161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3224\n","Loss =  tensor(6.3485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3225\n","Loss =  tensor(6.2240, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3226\n","Loss =  tensor(5.9271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3227\n","Loss =  tensor(5.4071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3228\n","Loss =  tensor(6.5633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3229\n","Loss =  tensor(4.5812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3230\n","Loss =  tensor(5.6879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3231\n","Loss =  tensor(3.9693, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3232\n","Loss =  tensor(6.1871, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3233\n","Loss =  tensor(5.2380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3234\n","Loss =  tensor(5.4806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3235\n","Loss =  tensor(4.5269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3236\n","Loss =  tensor(5.8951, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3237\n","Loss =  tensor(6.1361, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3238\n","Loss =  tensor(6.0824, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3239\n","Loss =  tensor(5.6166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3240\n","Loss =  tensor(6.1279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3241\n","Loss =  tensor(5.6162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3242\n","Loss =  tensor(5.8504, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3243\n","Loss =  tensor(4.9298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3244\n","Loss =  tensor(5.4981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3245\n","Loss =  tensor(4.9741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3246\n","Loss =  tensor(5.5881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3247\n","Loss =  tensor(5.8687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3248\n","Loss =  tensor(4.5971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3249\n","Loss =  tensor(5.2894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3250\n","Loss =  tensor(5.6583, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3251\n","Loss =  tensor(4.6596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3252\n","Loss =  tensor(4.9071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3253\n","Loss =  tensor(5.7895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3254\n","Loss =  tensor(6.6106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3255\n","Loss =  tensor(5.0644, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3256\n","Loss =  tensor(4.7823, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3257\n","Loss =  tensor(4.7785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3258\n","Loss =  tensor(5.6209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3259\n","Loss =  tensor(5.7216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3260\n","Loss =  tensor(5.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3261\n","Loss =  tensor(5.7730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3262\n","Loss =  tensor(4.2637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3263\n","Loss =  tensor(5.4605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3264\n","Loss =  tensor(5.6769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3265\n","Loss =  tensor(4.3773, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3266\n","Loss =  tensor(5.0835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3267\n","Loss =  tensor(5.1885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  3268\n","Loss =  tensor(4.8142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  3269\n","Loss =  tensor(7.7066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3270\n","Loss =  tensor(5.7031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3271\n","Loss =  tensor(5.6851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3272\n","Loss =  tensor(6.1782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3273\n","Loss =  tensor(5.3971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3274\n","Loss =  tensor(5.3186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3275\n","Loss =  tensor(6.5948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3276\n","Loss =  tensor(5.5642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3277\n","Loss =  tensor(5.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3278\n","Loss =  tensor(6.5898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3279\n","Loss =  tensor(5.0411, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3280\n","Loss =  tensor(5.0614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3281\n","Loss =  tensor(4.2680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3282\n","Loss =  tensor(5.4410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3283\n","Loss =  tensor(5.6229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3284\n","Loss =  tensor(5.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3285\n","Loss =  tensor(4.9932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3286\n","Loss =  tensor(5.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3287\n","Loss =  tensor(6.2671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3288\n","Loss =  tensor(5.7946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3289\n","Loss =  tensor(5.3185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3290\n","Loss =  tensor(5.6254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3291\n","Loss =  tensor(3.7422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3292\n","Loss =  tensor(5.0965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3293\n","Loss =  tensor(5.1407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3294\n","Loss =  tensor(4.7673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3295\n","Loss =  tensor(4.2397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3296\n","Loss =  tensor(4.9241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3297\n","Loss =  tensor(5.2637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3298\n","Loss =  tensor(5.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3299\n","Loss =  tensor(4.0158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3300\n","Loss =  tensor(5.2562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3301\n","Loss =  tensor(5.1264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3302\n","Loss =  tensor(5.4080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3303\n","Loss =  tensor(5.2983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3304\n","Loss =  tensor(5.2516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3305\n","Loss =  tensor(5.3198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3306\n","Loss =  tensor(5.7280, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3307\n","Loss =  tensor(4.3022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3308\n","Loss =  tensor(5.0451, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3309\n","Loss =  tensor(4.8511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  3310\n","Loss =  tensor(4.8296, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3311\n","Loss =  tensor(4.9565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3312\n","Loss =  tensor(4.0295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3313\n","Loss =  tensor(5.6102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3314\n","Loss =  tensor(5.3209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3315\n","Loss =  tensor(4.8603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3316\n","Loss =  tensor(4.5413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3317\n","Loss =  tensor(4.5902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3318\n","Loss =  tensor(6.0186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3319\n","Loss =  tensor(3.2348, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3320\n","Loss =  tensor(5.0589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3321\n","Loss =  tensor(4.8988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3322\n","Loss =  tensor(5.0909, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3323\n","Loss =  tensor(5.6094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3324\n","Loss =  tensor(4.7881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3325\n","Loss =  tensor(5.1554, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3326\n","Loss =  tensor(5.4176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3327\n","Loss =  tensor(5.2212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3328\n","Loss =  tensor(4.9686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3329\n","Loss =  tensor(4.6538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3330\n","Loss =  tensor(4.8792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3331\n","Loss =  tensor(4.9305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3332\n","Loss =  tensor(4.2298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3333\n","Loss =  tensor(5.1379, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3334\n","Loss =  tensor(4.7108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3335\n","Loss =  tensor(4.4700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3336\n","Loss =  tensor(5.1308, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3337\n","Loss =  tensor(4.7378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3338\n","Loss =  tensor(5.0100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3339\n","Loss =  tensor(4.1389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3340\n","Loss =  tensor(5.3916, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3341\n","Loss =  tensor(4.1894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3342\n","Loss =  tensor(4.8499, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3343\n","Loss =  tensor(4.7423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3344\n","Loss =  tensor(3.6457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3345\n","Loss =  tensor(3.3461, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3346\n","Loss =  tensor(4.2736, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3347\n","Loss =  tensor(4.7535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3348\n","Loss =  tensor(5.3491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3349\n","Loss =  tensor(5.0695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3350\n","Loss =  tensor(5.0434, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3351\n","Loss =  tensor(4.9997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3352\n","Loss =  tensor(4.8239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3353\n","Loss =  tensor(4.9444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3354\n","Loss =  tensor(5.5521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3355\n","Loss =  tensor(4.8620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3356\n","Loss =  tensor(5.5639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3357\n","Loss =  tensor(4.0719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3358\n","Loss =  tensor(4.5414, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3359\n","Loss =  tensor(5.0296, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3360\n","Loss =  tensor(4.6043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3361\n","Loss =  tensor(4.3257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3362\n","Loss =  tensor(4.0378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3363\n","Loss =  tensor(3.8514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3364\n","Loss =  tensor(5.1597, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3365\n","Loss =  tensor(4.6315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3366\n","Loss =  tensor(5.4272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3367\n","Loss =  tensor(5.3931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3368\n","Loss =  tensor(3.8718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3369\n","Loss =  tensor(5.4434, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3370\n","Loss =  tensor(4.7744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3371\n","Loss =  tensor(4.8937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3372\n","Loss =  tensor(4.2178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3373\n","Loss =  tensor(4.6068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3374\n","Loss =  tensor(5.1821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3375\n","Loss =  tensor(4.2093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3376\n","Loss =  tensor(4.3902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3377\n","Loss =  tensor(4.5930, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3378\n","Loss =  tensor(4.2550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3379\n","Loss =  tensor(4.8486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3380\n","Loss =  tensor(4.5593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3381\n","Loss =  tensor(4.5318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3382\n","Loss =  tensor(5.3591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3383\n","Loss =  tensor(4.3025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3384\n","Loss =  tensor(5.7479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3385\n","Loss =  tensor(4.4034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3386\n","Loss =  tensor(4.9203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3387\n","Loss =  tensor(4.7225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3388\n","Loss =  tensor(4.6801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3389\n","Loss =  tensor(4.6116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3390\n","Loss =  tensor(4.3978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3391\n","Loss =  tensor(4.5775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3392\n","Loss =  tensor(4.5802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3393\n","Loss =  tensor(4.1342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3394\n","Loss =  tensor(4.4365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3395\n","Loss =  tensor(5.5788, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  3396\n","Loss =  tensor(4.5447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3397\n","Loss =  tensor(4.3756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3398\n","Loss =  tensor(4.6968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3399\n","Loss =  tensor(3.7910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3400\n","Loss =  tensor(4.7321, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3401\n","Loss =  tensor(4.6799, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3402\n","Loss =  tensor(4.5131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3403\n","Loss =  tensor(4.7178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3404\n","Loss =  tensor(5.2373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3405\n","Loss =  tensor(3.7988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3406\n","Loss =  tensor(4.5342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3407\n","Loss =  tensor(4.5905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3408\n","Loss =  tensor(4.0852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3409\n","Loss =  tensor(5.6618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3410\n","Loss =  tensor(4.9346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3411\n","Loss =  tensor(4.4403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3412\n","Loss =  tensor(4.4462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3413\n","Loss =  tensor(4.9487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3414\n","Loss =  tensor(3.8339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3415\n","Loss =  tensor(3.4577, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3416\n","Loss =  tensor(4.1530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3417\n","Loss =  tensor(5.0466, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3418\n","Loss =  tensor(5.2334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3419\n","Loss =  tensor(5.8287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3420\n","Loss =  tensor(4.9761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3421\n","Loss =  tensor(5.4449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3422\n","Loss =  tensor(3.3372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3423\n","Loss =  tensor(3.8622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3424\n","Loss =  tensor(4.2634, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3425\n","Loss =  tensor(4.2830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3426\n","Loss =  tensor(4.8902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3427\n","Loss =  tensor(4.0866, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3428\n","Loss =  tensor(4.1920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3429\n","Loss =  tensor(3.9690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3430\n","Loss =  tensor(4.7204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3431\n","Loss =  tensor(4.3570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3432\n","Loss =  tensor(3.4052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3433\n","Loss =  tensor(4.0350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3434\n","Loss =  tensor(5.2044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3435\n","Loss =  tensor(4.6747, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3436\n","Loss =  tensor(4.5331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3437\n","Loss =  tensor(4.6347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3438\n","Loss =  tensor(4.1559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3439\n","Loss =  tensor(3.2894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3440\n","Loss =  tensor(4.8545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3441\n","Loss =  tensor(3.8229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3442\n","Loss =  tensor(4.9527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3443\n","Loss =  tensor(5.3245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3444\n","Loss =  tensor(4.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3445\n","Loss =  tensor(4.5020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3446\n","Loss =  tensor(3.8328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3447\n","Loss =  tensor(3.5409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3448\n","Loss =  tensor(3.8106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3449\n","Loss =  tensor(4.3953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  3450\n","Loss =  tensor(4.5341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3451\n","Loss =  tensor(4.5967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3452\n","Loss =  tensor(4.4140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3453\n","Loss =  tensor(3.9540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3454\n","Loss =  tensor(3.6663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3455\n","Loss =  tensor(4.9220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3456\n","Loss =  tensor(4.5204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3457\n","Loss =  tensor(4.7038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3458\n","Loss =  tensor(3.9103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3459\n","Loss =  tensor(4.8944, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3460\n","Loss =  tensor(3.6473, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3461\n","Loss =  tensor(3.5472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3462\n","Loss =  tensor(4.2976, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3463\n","Loss =  tensor(3.6996, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3464\n","Loss =  tensor(3.7220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3465\n","Loss =  tensor(4.1401, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3466\n","Loss =  tensor(4.8346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3467\n","Loss =  tensor(3.5245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3468\n","Loss =  tensor(3.5729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3469\n","Loss =  tensor(4.2778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3470\n","Loss =  tensor(3.4844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3471\n","Loss =  tensor(3.9796, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3472\n","Loss =  tensor(4.3399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3473\n","Loss =  tensor(3.8157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3474\n","Loss =  tensor(4.4220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3475\n","Loss =  tensor(3.7809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3476\n","Loss =  tensor(3.6700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3477\n","Loss =  tensor(3.8452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3478\n","Loss =  tensor(4.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3479\n","Loss =  tensor(3.3902, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3480\n","Loss =  tensor(3.9235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3481\n","Loss =  tensor(3.7263, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3482\n","Loss =  tensor(4.5634, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3483\n","Loss =  tensor(3.7162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3484\n","Loss =  tensor(3.7599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3485\n","Loss =  tensor(4.2642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3486\n","Loss =  tensor(4.8106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3487\n","Loss =  tensor(3.5245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3488\n","Loss =  tensor(4.3700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3489\n","Loss =  tensor(4.3288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3490\n","Loss =  tensor(4.7572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3491\n","Loss =  tensor(4.0768, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3492\n","Loss =  tensor(4.2188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3493\n","Loss =  tensor(3.2975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3494\n","Loss =  tensor(4.3650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3495\n","Loss =  tensor(3.5819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3496\n","Loss =  tensor(3.7981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3497\n","Loss =  tensor(5.0987, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3498\n","Loss =  tensor(3.2311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3499\n","Loss =  tensor(3.7124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3500\n","Loss =  tensor(3.8043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3501\n","Loss =  tensor(4.3975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3502\n","Loss =  tensor(4.2211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3503\n","Loss =  tensor(3.6302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3504\n","Loss =  tensor(4.2838, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3505\n","Loss =  tensor(3.6934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3506\n","Loss =  tensor(4.0111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3507\n","Loss =  tensor(3.4118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3508\n","Loss =  tensor(4.0695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3509\n","Loss =  tensor(4.3159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3510\n","Loss =  tensor(3.9180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3511\n","Loss =  tensor(3.6512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3512\n","Loss =  tensor(4.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3513\n","Loss =  tensor(3.9825, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3514\n","Loss =  tensor(4.1192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3515\n","Loss =  tensor(3.8351, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3516\n","Loss =  tensor(4.5277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3517\n","Loss =  tensor(4.1937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3518\n","Loss =  tensor(2.8996, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3519\n","Loss =  tensor(3.4445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3520\n","Loss =  tensor(4.5735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3521\n","Loss =  tensor(2.7908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3522\n","Loss =  tensor(3.1075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3523\n","Loss =  tensor(4.3670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3524\n","Loss =  tensor(3.8856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3525\n","Loss =  tensor(3.2320, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3526\n","Loss =  tensor(3.5092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3527\n","Loss =  tensor(3.4003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3528\n","Loss =  tensor(3.5757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3529\n","Loss =  tensor(3.4757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3530\n","Loss =  tensor(4.4208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3531\n","Loss =  tensor(4.1272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3532\n","Loss =  tensor(4.4216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3533\n","Loss =  tensor(3.7988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3534\n","Loss =  tensor(3.5515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3535\n","Loss =  tensor(4.1920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3536\n","Loss =  tensor(3.6657, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3537\n","Loss =  tensor(4.7018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  3538\n","Loss =  tensor(4.3119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3539\n","Loss =  tensor(3.5920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3540\n","Loss =  tensor(4.3690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3541\n","Loss =  tensor(3.8437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3542\n","Loss =  tensor(3.2105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3543\n","Loss =  tensor(3.1873, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3544\n","Loss =  tensor(4.5685, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3545\n","Loss =  tensor(3.8700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3546\n","Loss =  tensor(3.9289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3547\n","Loss =  tensor(4.0223, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3548\n","Loss =  tensor(3.3836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3549\n","Loss =  tensor(3.2953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3550\n","Loss =  tensor(4.2323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3551\n","Loss =  tensor(3.4249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3552\n","Loss =  tensor(3.3533, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3553\n","Loss =  tensor(4.5117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3554\n","Loss =  tensor(4.2347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3555\n","Loss =  tensor(3.4746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3556\n","Loss =  tensor(2.9529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3557\n","Loss =  tensor(3.6591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3558\n","Loss =  tensor(3.2779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3559\n","Loss =  tensor(3.7143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3560\n","Loss =  tensor(4.5746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3561\n","Loss =  tensor(3.3579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3562\n","Loss =  tensor(3.8606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3563\n","Loss =  tensor(3.9535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3564\n","Loss =  tensor(3.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3565\n","Loss =  tensor(3.4724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3566\n","Loss =  tensor(3.3645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3567\n","Loss =  tensor(4.4178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3568\n","Loss =  tensor(4.2593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3569\n","Loss =  tensor(3.5397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3570\n","Loss =  tensor(4.3794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3571\n","Loss =  tensor(3.6874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3572\n","Loss =  tensor(3.9170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3573\n","Loss =  tensor(3.0523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3574\n","Loss =  tensor(4.0979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3575\n","Loss =  tensor(4.0797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3576\n","Loss =  tensor(3.5678, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3577\n","Loss =  tensor(3.8226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3578\n","Loss =  tensor(3.7223, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3579\n","Loss =  tensor(3.4235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3580\n","Loss =  tensor(3.5120, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3581\n","Loss =  tensor(3.6029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3582\n","Loss =  tensor(3.4945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3583\n","Loss =  tensor(3.7015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3584\n","Loss =  tensor(3.5945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3585\n","Loss =  tensor(3.8343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3586\n","Loss =  tensor(3.0991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3587\n","Loss =  tensor(3.3090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3588\n","Loss =  tensor(3.6682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3589\n","Loss =  tensor(3.1771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3590\n","Loss =  tensor(3.6222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3591\n","Loss =  tensor(3.9700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3592\n","Loss =  tensor(3.6874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3593\n","Loss =  tensor(3.6555, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3594\n","Loss =  tensor(3.5724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3595\n","Loss =  tensor(3.6358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3596\n","Loss =  tensor(2.9104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3597\n","Loss =  tensor(3.5772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3598\n","Loss =  tensor(3.7017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3599\n","Loss =  tensor(3.3792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3600\n","Loss =  tensor(3.1188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3601\n","Loss =  tensor(3.9435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3602\n","Loss =  tensor(4.1610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3603\n","Loss =  tensor(3.9222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3604\n","Loss =  tensor(3.7421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3605\n","Loss =  tensor(3.6559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3606\n","Loss =  tensor(3.7771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3607\n","Loss =  tensor(3.7991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3608\n","Loss =  tensor(3.7273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3609\n","Loss =  tensor(4.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3610\n","Loss =  tensor(3.1815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3611\n","Loss =  tensor(3.9438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3612\n","Loss =  tensor(3.3879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3613\n","Loss =  tensor(3.7517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3614\n","Loss =  tensor(3.5004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3615\n","Loss =  tensor(4.0722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3616\n","Loss =  tensor(3.4638, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3617\n","Loss =  tensor(2.5501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3618\n","Loss =  tensor(4.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3619\n","Loss =  tensor(2.5347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3620\n","Loss =  tensor(3.8439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3621\n","Loss =  tensor(3.6216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3622\n","Loss =  tensor(3.7339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3623\n","Loss =  tensor(3.2208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3624\n","Loss =  tensor(3.4857, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3625\n","Loss =  tensor(3.4460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3626\n","Loss =  tensor(3.2741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3627\n","Loss =  tensor(3.6983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3628\n","Loss =  tensor(2.9422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3629\n","Loss =  tensor(3.4519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3630\n","Loss =  tensor(3.3016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3631\n","Loss =  tensor(2.9725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3632\n","Loss =  tensor(2.3963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3633\n","Loss =  tensor(3.4883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3634\n","Loss =  tensor(3.3020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3635\n","Loss =  tensor(2.8709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3636\n","Loss =  tensor(3.0312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3637\n","Loss =  tensor(3.0875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3638\n","Loss =  tensor(3.1366, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3639\n","Loss =  tensor(3.7862, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3640\n","Loss =  tensor(2.9236, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3641\n","Loss =  tensor(2.9280, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3642\n","Loss =  tensor(3.1398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3643\n","Loss =  tensor(3.8265, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3644\n","Loss =  tensor(2.9882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3645\n","Loss =  tensor(3.1422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3646\n","Loss =  tensor(2.9239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3647\n","Loss =  tensor(3.8026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3648\n","Loss =  tensor(3.2162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3649\n","Loss =  tensor(3.4981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3650\n","Loss =  tensor(2.5274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3651\n","Loss =  tensor(3.3683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3652\n","Loss =  tensor(3.5341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3653\n","Loss =  tensor(2.8818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3654\n","Loss =  tensor(2.9575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3655\n","Loss =  tensor(3.9931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3656\n","Loss =  tensor(3.0982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3657\n","Loss =  tensor(3.9890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3658\n","Loss =  tensor(3.3862, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3659\n","Loss =  tensor(3.8180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3660\n","Loss =  tensor(3.0420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3661\n","Loss =  tensor(3.7276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3662\n","Loss =  tensor(3.5982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3663\n","Loss =  tensor(2.6025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3664\n","Loss =  tensor(3.2476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3665\n","Loss =  tensor(2.4906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3666\n","Loss =  tensor(3.9195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3667\n","Loss =  tensor(2.8399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3668\n","Loss =  tensor(2.8612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3669\n","Loss =  tensor(2.9797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3670\n","Loss =  tensor(2.9787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3671\n","Loss =  tensor(2.9687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3672\n","Loss =  tensor(2.7559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  3673\n","Loss =  tensor(3.5389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3674\n","Loss =  tensor(3.8072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3675\n","Loss =  tensor(2.7162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3676\n","Loss =  tensor(3.7497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3677\n","Loss =  tensor(3.3592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3678\n","Loss =  tensor(3.3493, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3679\n","Loss =  tensor(3.6398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3680\n","Loss =  tensor(3.0644, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3681\n","Loss =  tensor(3.2962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3682\n","Loss =  tensor(3.3713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3683\n","Loss =  tensor(3.1136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3684\n","Loss =  tensor(3.0713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3685\n","Loss =  tensor(2.9221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3686\n","Loss =  tensor(2.6722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3687\n","Loss =  tensor(3.6600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3688\n","Loss =  tensor(2.6718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3689\n","Loss =  tensor(3.1168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3690\n","Loss =  tensor(3.4032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3691\n","Loss =  tensor(3.0939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3692\n","Loss =  tensor(3.1343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3693\n","Loss =  tensor(3.6212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3694\n","Loss =  tensor(3.5673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3695\n","Loss =  tensor(3.7382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3696\n","Loss =  tensor(3.8092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3697\n","Loss =  tensor(3.5316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3698\n","Loss =  tensor(3.2140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3699\n","Loss =  tensor(2.7553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3700\n","Loss =  tensor(3.1230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3701\n","Loss =  tensor(3.3931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3702\n","Loss =  tensor(3.0343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3703\n","Loss =  tensor(2.8452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3704\n","Loss =  tensor(2.7963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3705\n","Loss =  tensor(3.0326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3706\n","Loss =  tensor(2.9703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3707\n","Loss =  tensor(3.3295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3708\n","Loss =  tensor(3.2253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3709\n","Loss =  tensor(2.9587, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3710\n","Loss =  tensor(3.4508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3711\n","Loss =  tensor(2.9009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3712\n","Loss =  tensor(2.9028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3713\n","Loss =  tensor(3.3872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3714\n","Loss =  tensor(2.7045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3715\n","Loss =  tensor(2.8151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3716\n","Loss =  tensor(2.5903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3717\n","Loss =  tensor(3.0515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3718\n","Loss =  tensor(3.5310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3719\n","Loss =  tensor(2.7901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3720\n","Loss =  tensor(2.8671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3721\n","Loss =  tensor(3.3783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3722\n","Loss =  tensor(2.2939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3723\n","Loss =  tensor(2.9761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3724\n","Loss =  tensor(2.6249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3725\n","Loss =  tensor(2.9141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3726\n","Loss =  tensor(3.4877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3727\n","Loss =  tensor(3.0575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3728\n","Loss =  tensor(3.0158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3729\n","Loss =  tensor(2.7992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3730\n","Loss =  tensor(3.0608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3731\n","Loss =  tensor(3.1349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3732\n","Loss =  tensor(3.2260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3733\n","Loss =  tensor(3.2742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3734\n","Loss =  tensor(3.0551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3735\n","Loss =  tensor(3.2351, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3736\n","Loss =  tensor(3.1372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3737\n","Loss =  tensor(2.7697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3738\n","Loss =  tensor(2.9472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3739\n","Loss =  tensor(3.2798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  3740\n","Loss =  tensor(3.2579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3741\n","Loss =  tensor(3.1004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3742\n","Loss =  tensor(2.4645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3743\n","Loss =  tensor(3.0913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3744\n","Loss =  tensor(2.7595, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3745\n","Loss =  tensor(2.8048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3746\n","Loss =  tensor(2.5042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3747\n","Loss =  tensor(2.9335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3748\n","Loss =  tensor(3.1141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3749\n","Loss =  tensor(2.1124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3750\n","Loss =  tensor(2.9093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3751\n","Loss =  tensor(2.8017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3752\n","Loss =  tensor(2.6759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3753\n","Loss =  tensor(2.5215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3754\n","Loss =  tensor(3.4907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3755\n","Loss =  tensor(3.2606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3756\n","Loss =  tensor(2.5491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3757\n","Loss =  tensor(2.7814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3758\n","Loss =  tensor(2.6062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3759\n","Loss =  tensor(2.6910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3760\n","Loss =  tensor(3.3063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3761\n","Loss =  tensor(2.5796, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3762\n","Loss =  tensor(2.4051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3763\n","Loss =  tensor(2.6617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3764\n","Loss =  tensor(2.6184, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3765\n","Loss =  tensor(3.1172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3766\n","Loss =  tensor(3.2822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3767\n","Loss =  tensor(2.8908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3768\n","Loss =  tensor(2.4709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3769\n","Loss =  tensor(3.0343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3770\n","Loss =  tensor(3.1163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3771\n","Loss =  tensor(2.9381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3772\n","Loss =  tensor(3.1832, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3773\n","Loss =  tensor(2.7398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3774\n","Loss =  tensor(2.6535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3775\n","Loss =  tensor(2.8111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3776\n","Loss =  tensor(3.4527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3777\n","Loss =  tensor(3.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3778\n","Loss =  tensor(2.3787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3779\n","Loss =  tensor(2.2843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3780\n","Loss =  tensor(2.6458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3781\n","Loss =  tensor(3.2849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3782\n","Loss =  tensor(2.8816, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3783\n","Loss =  tensor(3.6123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3784\n","Loss =  tensor(2.8701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3785\n","Loss =  tensor(2.8787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3786\n","Loss =  tensor(2.6615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3787\n","Loss =  tensor(2.3921, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3788\n","Loss =  tensor(2.3715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3789\n","Loss =  tensor(2.5548, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3790\n","Loss =  tensor(3.2705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3791\n","Loss =  tensor(2.9239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3792\n","Loss =  tensor(2.9220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3793\n","Loss =  tensor(2.8867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3794\n","Loss =  tensor(3.5009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3795\n","Loss =  tensor(2.3570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3796\n","Loss =  tensor(3.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3797\n","Loss =  tensor(2.3640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3798\n","Loss =  tensor(2.7735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3799\n","Loss =  tensor(2.3262, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3800\n","Loss =  tensor(1.8381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3801\n","Loss =  tensor(2.3852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3802\n","Loss =  tensor(2.8497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3803\n","Loss =  tensor(2.5927, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3804\n","Loss =  tensor(2.3319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3805\n","Loss =  tensor(2.2636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3806\n","Loss =  tensor(2.8323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3807\n","Loss =  tensor(2.9756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3808\n","Loss =  tensor(2.7091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3809\n","Loss =  tensor(2.2383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3810\n","Loss =  tensor(2.5819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3811\n","Loss =  tensor(2.5343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3812\n","Loss =  tensor(2.7098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3813\n","Loss =  tensor(2.0917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3814\n","Loss =  tensor(3.2379, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3815\n","Loss =  tensor(2.8472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3816\n","Loss =  tensor(2.6943, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3817\n","Loss =  tensor(3.0656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3818\n","Loss =  tensor(2.6867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3819\n","Loss =  tensor(2.6417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3820\n","Loss =  tensor(3.0564, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3821\n","Loss =  tensor(2.2232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3822\n","Loss =  tensor(2.9272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3823\n","Loss =  tensor(2.0439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3824\n","Loss =  tensor(2.2226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3825\n","Loss =  tensor(3.0239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3826\n","Loss =  tensor(2.4511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3827\n","Loss =  tensor(2.6492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3828\n","Loss =  tensor(2.5289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3829\n","Loss =  tensor(1.6282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3830\n","Loss =  tensor(2.3476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3831\n","Loss =  tensor(2.4097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3832\n","Loss =  tensor(2.1447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3833\n","Loss =  tensor(2.2197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3834\n","Loss =  tensor(2.4180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3835\n","Loss =  tensor(2.3368, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3836\n","Loss =  tensor(2.2574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3837\n","Loss =  tensor(2.5940, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3838\n","Loss =  tensor(2.3371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3839\n","Loss =  tensor(2.2146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3840\n","Loss =  tensor(2.4339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3841\n","Loss =  tensor(2.3340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3842\n","Loss =  tensor(1.9806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3843\n","Loss =  tensor(1.8228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3844\n","Loss =  tensor(2.5138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3845\n","Loss =  tensor(2.4628, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3846\n","Loss =  tensor(2.9369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3847\n","Loss =  tensor(2.3540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3848\n","Loss =  tensor(2.1784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3849\n","Loss =  tensor(2.3551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  3850\n","Loss =  tensor(2.4254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3851\n","Loss =  tensor(1.9889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3852\n","Loss =  tensor(2.6931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3853\n","Loss =  tensor(2.2806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3854\n","Loss =  tensor(2.4891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3855\n","Loss =  tensor(2.8387, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3856\n","Loss =  tensor(1.8365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3857\n","Loss =  tensor(2.6042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3858\n","Loss =  tensor(2.7234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3859\n","Loss =  tensor(2.1372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3860\n","Loss =  tensor(2.2452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3861\n","Loss =  tensor(2.4722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3862\n","Loss =  tensor(2.6244, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3863\n","Loss =  tensor(2.8483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3864\n","Loss =  tensor(2.1143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3865\n","Loss =  tensor(2.6472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3866\n","Loss =  tensor(2.4592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3867\n","Loss =  tensor(2.3936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3868\n","Loss =  tensor(2.1766, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3869\n","Loss =  tensor(2.2874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3870\n","Loss =  tensor(1.8353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3871\n","Loss =  tensor(2.2445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3872\n","Loss =  tensor(2.3138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3873\n","Loss =  tensor(2.5181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  3874\n","Loss =  tensor(2.6210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3875\n","Loss =  tensor(1.7034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3876\n","Loss =  tensor(2.1038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3877\n","Loss =  tensor(1.9050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3878\n","Loss =  tensor(2.0801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3879\n","Loss =  tensor(2.2822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3880\n","Loss =  tensor(2.3476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3881\n","Loss =  tensor(2.4048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3882\n","Loss =  tensor(3.1224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3883\n","Loss =  tensor(2.5864, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3884\n","Loss =  tensor(2.3346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3885\n","Loss =  tensor(2.5114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3886\n","Loss =  tensor(2.3493, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3887\n","Loss =  tensor(2.1430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3888\n","Loss =  tensor(2.3921, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3889\n","Loss =  tensor(2.4305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3890\n","Loss =  tensor(2.6268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3891\n","Loss =  tensor(2.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3892\n","Loss =  tensor(2.3284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3893\n","Loss =  tensor(2.1742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3894\n","Loss =  tensor(2.2461, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3895\n","Loss =  tensor(1.6959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3896\n","Loss =  tensor(2.2108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3897\n","Loss =  tensor(2.1652, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3898\n","Loss =  tensor(2.7631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3899\n","Loss =  tensor(2.3677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3900\n","Loss =  tensor(2.2180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3901\n","Loss =  tensor(2.3522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3902\n","Loss =  tensor(2.2837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3903\n","Loss =  tensor(2.6542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3904\n","Loss =  tensor(2.3538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3905\n","Loss =  tensor(2.5387, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3906\n","Loss =  tensor(2.2026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3907\n","Loss =  tensor(2.2459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3908\n","Loss =  tensor(1.8958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3909\n","Loss =  tensor(2.2510, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3910\n","Loss =  tensor(2.3534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3911\n","Loss =  tensor(2.2986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3912\n","Loss =  tensor(2.2859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3913\n","Loss =  tensor(2.1325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3914\n","Loss =  tensor(2.3013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3915\n","Loss =  tensor(1.6519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3916\n","Loss =  tensor(2.2488, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3917\n","Loss =  tensor(2.0655, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3918\n","Loss =  tensor(2.1741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3919\n","Loss =  tensor(2.1420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3920\n","Loss =  tensor(1.9960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3921\n","Loss =  tensor(2.1032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3922\n","Loss =  tensor(2.2066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3923\n","Loss =  tensor(2.3932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3924\n","Loss =  tensor(2.1058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3925\n","Loss =  tensor(2.0874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3926\n","Loss =  tensor(1.9997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3927\n","Loss =  tensor(1.7951, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3928\n","Loss =  tensor(1.8248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3929\n","Loss =  tensor(1.9526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3930\n","Loss =  tensor(2.1268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3931\n","Loss =  tensor(2.3272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3932\n","Loss =  tensor(2.1329, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3933\n","Loss =  tensor(2.4925, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3934\n","Loss =  tensor(2.1177, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3935\n","Loss =  tensor(2.0321, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3936\n","Loss =  tensor(2.1190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3937\n","Loss =  tensor(2.1519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3938\n","Loss =  tensor(1.6403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3939\n","Loss =  tensor(2.3861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3940\n","Loss =  tensor(2.2552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3941\n","Loss =  tensor(2.0754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3942\n","Loss =  tensor(2.0340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3943\n","Loss =  tensor(2.3685, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3944\n","Loss =  tensor(2.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3945\n","Loss =  tensor(1.9860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3946\n","Loss =  tensor(1.9433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3947\n","Loss =  tensor(1.5219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3948\n","Loss =  tensor(1.7868, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3949\n","Loss =  tensor(2.0460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3950\n","Loss =  tensor(1.8717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3951\n","Loss =  tensor(1.7886, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3952\n","Loss =  tensor(2.2206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3953\n","Loss =  tensor(2.1341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3954\n","Loss =  tensor(1.6872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3955\n","Loss =  tensor(2.3346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3956\n","Loss =  tensor(1.9342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3957\n","Loss =  tensor(1.7227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3958\n","Loss =  tensor(2.3508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3959\n","Loss =  tensor(2.4752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3960\n","Loss =  tensor(1.9064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3961\n","Loss =  tensor(2.3067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3962\n","Loss =  tensor(2.2033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3963\n","Loss =  tensor(1.9860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3964\n","Loss =  tensor(1.6059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  3965\n","Loss =  tensor(2.3422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3966\n","Loss =  tensor(1.7573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3967\n","Loss =  tensor(1.6500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3968\n","Loss =  tensor(2.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3969\n","Loss =  tensor(1.8048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3970\n","Loss =  tensor(2.0666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3971\n","Loss =  tensor(1.8792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3972\n","Loss =  tensor(1.9029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3973\n","Loss =  tensor(1.8581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3974\n","Loss =  tensor(2.2500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3975\n","Loss =  tensor(1.7764, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3976\n","Loss =  tensor(1.5798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3977\n","Loss =  tensor(2.0475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3978\n","Loss =  tensor(1.6197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3979\n","Loss =  tensor(1.9176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3980\n","Loss =  tensor(1.8839, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3981\n","Loss =  tensor(2.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3982\n","Loss =  tensor(2.0602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3983\n","Loss =  tensor(2.2339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3984\n","Loss =  tensor(1.7846, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3985\n","Loss =  tensor(1.7993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3986\n","Loss =  tensor(1.8813, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3987\n","Loss =  tensor(2.3566, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3988\n","Loss =  tensor(1.9979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3989\n","Loss =  tensor(1.9572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3990\n","Loss =  tensor(2.0973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3991\n","Loss =  tensor(1.8299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3992\n","Loss =  tensor(2.0565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3993\n","Loss =  tensor(1.8215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3994\n","Loss =  tensor(1.9307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3995\n","Loss =  tensor(1.9440, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  3996\n","Loss =  tensor(2.1027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3997\n","Loss =  tensor(1.7394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3998\n","Loss =  tensor(1.7777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  3999\n","Loss =  tensor(1.6491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4000\n","Loss =  tensor(1.9138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4001\n","Loss =  tensor(1.6439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4002\n","Loss =  tensor(1.9405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4003\n","Loss =  tensor(1.5786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4004\n","Loss =  tensor(1.9631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4005\n","Loss =  tensor(1.7521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4006\n","Loss =  tensor(1.4712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4007\n","Loss =  tensor(1.6385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4008\n","Loss =  tensor(1.7879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4009\n","Loss =  tensor(2.0298, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4010\n","Loss =  tensor(1.6932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4011\n","Loss =  tensor(1.9062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4012\n","Loss =  tensor(1.8459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4013\n","Loss =  tensor(1.8731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4014\n","Loss =  tensor(1.7326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4015\n","Loss =  tensor(1.6776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4016\n","Loss =  tensor(1.8513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4017\n","Loss =  tensor(2.1908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4018\n","Loss =  tensor(1.6028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4019\n","Loss =  tensor(1.7017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4020\n","Loss =  tensor(1.8416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4021\n","Loss =  tensor(2.3009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4022\n","Loss =  tensor(2.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4023\n","Loss =  tensor(1.9153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4024\n","Loss =  tensor(2.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4025\n","Loss =  tensor(1.7751, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4026\n","Loss =  tensor(1.7405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4027\n","Loss =  tensor(1.8972, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4028\n","Loss =  tensor(1.8572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4029\n","Loss =  tensor(1.6307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4030\n","Loss =  tensor(1.9739, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4031\n","Loss =  tensor(1.7994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4032\n","Loss =  tensor(1.8133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4033\n","Loss =  tensor(1.6057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4034\n","Loss =  tensor(1.9503, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4035\n","Loss =  tensor(1.8712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4036\n","Loss =  tensor(1.8948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4037\n","Loss =  tensor(1.6108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4038\n","Loss =  tensor(1.5895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4039\n","Loss =  tensor(1.6159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4040\n","Loss =  tensor(1.7384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4041\n","Loss =  tensor(2.2052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4042\n","Loss =  tensor(1.7612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4043\n","Loss =  tensor(1.8282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4044\n","Loss =  tensor(1.4666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4045\n","Loss =  tensor(1.4034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4046\n","Loss =  tensor(1.9394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4047\n","Loss =  tensor(1.8818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4048\n","Loss =  tensor(1.8901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4049\n","Loss =  tensor(1.6275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4050\n","Loss =  tensor(1.5261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4051\n","Loss =  tensor(1.6203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  4052\n","Loss =  tensor(1.6745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4053\n","Loss =  tensor(1.8404, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4054\n","Loss =  tensor(1.8234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4055\n","Loss =  tensor(1.7095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4056\n","Loss =  tensor(2.1349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4057\n","Loss =  tensor(1.3090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4058\n","Loss =  tensor(1.7314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4059\n","Loss =  tensor(1.7155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4060\n","Loss =  tensor(1.8603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4061\n","Loss =  tensor(1.7303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4062\n","Loss =  tensor(1.6532, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4063\n","Loss =  tensor(1.9719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4064\n","Loss =  tensor(1.8325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4065\n","Loss =  tensor(1.6511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4066\n","Loss =  tensor(1.7452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4067\n","Loss =  tensor(1.6611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4068\n","Loss =  tensor(2.1048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4069\n","Loss =  tensor(1.8179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4070\n","Loss =  tensor(1.9782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4071\n","Loss =  tensor(1.5606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4072\n","Loss =  tensor(1.6671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4073\n","Loss =  tensor(1.3992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4074\n","Loss =  tensor(1.6043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4075\n","Loss =  tensor(1.7103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4076\n","Loss =  tensor(1.8456, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4077\n","Loss =  tensor(1.6262, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4078\n","Loss =  tensor(1.4355, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4079\n","Loss =  tensor(1.7496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4080\n","Loss =  tensor(1.8994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4081\n","Loss =  tensor(1.7854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4082\n","Loss =  tensor(1.6952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4083\n","Loss =  tensor(2.0336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4084\n","Loss =  tensor(1.8683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4085\n","Loss =  tensor(1.5499, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4086\n","Loss =  tensor(1.6230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4087\n","Loss =  tensor(1.7764, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4088\n","Loss =  tensor(1.9689, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4089\n","Loss =  tensor(1.7308, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4090\n","Loss =  tensor(1.4622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4091\n","Loss =  tensor(1.7049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4092\n","Loss =  tensor(1.5255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4093\n","Loss =  tensor(1.7998, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4094\n","Loss =  tensor(1.5973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4095\n","Loss =  tensor(1.5894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4096\n","Loss =  tensor(1.4388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4097\n","Loss =  tensor(1.6751, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4098\n","Loss =  tensor(1.9328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4099\n","Loss =  tensor(1.6983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4100\n","Loss =  tensor(1.6175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4101\n","Loss =  tensor(1.4721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4102\n","Loss =  tensor(1.6778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4103\n","Loss =  tensor(1.6710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4104\n","Loss =  tensor(2.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4105\n","Loss =  tensor(1.8080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4106\n","Loss =  tensor(1.4923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4107\n","Loss =  tensor(1.3815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4108\n","Loss =  tensor(1.5378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4109\n","Loss =  tensor(1.4652, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4110\n","Loss =  tensor(1.5775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4111\n","Loss =  tensor(1.5582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4112\n","Loss =  tensor(1.3455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4113\n","Loss =  tensor(1.5963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4114\n","Loss =  tensor(1.8343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4115\n","Loss =  tensor(1.8215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4116\n","Loss =  tensor(1.4350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4117\n","Loss =  tensor(1.4153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4118\n","Loss =  tensor(1.6326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4119\n","Loss =  tensor(1.6781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4120\n","Loss =  tensor(1.4740, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4121\n","Loss =  tensor(1.6913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4122\n","Loss =  tensor(1.7983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4123\n","Loss =  tensor(1.4631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4124\n","Loss =  tensor(1.4937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4125\n","Loss =  tensor(1.9616, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4126\n","Loss =  tensor(1.5396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4127\n","Loss =  tensor(1.4258, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4128\n","Loss =  tensor(1.7155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4129\n","Loss =  tensor(1.8805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4130\n","Loss =  tensor(1.5622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4131\n","Loss =  tensor(1.6384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4132\n","Loss =  tensor(1.6142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4133\n","Loss =  tensor(1.8386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4134\n","Loss =  tensor(1.8852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4135\n","Loss =  tensor(1.3085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4136\n","Loss =  tensor(1.6597, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4137\n","Loss =  tensor(1.8027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4138\n","Loss =  tensor(1.6526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4139\n","Loss =  tensor(1.3877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4140\n","Loss =  tensor(1.6999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4141\n","Loss =  tensor(1.5822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4142\n","Loss =  tensor(1.2537, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4143\n","Loss =  tensor(1.5215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4144\n","Loss =  tensor(1.5953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4145\n","Loss =  tensor(1.4251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4146\n","Loss =  tensor(1.5027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4147\n","Loss =  tensor(1.4739, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4148\n","Loss =  tensor(1.6969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4149\n","Loss =  tensor(1.5543, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4150\n","Loss =  tensor(1.3505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4151\n","Loss =  tensor(1.3164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4152\n","Loss =  tensor(1.6275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4153\n","Loss =  tensor(1.7222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4154\n","Loss =  tensor(1.0788, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4155\n","Loss =  tensor(1.6393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4156\n","Loss =  tensor(1.4755, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4157\n","Loss =  tensor(1.4506, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4158\n","Loss =  tensor(1.3929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4159\n","Loss =  tensor(1.4590, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4160\n","Loss =  tensor(1.5731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4161\n","Loss =  tensor(1.7271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4162\n","Loss =  tensor(1.4367, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4163\n","Loss =  tensor(1.5707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4164\n","Loss =  tensor(1.4607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4165\n","Loss =  tensor(1.5045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4166\n","Loss =  tensor(1.2004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4167\n","Loss =  tensor(1.3770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4168\n","Loss =  tensor(1.6306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4169\n","Loss =  tensor(1.2183, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4170\n","Loss =  tensor(1.4270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4171\n","Loss =  tensor(1.7069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4172\n","Loss =  tensor(1.4407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4173\n","Loss =  tensor(1.5930, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4174\n","Loss =  tensor(1.3802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4175\n","Loss =  tensor(1.6631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4176\n","Loss =  tensor(1.6013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4177\n","Loss =  tensor(1.5670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4178\n","Loss =  tensor(1.6683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4179\n","Loss =  tensor(1.2882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4180\n","Loss =  tensor(1.6020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4181\n","Loss =  tensor(1.5416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4182\n","Loss =  tensor(1.4509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4183\n","Loss =  tensor(1.2439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4184\n","Loss =  tensor(1.2864, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4185\n","Loss =  tensor(1.1793, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4186\n","Loss =  tensor(1.3841, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4187\n","Loss =  tensor(1.6878, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  4188\n","Loss =  tensor(1.4791, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4189\n","Loss =  tensor(1.1336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4190\n","Loss =  tensor(1.3256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4191\n","Loss =  tensor(1.4906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4192\n","Loss =  tensor(1.6743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4193\n","Loss =  tensor(1.2886, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4194\n","Loss =  tensor(1.6863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4195\n","Loss =  tensor(1.2208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4196\n","Loss =  tensor(1.2844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4197\n","Loss =  tensor(1.4362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4198\n","Loss =  tensor(1.3841, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4199\n","Loss =  tensor(1.5209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4200\n","Loss =  tensor(1.3933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4201\n","Loss =  tensor(1.4087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4202\n","Loss =  tensor(1.3435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4203\n","Loss =  tensor(1.4793, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4204\n","Loss =  tensor(1.3258, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4205\n","Loss =  tensor(1.1889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4206\n","Loss =  tensor(1.5735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4207\n","Loss =  tensor(1.3204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4208\n","Loss =  tensor(1.1338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4209\n","Loss =  tensor(1.2873, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4210\n","Loss =  tensor(1.6937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4211\n","Loss =  tensor(1.3453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4212\n","Loss =  tensor(1.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4213\n","Loss =  tensor(1.3989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4214\n","Loss =  tensor(1.1729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4215\n","Loss =  tensor(1.2429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4216\n","Loss =  tensor(1.5301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4217\n","Loss =  tensor(1.3497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4218\n","Loss =  tensor(1.0821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4219\n","Loss =  tensor(1.2458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4220\n","Loss =  tensor(1.0746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4221\n","Loss =  tensor(1.2988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4222\n","Loss =  tensor(1.4612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4223\n","Loss =  tensor(1.2934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4224\n","Loss =  tensor(1.2324, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4225\n","Loss =  tensor(1.4128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4226\n","Loss =  tensor(1.2966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4227\n","Loss =  tensor(1.0735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4228\n","Loss =  tensor(1.4895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4229\n","Loss =  tensor(1.2725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4230\n","Loss =  tensor(1.2985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4231\n","Loss =  tensor(1.3241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4232\n","Loss =  tensor(1.2787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4233\n","Loss =  tensor(1.2359, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4234\n","Loss =  tensor(0.9372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4235\n","Loss =  tensor(1.2387, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4236\n","Loss =  tensor(1.3595, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4237\n","Loss =  tensor(1.3396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4238\n","Loss =  tensor(1.0611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4239\n","Loss =  tensor(1.1956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4240\n","Loss =  tensor(1.1154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4241\n","Loss =  tensor(1.1623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4242\n","Loss =  tensor(1.2545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4243\n","Loss =  tensor(1.2350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4244\n","Loss =  tensor(1.3105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4245\n","Loss =  tensor(1.1493, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4246\n","Loss =  tensor(1.0903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4247\n","Loss =  tensor(1.2982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4248\n","Loss =  tensor(1.0447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4249\n","Loss =  tensor(1.0630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4250\n","Loss =  tensor(1.2129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4251\n","Loss =  tensor(1.0940, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4252\n","Loss =  tensor(1.6872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4253\n","Loss =  tensor(0.9354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4254\n","Loss =  tensor(1.0316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4255\n","Loss =  tensor(1.1434, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4256\n","Loss =  tensor(1.0949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4257\n","Loss =  tensor(1.1898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4258\n","Loss =  tensor(1.3508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4259\n","Loss =  tensor(1.4107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4260\n","Loss =  tensor(1.2651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4261\n","Loss =  tensor(0.8934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4262\n","Loss =  tensor(0.8670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4263\n","Loss =  tensor(1.2415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4264\n","Loss =  tensor(0.9416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4265\n","Loss =  tensor(1.1653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4266\n","Loss =  tensor(1.3894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4267\n","Loss =  tensor(1.1938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4268\n","Loss =  tensor(1.1440, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4269\n","Loss =  tensor(1.2262, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4270\n","Loss =  tensor(1.1261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4271\n","Loss =  tensor(0.9981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4272\n","Loss =  tensor(0.9907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4273\n","Loss =  tensor(1.0443, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4274\n","Loss =  tensor(1.1430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4275\n","Loss =  tensor(1.1427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4276\n","Loss =  tensor(1.1393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4277\n","Loss =  tensor(1.1776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4278\n","Loss =  tensor(1.0486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4279\n","Loss =  tensor(1.2989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4280\n","Loss =  tensor(1.2325, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4281\n","Loss =  tensor(1.3269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4282\n","Loss =  tensor(1.0775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  4283\n","Loss =  tensor(1.5946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4284\n","Loss =  tensor(0.9121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4285\n","Loss =  tensor(1.0774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4286\n","Loss =  tensor(1.0633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4287\n","Loss =  tensor(1.1907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4288\n","Loss =  tensor(1.2056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4289\n","Loss =  tensor(1.1275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4290\n","Loss =  tensor(1.2402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4291\n","Loss =  tensor(0.9060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4292\n","Loss =  tensor(1.3482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4293\n","Loss =  tensor(1.1622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4294\n","Loss =  tensor(1.3085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4295\n","Loss =  tensor(1.0801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4296\n","Loss =  tensor(1.1157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4297\n","Loss =  tensor(1.1253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4298\n","Loss =  tensor(1.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4299\n","Loss =  tensor(1.0874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4300\n","Loss =  tensor(1.1560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4301\n","Loss =  tensor(1.0905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4302\n","Loss =  tensor(1.1041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4303\n","Loss =  tensor(0.9884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4304\n","Loss =  tensor(1.3068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4305\n","Loss =  tensor(0.9498, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4306\n","Loss =  tensor(1.1238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4307\n","Loss =  tensor(1.3226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4308\n","Loss =  tensor(1.2418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4309\n","Loss =  tensor(1.1343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4310\n","Loss =  tensor(1.1599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4311\n","Loss =  tensor(1.3109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4312\n","Loss =  tensor(1.0563, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4313\n","Loss =  tensor(1.1797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4314\n","Loss =  tensor(1.0948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4315\n","Loss =  tensor(1.1431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4316\n","Loss =  tensor(0.9688, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4317\n","Loss =  tensor(1.1398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4318\n","Loss =  tensor(1.0448, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4319\n","Loss =  tensor(1.1235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4320\n","Loss =  tensor(0.9918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4321\n","Loss =  tensor(1.0136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4322\n","Loss =  tensor(1.1549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4323\n","Loss =  tensor(1.2291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4324\n","Loss =  tensor(1.0824, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4325\n","Loss =  tensor(0.7859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4326\n","Loss =  tensor(1.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4327\n","Loss =  tensor(1.1928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4328\n","Loss =  tensor(1.0623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4329\n","Loss =  tensor(1.0780, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4330\n","Loss =  tensor(0.9185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4331\n","Loss =  tensor(1.0616, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4332\n","Loss =  tensor(1.5112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4333\n","Loss =  tensor(0.9581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4334\n","Loss =  tensor(1.0538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4335\n","Loss =  tensor(1.0759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4336\n","Loss =  tensor(1.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4337\n","Loss =  tensor(1.1128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4338\n","Loss =  tensor(0.9967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4339\n","Loss =  tensor(0.9890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4340\n","Loss =  tensor(0.8455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4341\n","Loss =  tensor(1.1149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4342\n","Loss =  tensor(1.0986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4343\n","Loss =  tensor(0.8187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4344\n","Loss =  tensor(1.1259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4345\n","Loss =  tensor(1.1235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4346\n","Loss =  tensor(0.9919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4347\n","Loss =  tensor(0.8800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4348\n","Loss =  tensor(1.0301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4349\n","Loss =  tensor(0.8259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4350\n","Loss =  tensor(0.9966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4351\n","Loss =  tensor(1.0691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4352\n","Loss =  tensor(0.7758, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4353\n","Loss =  tensor(0.8502, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4354\n","Loss =  tensor(0.8975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4355\n","Loss =  tensor(1.0489, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4356\n","Loss =  tensor(1.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4357\n","Loss =  tensor(1.2600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4358\n","Loss =  tensor(0.8924, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4359\n","Loss =  tensor(0.9922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4360\n","Loss =  tensor(1.1742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4361\n","Loss =  tensor(1.0285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4362\n","Loss =  tensor(0.7396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4363\n","Loss =  tensor(1.1107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4364\n","Loss =  tensor(1.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4365\n","Loss =  tensor(1.1131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4366\n","Loss =  tensor(1.2681, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4367\n","Loss =  tensor(1.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4368\n","Loss =  tensor(0.8938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4369\n","Loss =  tensor(0.9446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4370\n","Loss =  tensor(0.9035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4371\n","Loss =  tensor(0.9132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4372\n","Loss =  tensor(1.1837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4373\n","Loss =  tensor(1.0948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4374\n","Loss =  tensor(1.0464, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4375\n","Loss =  tensor(0.9853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4376\n","Loss =  tensor(0.8977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4377\n","Loss =  tensor(1.0453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4378\n","Loss =  tensor(1.0425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4379\n","Loss =  tensor(1.1673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4380\n","Loss =  tensor(1.0354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4381\n","Loss =  tensor(0.7276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4382\n","Loss =  tensor(0.9810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  4383\n","Loss =  tensor(1.2024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4384\n","Loss =  tensor(0.9105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4385\n","Loss =  tensor(1.0522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4386\n","Loss =  tensor(1.0513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4387\n","Loss =  tensor(1.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4388\n","Loss =  tensor(1.0973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4389\n","Loss =  tensor(0.8813, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4390\n","Loss =  tensor(0.8703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4391\n","Loss =  tensor(1.1849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4392\n","Loss =  tensor(1.0157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4393\n","Loss =  tensor(1.0424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4394\n","Loss =  tensor(0.9402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4395\n","Loss =  tensor(0.9542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4396\n","Loss =  tensor(0.7232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4397\n","Loss =  tensor(1.0273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4398\n","Loss =  tensor(1.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4399\n","Loss =  tensor(1.1569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4400\n","Loss =  tensor(0.9558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4401\n","Loss =  tensor(1.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4402\n","Loss =  tensor(0.9608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4403\n","Loss =  tensor(0.7272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4404\n","Loss =  tensor(0.9258, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4405\n","Loss =  tensor(1.0836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4406\n","Loss =  tensor(0.8836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4407\n","Loss =  tensor(0.9495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4408\n","Loss =  tensor(0.7994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4409\n","Loss =  tensor(0.9594, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4410\n","Loss =  tensor(0.8631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4411\n","Loss =  tensor(0.9538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4412\n","Loss =  tensor(0.7505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4413\n","Loss =  tensor(0.9599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4414\n","Loss =  tensor(0.7589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4415\n","Loss =  tensor(0.9199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4416\n","Loss =  tensor(0.8670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4417\n","Loss =  tensor(0.7697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4418\n","Loss =  tensor(1.0939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4419\n","Loss =  tensor(1.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4420\n","Loss =  tensor(1.0218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4421\n","Loss =  tensor(1.0294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4422\n","Loss =  tensor(0.6654, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4423\n","Loss =  tensor(0.7362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4424\n","Loss =  tensor(0.7513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4425\n","Loss =  tensor(0.8129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4426\n","Loss =  tensor(0.9833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4427\n","Loss =  tensor(0.9612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4428\n","Loss =  tensor(0.8797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4429\n","Loss =  tensor(0.8246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4430\n","Loss =  tensor(0.8567, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4431\n","Loss =  tensor(0.8501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4432\n","Loss =  tensor(1.0350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4433\n","Loss =  tensor(0.7146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4434\n","Loss =  tensor(0.6788, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4435\n","Loss =  tensor(0.7637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4436\n","Loss =  tensor(0.7129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4437\n","Loss =  tensor(0.9044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4438\n","Loss =  tensor(0.8170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4439\n","Loss =  tensor(0.9393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4440\n","Loss =  tensor(0.8737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4441\n","Loss =  tensor(0.8726, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4442\n","Loss =  tensor(0.8081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4443\n","Loss =  tensor(0.9235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4444\n","Loss =  tensor(0.7333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4445\n","Loss =  tensor(0.8556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4446\n","Loss =  tensor(0.7949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4447\n","Loss =  tensor(0.7597, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4448\n","Loss =  tensor(0.6497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4449\n","Loss =  tensor(0.9392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4450\n","Loss =  tensor(1.0422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4451\n","Loss =  tensor(0.9622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4452\n","Loss =  tensor(0.7419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4453\n","Loss =  tensor(0.7344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4454\n","Loss =  tensor(0.7967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4455\n","Loss =  tensor(0.9808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4456\n","Loss =  tensor(0.8724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4457\n","Loss =  tensor(0.8439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4458\n","Loss =  tensor(0.8301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4459\n","Loss =  tensor(0.8561, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4460\n","Loss =  tensor(0.7954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4461\n","Loss =  tensor(0.7608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4462\n","Loss =  tensor(0.8173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4463\n","Loss =  tensor(0.7594, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4464\n","Loss =  tensor(0.7077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4465\n","Loss =  tensor(0.8617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4466\n","Loss =  tensor(0.8303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4467\n","Loss =  tensor(0.7842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4468\n","Loss =  tensor(0.7980, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4469\n","Loss =  tensor(0.6156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4470\n","Loss =  tensor(0.8136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4471\n","Loss =  tensor(0.8220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4472\n","Loss =  tensor(0.7624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4473\n","Loss =  tensor(0.8584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4474\n","Loss =  tensor(0.7767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4475\n","Loss =  tensor(0.7335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4476\n","Loss =  tensor(0.7611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4477\n","Loss =  tensor(0.8717, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4478\n","Loss =  tensor(0.8657, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4479\n","Loss =  tensor(0.7701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4480\n","Loss =  tensor(0.8179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4481\n","Loss =  tensor(0.8310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4482\n","Loss =  tensor(0.7418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4483\n","Loss =  tensor(0.7374, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4484\n","Loss =  tensor(0.7309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4485\n","Loss =  tensor(0.7173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4486\n","Loss =  tensor(0.9003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4487\n","Loss =  tensor(0.7674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4488\n","Loss =  tensor(0.6838, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4489\n","Loss =  tensor(0.7307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4490\n","Loss =  tensor(0.8672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4491\n","Loss =  tensor(0.8231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4492\n","Loss =  tensor(0.6802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4493\n","Loss =  tensor(0.7205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4494\n","Loss =  tensor(0.7260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4495\n","Loss =  tensor(0.7089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4496\n","Loss =  tensor(0.6967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4497\n","Loss =  tensor(0.8692, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4498\n","Loss =  tensor(0.7828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4499\n","Loss =  tensor(0.8596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4500\n","Loss =  tensor(0.7639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4501\n","Loss =  tensor(0.6061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4502\n","Loss =  tensor(0.8618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4503\n","Loss =  tensor(0.8752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4504\n","Loss =  tensor(0.5980, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4505\n","Loss =  tensor(0.8757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4506\n","Loss =  tensor(0.8811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4507\n","Loss =  tensor(0.7607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4508\n","Loss =  tensor(0.7492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4509\n","Loss =  tensor(0.6823, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4510\n","Loss =  tensor(0.7848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4511\n","Loss =  tensor(0.8659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4512\n","Loss =  tensor(0.7311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4513\n","Loss =  tensor(0.6771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4514\n","Loss =  tensor(0.7446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4515\n","Loss =  tensor(0.6945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4516\n","Loss =  tensor(0.7529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4517\n","Loss =  tensor(0.8802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4518\n","Loss =  tensor(0.6521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4519\n","Loss =  tensor(0.7912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4520\n","Loss =  tensor(0.7364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4521\n","Loss =  tensor(0.6779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4522\n","Loss =  tensor(0.8980, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4523\n","Loss =  tensor(0.7916, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4524\n","Loss =  tensor(0.5647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4525\n","Loss =  tensor(0.8278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4526\n","Loss =  tensor(0.6221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4527\n","Loss =  tensor(0.8371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4528\n","Loss =  tensor(0.8174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4529\n","Loss =  tensor(0.6872, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4530\n","Loss =  tensor(0.6486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4531\n","Loss =  tensor(0.6431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4532\n","Loss =  tensor(0.7312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4533\n","Loss =  tensor(0.6505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  4534\n","Loss =  tensor(0.6731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4535\n","Loss =  tensor(0.8718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4536\n","Loss =  tensor(0.7305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4537\n","Loss =  tensor(0.7671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4538\n","Loss =  tensor(0.7422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4539\n","Loss =  tensor(0.8183, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4540\n","Loss =  tensor(0.7029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4541\n","Loss =  tensor(0.7550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4542\n","Loss =  tensor(0.5112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4543\n","Loss =  tensor(0.6275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4544\n","Loss =  tensor(0.8130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4545\n","Loss =  tensor(0.6542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4546\n","Loss =  tensor(0.6972, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4547\n","Loss =  tensor(0.6640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4548\n","Loss =  tensor(0.6832, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4549\n","Loss =  tensor(0.7395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4550\n","Loss =  tensor(0.7854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4551\n","Loss =  tensor(0.6139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4552\n","Loss =  tensor(0.6227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4553\n","Loss =  tensor(0.7636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4554\n","Loss =  tensor(0.6485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4555\n","Loss =  tensor(0.7177, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4556\n","Loss =  tensor(0.6459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4557\n","Loss =  tensor(0.6489, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4558\n","Loss =  tensor(0.6417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4559\n","Loss =  tensor(0.6270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4560\n","Loss =  tensor(0.6709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4561\n","Loss =  tensor(0.5660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4562\n","Loss =  tensor(0.7442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4563\n","Loss =  tensor(0.7206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4564\n","Loss =  tensor(0.6751, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4565\n","Loss =  tensor(0.5271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4566\n","Loss =  tensor(0.6471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4567\n","Loss =  tensor(0.5722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4568\n","Loss =  tensor(0.6225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4569\n","Loss =  tensor(0.6057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4570\n","Loss =  tensor(0.7143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4571\n","Loss =  tensor(0.6750, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4572\n","Loss =  tensor(0.6069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4573\n","Loss =  tensor(0.7402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4574\n","Loss =  tensor(0.6635, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4575\n","Loss =  tensor(0.5780, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4576\n","Loss =  tensor(0.5829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4577\n","Loss =  tensor(0.6203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4578\n","Loss =  tensor(0.5575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4579\n","Loss =  tensor(0.5919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4580\n","Loss =  tensor(0.6207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4581\n","Loss =  tensor(0.6066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4582\n","Loss =  tensor(0.6210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4583\n","Loss =  tensor(0.5712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4584\n","Loss =  tensor(0.7097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4585\n","Loss =  tensor(0.6782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4586\n","Loss =  tensor(0.5657, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4587\n","Loss =  tensor(0.5586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4588\n","Loss =  tensor(0.7252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4589\n","Loss =  tensor(0.5357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4590\n","Loss =  tensor(0.5520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4591\n","Loss =  tensor(0.5858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4592\n","Loss =  tensor(0.7122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4593\n","Loss =  tensor(0.5890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4594\n","Loss =  tensor(0.5681, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4595\n","Loss =  tensor(0.5408, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4596\n","Loss =  tensor(0.6624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4597\n","Loss =  tensor(0.6898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4598\n","Loss =  tensor(0.6081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4599\n","Loss =  tensor(0.5009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4600\n","Loss =  tensor(0.5431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4601\n","Loss =  tensor(0.5560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4602\n","Loss =  tensor(0.6591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4603\n","Loss =  tensor(0.6556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4604\n","Loss =  tensor(0.6797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4605\n","Loss =  tensor(0.4729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4606\n","Loss =  tensor(0.5727, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4607\n","Loss =  tensor(0.5661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4608\n","Loss =  tensor(0.5263, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4609\n","Loss =  tensor(0.6092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4610\n","Loss =  tensor(0.6145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4611\n","Loss =  tensor(0.5435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4612\n","Loss =  tensor(0.4821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4613\n","Loss =  tensor(0.6080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4614\n","Loss =  tensor(0.7087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4615\n","Loss =  tensor(0.5932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4616\n","Loss =  tensor(0.5856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4617\n","Loss =  tensor(0.4989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4618\n","Loss =  tensor(0.6099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4619\n","Loss =  tensor(0.5386, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4620\n","Loss =  tensor(0.5825, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4621\n","Loss =  tensor(0.5883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4622\n","Loss =  tensor(0.6803, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4623\n","Loss =  tensor(0.5605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4624\n","Loss =  tensor(0.5990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4625\n","Loss =  tensor(0.5442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4626\n","Loss =  tensor(0.5255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4627\n","Loss =  tensor(0.4572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4628\n","Loss =  tensor(0.5720, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4629\n","Loss =  tensor(0.5711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4630\n","Loss =  tensor(0.4254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4631\n","Loss =  tensor(0.4835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4632\n","Loss =  tensor(0.4553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4633\n","Loss =  tensor(0.5114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4634\n","Loss =  tensor(0.5710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4635\n","Loss =  tensor(0.5556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4636\n","Loss =  tensor(0.5108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4637\n","Loss =  tensor(0.5122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4638\n","Loss =  tensor(0.6053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4639\n","Loss =  tensor(0.5882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4640\n","Loss =  tensor(0.5786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4641\n","Loss =  tensor(0.4664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4642\n","Loss =  tensor(0.5301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4643\n","Loss =  tensor(0.4923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4644\n","Loss =  tensor(0.5808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4645\n","Loss =  tensor(0.4826, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4646\n","Loss =  tensor(0.5611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4647\n","Loss =  tensor(0.6140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4648\n","Loss =  tensor(0.4546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4649\n","Loss =  tensor(0.4439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  4650\n","Loss =  tensor(0.6509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4651\n","Loss =  tensor(0.4688, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4652\n","Loss =  tensor(0.5347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4653\n","Loss =  tensor(0.6079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4654\n","Loss =  tensor(0.4470, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4655\n","Loss =  tensor(0.6435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4656\n","Loss =  tensor(0.6394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4657\n","Loss =  tensor(0.5164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4658\n","Loss =  tensor(0.5592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4659\n","Loss =  tensor(0.5226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4660\n","Loss =  tensor(0.6141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4661\n","Loss =  tensor(0.5317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4662\n","Loss =  tensor(0.4988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4663\n","Loss =  tensor(0.5204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4664\n","Loss =  tensor(0.5949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4665\n","Loss =  tensor(0.5159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4666\n","Loss =  tensor(0.4568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4667\n","Loss =  tensor(0.5143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4668\n","Loss =  tensor(0.5313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4669\n","Loss =  tensor(0.4272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4670\n","Loss =  tensor(0.4284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4671\n","Loss =  tensor(0.4831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4672\n","Loss =  tensor(0.5570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4673\n","Loss =  tensor(0.4118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4674\n","Loss =  tensor(0.4512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4675\n","Loss =  tensor(0.5381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4676\n","Loss =  tensor(0.5630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4677\n","Loss =  tensor(0.5515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4678\n","Loss =  tensor(0.5076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4679\n","Loss =  tensor(0.5190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4680\n","Loss =  tensor(0.5555, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4681\n","Loss =  tensor(0.3653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4682\n","Loss =  tensor(0.4224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4683\n","Loss =  tensor(0.4720, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4684\n","Loss =  tensor(0.4148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4685\n","Loss =  tensor(0.5320, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4686\n","Loss =  tensor(0.4706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4687\n","Loss =  tensor(0.3972, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4688\n","Loss =  tensor(0.4293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4689\n","Loss =  tensor(0.4760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4690\n","Loss =  tensor(0.4479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4691\n","Loss =  tensor(0.4956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4692\n","Loss =  tensor(0.6439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4693\n","Loss =  tensor(0.4357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4694\n","Loss =  tensor(0.4915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4695\n","Loss =  tensor(0.5184, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4696\n","Loss =  tensor(0.5352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4697\n","Loss =  tensor(0.5335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4698\n","Loss =  tensor(0.5274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4699\n","Loss =  tensor(0.5444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4700\n","Loss =  tensor(0.5430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4701\n","Loss =  tensor(0.5849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4702\n","Loss =  tensor(0.4702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4703\n","Loss =  tensor(0.5664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4704\n","Loss =  tensor(0.4856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4705\n","Loss =  tensor(0.4989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4706\n","Loss =  tensor(0.5415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4707\n","Loss =  tensor(0.4637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4708\n","Loss =  tensor(0.5778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4709\n","Loss =  tensor(0.4398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4710\n","Loss =  tensor(0.3975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4711\n","Loss =  tensor(0.5629, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4712\n","Loss =  tensor(0.5182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4713\n","Loss =  tensor(0.5592, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4714\n","Loss =  tensor(0.5088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4715\n","Loss =  tensor(0.3869, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4716\n","Loss =  tensor(0.4371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4717\n","Loss =  tensor(0.5404, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4718\n","Loss =  tensor(0.6133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4719\n","Loss =  tensor(0.4906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4720\n","Loss =  tensor(0.4819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4721\n","Loss =  tensor(0.4822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4722\n","Loss =  tensor(0.4928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4723\n","Loss =  tensor(0.5357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4724\n","Loss =  tensor(0.3915, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4725\n","Loss =  tensor(0.5011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4726\n","Loss =  tensor(0.4937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4727\n","Loss =  tensor(0.5083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4728\n","Loss =  tensor(0.4707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4729\n","Loss =  tensor(0.4501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4730\n","Loss =  tensor(0.4498, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4731\n","Loss =  tensor(0.4674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4732\n","Loss =  tensor(0.3925, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4733\n","Loss =  tensor(0.5096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4734\n","Loss =  tensor(0.4384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4735\n","Loss =  tensor(0.5286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4736\n","Loss =  tensor(0.4912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4737\n","Loss =  tensor(0.4391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4738\n","Loss =  tensor(0.4496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4739\n","Loss =  tensor(0.7885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4740\n","Loss =  tensor(0.3369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4741\n","Loss =  tensor(0.4900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4742\n","Loss =  tensor(0.5275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4743\n","Loss =  tensor(0.3442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4744\n","Loss =  tensor(0.4988, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4745\n","Loss =  tensor(0.5917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4746\n","Loss =  tensor(0.3814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4747\n","Loss =  tensor(0.6405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4748\n","Loss =  tensor(0.6436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4749\n","Loss =  tensor(0.3968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4750\n","Loss =  tensor(0.5529, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4751\n","Loss =  tensor(0.3579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4752\n","Loss =  tensor(0.4512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4753\n","Loss =  tensor(0.4220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4754\n","Loss =  tensor(0.4933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4755\n","Loss =  tensor(0.3962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4756\n","Loss =  tensor(0.6604, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4757\n","Loss =  tensor(0.4385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4758\n","Loss =  tensor(0.6052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4759\n","Loss =  tensor(0.6342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4760\n","Loss =  tensor(0.4601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4761\n","Loss =  tensor(0.4062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4762\n","Loss =  tensor(0.4881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4763\n","Loss =  tensor(0.3942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4764\n","Loss =  tensor(0.4156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4765\n","Loss =  tensor(0.4552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4766\n","Loss =  tensor(0.3612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4767\n","Loss =  tensor(0.4227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4768\n","Loss =  tensor(0.5180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4769\n","Loss =  tensor(0.4431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4770\n","Loss =  tensor(0.5277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4771\n","Loss =  tensor(0.5540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4772\n","Loss =  tensor(0.3253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4773\n","Loss =  tensor(0.3400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  4774\n","Loss =  tensor(0.5642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4775\n","Loss =  tensor(0.3516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4776\n","Loss =  tensor(0.4101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4777\n","Loss =  tensor(0.5766, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4778\n","Loss =  tensor(0.3283, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4779\n","Loss =  tensor(0.5155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4780\n","Loss =  tensor(0.2891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4781\n","Loss =  tensor(0.4344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4782\n","Loss =  tensor(0.4410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4783\n","Loss =  tensor(0.3551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4784\n","Loss =  tensor(0.4420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4785\n","Loss =  tensor(0.4636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4786\n","Loss =  tensor(0.4183, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4787\n","Loss =  tensor(0.4070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4788\n","Loss =  tensor(0.3670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4789\n","Loss =  tensor(0.3917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4790\n","Loss =  tensor(0.4427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4791\n","Loss =  tensor(0.3614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4792\n","Loss =  tensor(0.3556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4793\n","Loss =  tensor(0.3414, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4794\n","Loss =  tensor(0.3963, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4795\n","Loss =  tensor(0.3674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4796\n","Loss =  tensor(0.4716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4797\n","Loss =  tensor(0.3039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4798\n","Loss =  tensor(0.3301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4799\n","Loss =  tensor(0.3702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4800\n","Loss =  tensor(0.3220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4801\n","Loss =  tensor(0.4128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4802\n","Loss =  tensor(0.3752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4803\n","Loss =  tensor(0.3833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4804\n","Loss =  tensor(0.3702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4805\n","Loss =  tensor(0.4081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4806\n","Loss =  tensor(0.3538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4807\n","Loss =  tensor(0.4912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4808\n","Loss =  tensor(0.4143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4809\n","Loss =  tensor(0.3481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4810\n","Loss =  tensor(0.3831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4811\n","Loss =  tensor(0.3569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4812\n","Loss =  tensor(0.3338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4813\n","Loss =  tensor(0.3827, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4814\n","Loss =  tensor(0.3995, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4815\n","Loss =  tensor(0.3492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4816\n","Loss =  tensor(0.3343, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4817\n","Loss =  tensor(0.3241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4818\n","Loss =  tensor(0.2800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4819\n","Loss =  tensor(0.3264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4820\n","Loss =  tensor(0.3299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4821\n","Loss =  tensor(0.3302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4822\n","Loss =  tensor(0.3546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4823\n","Loss =  tensor(0.3744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4824\n","Loss =  tensor(0.3166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4825\n","Loss =  tensor(0.3382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4826\n","Loss =  tensor(0.3332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4827\n","Loss =  tensor(0.3562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4828\n","Loss =  tensor(0.3691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4829\n","Loss =  tensor(0.3549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4830\n","Loss =  tensor(0.3093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4831\n","Loss =  tensor(0.3469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4832\n","Loss =  tensor(0.4442, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4833\n","Loss =  tensor(0.4226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4834\n","Loss =  tensor(0.4220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4835\n","Loss =  tensor(0.3080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4836\n","Loss =  tensor(0.4719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4837\n","Loss =  tensor(0.2842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4838\n","Loss =  tensor(0.3445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4839\n","Loss =  tensor(0.3341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4840\n","Loss =  tensor(0.3584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4841\n","Loss =  tensor(0.3143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4842\n","Loss =  tensor(0.3576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4843\n","Loss =  tensor(0.3835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4844\n","Loss =  tensor(0.3486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4845\n","Loss =  tensor(0.3404, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4846\n","Loss =  tensor(0.4437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4847\n","Loss =  tensor(0.3294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4848\n","Loss =  tensor(0.3036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4849\n","Loss =  tensor(0.4427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4850\n","Loss =  tensor(0.2969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4851\n","Loss =  tensor(0.3812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4852\n","Loss =  tensor(0.3498, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4853\n","Loss =  tensor(0.3364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4854\n","Loss =  tensor(0.2778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4855\n","Loss =  tensor(0.3648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4856\n","Loss =  tensor(0.3867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4857\n","Loss =  tensor(0.3658, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4858\n","Loss =  tensor(0.2938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4859\n","Loss =  tensor(0.3115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4860\n","Loss =  tensor(0.2783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4861\n","Loss =  tensor(0.2971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4862\n","Loss =  tensor(0.3580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4863\n","Loss =  tensor(0.3314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4864\n","Loss =  tensor(0.2896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4865\n","Loss =  tensor(0.2881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4866\n","Loss =  tensor(0.3439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4867\n","Loss =  tensor(0.2354, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4868\n","Loss =  tensor(0.3669, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4869\n","Loss =  tensor(0.3527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4870\n","Loss =  tensor(0.3430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4871\n","Loss =  tensor(0.5391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4872\n","Loss =  tensor(0.3614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4873\n","Loss =  tensor(0.3469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4874\n","Loss =  tensor(0.4580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4875\n","Loss =  tensor(0.3129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4876\n","Loss =  tensor(0.3746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4877\n","Loss =  tensor(0.3697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4878\n","Loss =  tensor(0.3696, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4879\n","Loss =  tensor(0.4255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4880\n","Loss =  tensor(0.2572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4881\n","Loss =  tensor(0.5395, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4882\n","Loss =  tensor(0.4370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4883\n","Loss =  tensor(0.4294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4884\n","Loss =  tensor(0.4797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4885\n","Loss =  tensor(0.3214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4886\n","Loss =  tensor(0.4036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4887\n","Loss =  tensor(0.4194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4888\n","Loss =  tensor(0.3269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4889\n","Loss =  tensor(0.3967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4890\n","Loss =  tensor(0.3754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4891\n","Loss =  tensor(0.2946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4892\n","Loss =  tensor(0.3165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4893\n","Loss =  tensor(0.3057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4894\n","Loss =  tensor(0.3245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4895\n","Loss =  tensor(0.3575, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4896\n","Loss =  tensor(0.2763, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4897\n","Loss =  tensor(0.2781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4898\n","Loss =  tensor(0.3432, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4899\n","Loss =  tensor(0.2851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4900\n","Loss =  tensor(0.3310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4901\n","Loss =  tensor(0.4950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4902\n","Loss =  tensor(0.2779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4903\n","Loss =  tensor(0.4882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4904\n","Loss =  tensor(0.2364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4905\n","Loss =  tensor(0.3519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4906\n","Loss =  tensor(0.4492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4907\n","Loss =  tensor(0.3144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4908\n","Loss =  tensor(0.3691, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4909\n","Loss =  tensor(0.4179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4910\n","Loss =  tensor(0.2950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4911\n","Loss =  tensor(0.4370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4912\n","Loss =  tensor(0.2774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4913\n","Loss =  tensor(0.3836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4914\n","Loss =  tensor(0.4369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4915\n","Loss =  tensor(0.3110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4916\n","Loss =  tensor(0.4533, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4917\n","Loss =  tensor(0.3487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4918\n","Loss =  tensor(0.2611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4919\n","Loss =  tensor(0.4155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4920\n","Loss =  tensor(0.2435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4921\n","Loss =  tensor(0.3797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4922\n","Loss =  tensor(0.3244, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4923\n","Loss =  tensor(0.2118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4924\n","Loss =  tensor(0.3233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4925\n","Loss =  tensor(0.7075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4926\n","Loss =  tensor(0.3123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4927\n","Loss =  tensor(0.6076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4928\n","Loss =  tensor(0.3559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4929\n","Loss =  tensor(0.4247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4930\n","Loss =  tensor(0.4112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4931\n","Loss =  tensor(0.2419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4932\n","Loss =  tensor(0.4958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4933\n","Loss =  tensor(0.5736, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4934\n","Loss =  tensor(0.2546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4935\n","Loss =  tensor(0.6069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4936\n","Loss =  tensor(0.3141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4937\n","Loss =  tensor(0.2965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4938\n","Loss =  tensor(0.5240, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4939\n","Loss =  tensor(0.2666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4940\n","Loss =  tensor(0.3754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4941\n","Loss =  tensor(0.3232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4942\n","Loss =  tensor(0.2441, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4943\n","Loss =  tensor(0.3279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4944\n","Loss =  tensor(0.3251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4945\n","Loss =  tensor(0.3031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4946\n","Loss =  tensor(0.4662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4947\n","Loss =  tensor(0.2437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4948\n","Loss =  tensor(0.3117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4949\n","Loss =  tensor(0.3707, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4950\n","Loss =  tensor(0.3016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4951\n","Loss =  tensor(0.4042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4952\n","Loss =  tensor(0.2550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4953\n","Loss =  tensor(0.3167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4954\n","Loss =  tensor(0.3586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4955\n","Loss =  tensor(0.2856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4956\n","Loss =  tensor(0.1856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4957\n","Loss =  tensor(0.3268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4958\n","Loss =  tensor(0.2257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4959\n","Loss =  tensor(0.3290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4960\n","Loss =  tensor(0.2669, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4961\n","Loss =  tensor(0.2362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4962\n","Loss =  tensor(0.3451, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4963\n","Loss =  tensor(0.3671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4964\n","Loss =  tensor(0.3226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4965\n","Loss =  tensor(0.4178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4966\n","Loss =  tensor(0.2476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4967\n","Loss =  tensor(0.2471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4968\n","Loss =  tensor(0.5107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4969\n","Loss =  tensor(0.3132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4970\n","Loss =  tensor(0.5531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4971\n","Loss =  tensor(0.2257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4972\n","Loss =  tensor(0.5850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4973\n","Loss =  tensor(0.2735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4974\n","Loss =  tensor(0.2824, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4975\n","Loss =  tensor(0.3424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4976\n","Loss =  tensor(0.2166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4977\n","Loss =  tensor(0.2807, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4978\n","Loss =  tensor(0.3218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4979\n","Loss =  tensor(0.2409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4980\n","Loss =  tensor(0.3495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4981\n","Loss =  tensor(0.2789, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4982\n","Loss =  tensor(0.2511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4983\n","Loss =  tensor(0.4400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4984\n","Loss =  tensor(0.2809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4985\n","Loss =  tensor(0.5143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4986\n","Loss =  tensor(0.2877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4987\n","Loss =  tensor(0.2916, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4988\n","Loss =  tensor(0.5338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4989\n","Loss =  tensor(0.2664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4990\n","Loss =  tensor(0.3932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4991\n","Loss =  tensor(0.3138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4992\n","Loss =  tensor(0.2961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  4993\n","Loss =  tensor(0.4635, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4994\n","Loss =  tensor(0.2247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4995\n","Loss =  tensor(0.3258, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  4996\n","Loss =  tensor(0.4099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  4997\n","Loss =  tensor(0.1950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4998\n","Loss =  tensor(0.2429, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  4999\n","Loss =  tensor(0.3017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5000\n","Loss =  tensor(0.2119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5001\n","Loss =  tensor(0.2618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5002\n","Loss =  tensor(0.2559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5003\n","Loss =  tensor(0.2797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  5004\n","Loss =  tensor(0.2694, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  5005\n","Loss =  tensor(0.1938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5006\n","Loss =  tensor(0.2018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5007\n","Loss =  tensor(0.2210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5008\n","Loss =  tensor(0.2249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5009\n","Loss =  tensor(0.2666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  5010\n","Loss =  tensor(0.2158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5011\n","Loss =  tensor(0.2054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5012\n","Loss =  tensor(0.2127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5013\n","Loss =  tensor(0.2212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5014\n","Loss =  tensor(0.1664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5015\n","Loss =  tensor(0.2456, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5016\n","Loss =  tensor(0.2044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5017\n","Loss =  tensor(0.2341, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5018\n","Loss =  tensor(0.1930, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5019\n","Loss =  tensor(0.2234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5020\n","Loss =  tensor(0.2443, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5021\n","Loss =  tensor(0.2196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5022\n","Loss =  tensor(0.1637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5023\n","Loss =  tensor(0.2090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5024\n","Loss =  tensor(0.2066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5025\n","Loss =  tensor(0.2130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5026\n","Loss =  tensor(0.1683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5027\n","Loss =  tensor(0.2053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5028\n","Loss =  tensor(0.2287, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5029\n","Loss =  tensor(0.2486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5030\n","Loss =  tensor(0.2188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  5031\n","Loss =  tensor(0.2726, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  5032\n","Loss =  tensor(0.2089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5033\n","Loss =  tensor(0.1668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5034\n","Loss =  tensor(0.2233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5035\n","Loss =  tensor(0.1898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5036\n","Loss =  tensor(0.2099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5037\n","Loss =  tensor(0.2378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5038\n","Loss =  tensor(0.1853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5039\n","Loss =  tensor(0.2150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5040\n","Loss =  tensor(0.2315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5041\n","Loss =  tensor(0.1899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5042\n","Loss =  tensor(0.2143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5043\n","Loss =  tensor(0.2375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5044\n","Loss =  tensor(0.1860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5045\n","Loss =  tensor(0.2353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5046\n","Loss =  tensor(0.1938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5047\n","Loss =  tensor(0.2156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5048\n","Loss =  tensor(0.2459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5049\n","Loss =  tensor(0.1890, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5050\n","Loss =  tensor(0.2207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5051\n","Loss =  tensor(0.1965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5052\n","Loss =  tensor(0.1932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5053\n","Loss =  tensor(0.2022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5054\n","Loss =  tensor(0.1807, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5055\n","Loss =  tensor(0.2269, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5056\n","Loss =  tensor(0.1767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5057\n","Loss =  tensor(0.2046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5058\n","Loss =  tensor(0.1920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5059\n","Loss =  tensor(0.1837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5060\n","Loss =  tensor(0.1614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5061\n","Loss =  tensor(0.1854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5062\n","Loss =  tensor(0.1955, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5063\n","Loss =  tensor(0.2096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5064\n","Loss =  tensor(0.1569, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5065\n","Loss =  tensor(0.1713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5066\n","Loss =  tensor(0.1781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5067\n","Loss =  tensor(0.1794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5068\n","Loss =  tensor(0.1814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5069\n","Loss =  tensor(0.1590, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5070\n","Loss =  tensor(0.2042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5071\n","Loss =  tensor(0.1987, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5072\n","Loss =  tensor(0.2013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5073\n","Loss =  tensor(0.1846, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5074\n","Loss =  tensor(0.1826, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5075\n","Loss =  tensor(0.1718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5076\n","Loss =  tensor(0.2137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5077\n","Loss =  tensor(0.1768, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5078\n","Loss =  tensor(0.1553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5079\n","Loss =  tensor(0.1818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5080\n","Loss =  tensor(0.1859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5081\n","Loss =  tensor(0.1752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5082\n","Loss =  tensor(0.2121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5083\n","Loss =  tensor(0.2112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5084\n","Loss =  tensor(0.1729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5085\n","Loss =  tensor(0.1962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5086\n","Loss =  tensor(0.2106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5087\n","Loss =  tensor(0.1722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5088\n","Loss =  tensor(0.1573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5089\n","Loss =  tensor(0.1922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5090\n","Loss =  tensor(0.1950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5091\n","Loss =  tensor(0.1954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5092\n","Loss =  tensor(0.1899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5093\n","Loss =  tensor(0.1553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5094\n","Loss =  tensor(0.1801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5095\n","Loss =  tensor(0.2340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5096\n","Loss =  tensor(0.1587, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5097\n","Loss =  tensor(0.1821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5098\n","Loss =  tensor(0.1596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5099\n","Loss =  tensor(0.1850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5100\n","Loss =  tensor(0.1860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5101\n","Loss =  tensor(0.1460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5102\n","Loss =  tensor(0.1727, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5103\n","Loss =  tensor(0.1557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5104\n","Loss =  tensor(0.1658, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5105\n","Loss =  tensor(0.1487, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5106\n","Loss =  tensor(0.1734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5107\n","Loss =  tensor(0.1657, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5108\n","Loss =  tensor(0.1399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5109\n","Loss =  tensor(0.1786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5110\n","Loss =  tensor(0.1607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5111\n","Loss =  tensor(0.1375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5112\n","Loss =  tensor(0.1765, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5113\n","Loss =  tensor(0.1402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5114\n","Loss =  tensor(0.1581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5115\n","Loss =  tensor(0.1671, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5116\n","Loss =  tensor(0.1457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5117\n","Loss =  tensor(0.1894, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5118\n","Loss =  tensor(0.1389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5119\n","Loss =  tensor(0.1421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5120\n","Loss =  tensor(0.1677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5121\n","Loss =  tensor(0.1334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5122\n","Loss =  tensor(0.1465, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5123\n","Loss =  tensor(0.1474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5124\n","Loss =  tensor(0.1380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5125\n","Loss =  tensor(0.1467, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5126\n","Loss =  tensor(0.1218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5127\n","Loss =  tensor(0.1784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5128\n","Loss =  tensor(0.1346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5129\n","Loss =  tensor(0.1526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5130\n","Loss =  tensor(0.1444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5131\n","Loss =  tensor(0.1561, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5132\n","Loss =  tensor(0.1210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5133\n","Loss =  tensor(0.1576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5134\n","Loss =  tensor(0.1299, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5135\n","Loss =  tensor(0.1211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5136\n","Loss =  tensor(0.2054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5137\n","Loss =  tensor(0.1143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5138\n","Loss =  tensor(0.1528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5139\n","Loss =  tensor(0.1568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5140\n","Loss =  tensor(0.1666, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5141\n","Loss =  tensor(0.1403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5142\n","Loss =  tensor(0.1615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5143\n","Loss =  tensor(0.1978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5144\n","Loss =  tensor(0.1116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5145\n","Loss =  tensor(0.1709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5146\n","Loss =  tensor(0.1478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5147\n","Loss =  tensor(0.1214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5148\n","Loss =  tensor(0.1593, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5149\n","Loss =  tensor(0.1300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5150\n","Loss =  tensor(0.1405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5151\n","Loss =  tensor(0.1541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5152\n","Loss =  tensor(0.1507, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5153\n","Loss =  tensor(0.1305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5154\n","Loss =  tensor(0.1236, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5155\n","Loss =  tensor(0.1246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5156\n","Loss =  tensor(0.1534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5157\n","Loss =  tensor(0.1275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5158\n","Loss =  tensor(0.1495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5159\n","Loss =  tensor(0.1591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5160\n","Loss =  tensor(0.1213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5161\n","Loss =  tensor(0.1633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5162\n","Loss =  tensor(0.1127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5163\n","Loss =  tensor(0.1352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5164\n","Loss =  tensor(0.1551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5165\n","Loss =  tensor(0.1268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5166\n","Loss =  tensor(0.1214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5167\n","Loss =  tensor(0.1288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5168\n","Loss =  tensor(0.1225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5169\n","Loss =  tensor(0.1713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5170\n","Loss =  tensor(0.1542, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5171\n","Loss =  tensor(0.1398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5172\n","Loss =  tensor(0.1353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5173\n","Loss =  tensor(0.1445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5174\n","Loss =  tensor(0.2344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5175\n","Loss =  tensor(0.1162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5176\n","Loss =  tensor(0.1632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5177\n","Loss =  tensor(0.1534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5178\n","Loss =  tensor(0.1574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5179\n","Loss =  tensor(0.1202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5180\n","Loss =  tensor(0.1398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5181\n","Loss =  tensor(0.1677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5182\n","Loss =  tensor(0.1313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5183\n","Loss =  tensor(0.1830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5184\n","Loss =  tensor(0.1040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5185\n","Loss =  tensor(0.1623, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5186\n","Loss =  tensor(0.1231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5187\n","Loss =  tensor(0.1365, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5188\n","Loss =  tensor(0.1277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5189\n","Loss =  tensor(0.1153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5190\n","Loss =  tensor(0.1415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5191\n","Loss =  tensor(0.1371, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  5192\n","Loss =  tensor(0.1660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5193\n","Loss =  tensor(0.1126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5194\n","Loss =  tensor(0.1110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5195\n","Loss =  tensor(0.1044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5196\n","Loss =  tensor(0.1168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5197\n","Loss =  tensor(0.1320, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5198\n","Loss =  tensor(0.1086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5199\n","Loss =  tensor(0.1135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5200\n","Loss =  tensor(0.1010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5201\n","Loss =  tensor(0.1195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5202\n","Loss =  tensor(0.1362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5203\n","Loss =  tensor(0.1197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5204\n","Loss =  tensor(0.1083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5205\n","Loss =  tensor(0.1189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5206\n","Loss =  tensor(0.1246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5207\n","Loss =  tensor(0.1114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5208\n","Loss =  tensor(0.1237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5209\n","Loss =  tensor(0.1123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5210\n","Loss =  tensor(0.1161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5211\n","Loss =  tensor(0.1206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5212\n","Loss =  tensor(0.1219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5213\n","Loss =  tensor(0.1045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5214\n","Loss =  tensor(0.1097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5215\n","Loss =  tensor(0.1145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5216\n","Loss =  tensor(0.0971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5217\n","Loss =  tensor(0.1021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5218\n","Loss =  tensor(0.1282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5219\n","Loss =  tensor(0.1193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5220\n","Loss =  tensor(0.1096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5221\n","Loss =  tensor(0.1198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5222\n","Loss =  tensor(0.0997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5223\n","Loss =  tensor(0.0986, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5224\n","Loss =  tensor(0.1008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5225\n","Loss =  tensor(0.0911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5226\n","Loss =  tensor(0.1079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5227\n","Loss =  tensor(0.1229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5228\n","Loss =  tensor(0.1170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5229\n","Loss =  tensor(0.1490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5230\n","Loss =  tensor(0.1011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5231\n","Loss =  tensor(0.1568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5232\n","Loss =  tensor(0.1154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5233\n","Loss =  tensor(0.1138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5234\n","Loss =  tensor(0.0937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5235\n","Loss =  tensor(0.1099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5236\n","Loss =  tensor(0.1279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5237\n","Loss =  tensor(0.1043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5238\n","Loss =  tensor(0.1509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5239\n","Loss =  tensor(0.1358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5240\n","Loss =  tensor(0.1143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5241\n","Loss =  tensor(0.1425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5242\n","Loss =  tensor(0.1176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5243\n","Loss =  tensor(0.1041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5244\n","Loss =  tensor(0.1261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5245\n","Loss =  tensor(0.1092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5246\n","Loss =  tensor(0.1035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5247\n","Loss =  tensor(0.1319, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5248\n","Loss =  tensor(0.1133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5249\n","Loss =  tensor(0.1155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5250\n","Loss =  tensor(0.1028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5251\n","Loss =  tensor(0.1181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5252\n","Loss =  tensor(0.1085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5253\n","Loss =  tensor(0.1064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5254\n","Loss =  tensor(0.1041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5255\n","Loss =  tensor(0.1097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5256\n","Loss =  tensor(0.0958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5257\n","Loss =  tensor(0.1100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5258\n","Loss =  tensor(0.1124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5259\n","Loss =  tensor(0.0966, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5260\n","Loss =  tensor(0.0847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5261\n","Loss =  tensor(0.1065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5262\n","Loss =  tensor(0.0765, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5263\n","Loss =  tensor(0.0968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5264\n","Loss =  tensor(0.1195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5265\n","Loss =  tensor(0.0912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5266\n","Loss =  tensor(0.0897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5267\n","Loss =  tensor(0.0891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5268\n","Loss =  tensor(0.0932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5269\n","Loss =  tensor(0.0853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5270\n","Loss =  tensor(0.0952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5271\n","Loss =  tensor(0.1025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5272\n","Loss =  tensor(0.0960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5273\n","Loss =  tensor(0.0931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5274\n","Loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5275\n","Loss =  tensor(0.0903, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5276\n","Loss =  tensor(0.0822, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5277\n","Loss =  tensor(0.1101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5278\n","Loss =  tensor(0.1014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5279\n","Loss =  tensor(0.0821, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5280\n","Loss =  tensor(0.0874, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5281\n","Loss =  tensor(0.1135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5282\n","Loss =  tensor(0.0945, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5283\n","Loss =  tensor(0.0815, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5284\n","Loss =  tensor(0.0831, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5285\n","Loss =  tensor(0.1022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5286\n","Loss =  tensor(0.0878, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5287\n","Loss =  tensor(0.0866, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5288\n","Loss =  tensor(0.0779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5289\n","Loss =  tensor(0.1004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5290\n","Loss =  tensor(0.0946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5291\n","Loss =  tensor(0.0944, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5292\n","Loss =  tensor(0.0923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5293\n","Loss =  tensor(0.0937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5294\n","Loss =  tensor(0.0968, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5295\n","Loss =  tensor(0.0863, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5296\n","Loss =  tensor(0.0820, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5297\n","Loss =  tensor(0.0703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5298\n","Loss =  tensor(0.0854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5299\n","Loss =  tensor(0.0812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5300\n","Loss =  tensor(0.1000, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5301\n","Loss =  tensor(0.0870, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5302\n","Loss =  tensor(0.0918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5303\n","Loss =  tensor(0.0746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5304\n","Loss =  tensor(0.1122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5305\n","Loss =  tensor(0.1127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5306\n","Loss =  tensor(0.0937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5307\n","Loss =  tensor(0.0856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5308\n","Loss =  tensor(0.0917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5309\n","Loss =  tensor(0.0804, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5310\n","Loss =  tensor(0.0907, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5311\n","Loss =  tensor(0.0965, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5312\n","Loss =  tensor(0.0850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5313\n","Loss =  tensor(0.0859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5314\n","Loss =  tensor(0.0932, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5315\n","Loss =  tensor(0.0713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5316\n","Loss =  tensor(0.0669, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5317\n","Loss =  tensor(0.0877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5318\n","Loss =  tensor(0.0739, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5319\n","Loss =  tensor(0.0913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5320\n","Loss =  tensor(0.0901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5321\n","Loss =  tensor(0.0846, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5322\n","Loss =  tensor(0.0934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5323\n","Loss =  tensor(0.0956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5324\n","Loss =  tensor(0.0997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5325\n","Loss =  tensor(0.1028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5326\n","Loss =  tensor(0.0783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5327\n","Loss =  tensor(0.0854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5328\n","Loss =  tensor(0.0651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5329\n","Loss =  tensor(0.0690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5330\n","Loss =  tensor(0.0737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5331\n","Loss =  tensor(0.0745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5332\n","Loss =  tensor(0.0654, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5333\n","Loss =  tensor(0.0747, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5334\n","Loss =  tensor(0.0784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5335\n","Loss =  tensor(0.0833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5336\n","Loss =  tensor(0.0946, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5337\n","Loss =  tensor(0.0783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5338\n","Loss =  tensor(0.0992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5339\n","Loss =  tensor(0.0933, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5340\n","Loss =  tensor(0.1380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5341\n","Loss =  tensor(0.0746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5342\n","Loss =  tensor(0.1100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5343\n","Loss =  tensor(0.1020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5344\n","Loss =  tensor(0.1118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5345\n","Loss =  tensor(0.1199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5346\n","Loss =  tensor(0.0847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5347\n","Loss =  tensor(0.0881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5348\n","Loss =  tensor(0.1188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5349\n","Loss =  tensor(0.0858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5350\n","Loss =  tensor(0.1158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5351\n","Loss =  tensor(0.0752, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5352\n","Loss =  tensor(0.1156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5353\n","Loss =  tensor(0.1107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5354\n","Loss =  tensor(0.0761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5355\n","Loss =  tensor(0.0974, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5356\n","Loss =  tensor(0.0864, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5357\n","Loss =  tensor(0.0751, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5358\n","Loss =  tensor(0.0870, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5359\n","Loss =  tensor(0.0861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5360\n","Loss =  tensor(0.0783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5361\n","Loss =  tensor(0.0848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5362\n","Loss =  tensor(0.0587, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5363\n","Loss =  tensor(0.0614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5364\n","Loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5365\n","Loss =  tensor(0.0724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5366\n","Loss =  tensor(0.0829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5367\n","Loss =  tensor(0.0695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5368\n","Loss =  tensor(0.0748, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5369\n","Loss =  tensor(0.0793, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5370\n","Loss =  tensor(0.0617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5371\n","Loss =  tensor(0.0833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5372\n","Loss =  tensor(0.0737, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5373\n","Loss =  tensor(0.0637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5374\n","Loss =  tensor(0.0943, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5375\n","Loss =  tensor(0.0790, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5376\n","Loss =  tensor(0.0924, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5377\n","Loss =  tensor(0.0636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5378\n","Loss =  tensor(0.0905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5379\n","Loss =  tensor(0.1045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5380\n","Loss =  tensor(0.0668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5381\n","Loss =  tensor(0.1141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5382\n","Loss =  tensor(0.0947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5383\n","Loss =  tensor(0.0784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5384\n","Loss =  tensor(0.1804, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5385\n","Loss =  tensor(0.0906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5386\n","Loss =  tensor(0.1895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5387\n","Loss =  tensor(0.0664, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5388\n","Loss =  tensor(0.1910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5389\n","Loss =  tensor(0.0778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5390\n","Loss =  tensor(0.1536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5391\n","Loss =  tensor(0.0734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5392\n","Loss =  tensor(0.1242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5393\n","Loss =  tensor(0.0962, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5394\n","Loss =  tensor(0.0767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5395\n","Loss =  tensor(0.0897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5396\n","Loss =  tensor(0.0824, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5397\n","Loss =  tensor(0.1010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5398\n","Loss =  tensor(0.0735, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5399\n","Loss =  tensor(0.0772, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5400\n","Loss =  tensor(0.1205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5401\n","Loss =  tensor(0.0572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5402\n","Loss =  tensor(0.0976, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5403\n","Loss =  tensor(0.0923, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5404\n","Loss =  tensor(0.0742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5405\n","Loss =  tensor(0.1208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5406\n","Loss =  tensor(0.0728, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5407\n","Loss =  tensor(0.0880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5408\n","Loss =  tensor(0.0836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5409\n","Loss =  tensor(0.0675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5410\n","Loss =  tensor(0.0770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5411\n","Loss =  tensor(0.0645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5412\n","Loss =  tensor(0.0648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5413\n","Loss =  tensor(0.0889, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5414\n","Loss =  tensor(0.0626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5415\n","Loss =  tensor(0.0861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5416\n","Loss =  tensor(0.0677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5417\n","Loss =  tensor(0.0571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5418\n","Loss =  tensor(0.0612, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5419\n","Loss =  tensor(0.0605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5420\n","Loss =  tensor(0.0809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5421\n","Loss =  tensor(0.0580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5422\n","Loss =  tensor(0.0617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5423\n","Loss =  tensor(0.0550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5424\n","Loss =  tensor(0.0552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5425\n","Loss =  tensor(0.0584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5426\n","Loss =  tensor(0.0587, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5427\n","Loss =  tensor(0.0507, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5428\n","Loss =  tensor(0.0615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5429\n","Loss =  tensor(0.0618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5430\n","Loss =  tensor(0.0549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5431\n","Loss =  tensor(0.0458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5432\n","Loss =  tensor(0.0509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5433\n","Loss =  tensor(0.0458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5434\n","Loss =  tensor(0.0626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5435\n","Loss =  tensor(0.0541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5436\n","Loss =  tensor(0.0606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5437\n","Loss =  tensor(0.0580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5438\n","Loss =  tensor(0.0531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5439\n","Loss =  tensor(0.0492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5440\n","Loss =  tensor(0.0560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5441\n","Loss =  tensor(0.0644, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5442\n","Loss =  tensor(0.0486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5443\n","Loss =  tensor(0.0609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5444\n","Loss =  tensor(0.0600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5445\n","Loss =  tensor(0.0521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5446\n","Loss =  tensor(0.0606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5447\n","Loss =  tensor(0.0713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5448\n","Loss =  tensor(0.0615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5449\n","Loss =  tensor(0.0561, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5450\n","Loss =  tensor(0.0610, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5451\n","Loss =  tensor(0.0704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5452\n","Loss =  tensor(0.0464, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5453\n","Loss =  tensor(0.0522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5454\n","Loss =  tensor(0.0517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5455\n","Loss =  tensor(0.0582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5456\n","Loss =  tensor(0.0703, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5457\n","Loss =  tensor(0.0581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5458\n","Loss =  tensor(0.0661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5459\n","Loss =  tensor(0.0530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5460\n","Loss =  tensor(0.0640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5461\n","Loss =  tensor(0.0547, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5462\n","Loss =  tensor(0.0559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5463\n","Loss =  tensor(0.0690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5464\n","Loss =  tensor(0.0562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5465\n","Loss =  tensor(0.0672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5466\n","Loss =  tensor(0.0551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5467\n","Loss =  tensor(0.0620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5468\n","Loss =  tensor(0.0540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5469\n","Loss =  tensor(0.0579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5470\n","Loss =  tensor(0.0509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5471\n","Loss =  tensor(0.0452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5472\n","Loss =  tensor(0.0526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5473\n","Loss =  tensor(0.0568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5474\n","Loss =  tensor(0.0483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5475\n","Loss =  tensor(0.0437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5476\n","Loss =  tensor(0.0451, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5477\n","Loss =  tensor(0.0447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5478\n","Loss =  tensor(0.0519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5479\n","Loss =  tensor(0.0468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5480\n","Loss =  tensor(0.0524, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5481\n","Loss =  tensor(0.0453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5482\n","Loss =  tensor(0.0438, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5483\n","Loss =  tensor(0.0437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5484\n","Loss =  tensor(0.0580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5485\n","Loss =  tensor(0.0483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5486\n","Loss =  tensor(0.0490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5487\n","Loss =  tensor(0.0430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5488\n","Loss =  tensor(0.0490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5489\n","Loss =  tensor(0.0495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5490\n","Loss =  tensor(0.0514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5491\n","Loss =  tensor(0.0425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5492\n","Loss =  tensor(0.0460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5493\n","Loss =  tensor(0.0515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5494\n","Loss =  tensor(0.0431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5495\n","Loss =  tensor(0.0515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5496\n","Loss =  tensor(0.0391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5497\n","Loss =  tensor(0.0525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5498\n","Loss =  tensor(0.0493, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5499\n","Loss =  tensor(0.0522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5500\n","Loss =  tensor(0.0446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5501\n","Loss =  tensor(0.0380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5502\n","Loss =  tensor(0.0601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5503\n","Loss =  tensor(0.0570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5504\n","Loss =  tensor(0.0353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5505\n","Loss =  tensor(0.0460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5506\n","Loss =  tensor(0.0397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5507\n","Loss =  tensor(0.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5508\n","Loss =  tensor(0.0418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5509\n","Loss =  tensor(0.0439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5510\n","Loss =  tensor(0.0391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5511\n","Loss =  tensor(0.0405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5512\n","Loss =  tensor(0.0496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5513\n","Loss =  tensor(0.0527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5514\n","Loss =  tensor(0.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5515\n","Loss =  tensor(0.0530, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5516\n","Loss =  tensor(0.0520, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5517\n","Loss =  tensor(0.0627, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5518\n","Loss =  tensor(0.0467, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5519\n","Loss =  tensor(0.0502, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5520\n","Loss =  tensor(0.0477, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5521\n","Loss =  tensor(0.0381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5522\n","Loss =  tensor(0.0541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5523\n","Loss =  tensor(0.0426, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5524\n","Loss =  tensor(0.0469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5525\n","Loss =  tensor(0.0439, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5526\n","Loss =  tensor(0.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5527\n","Loss =  tensor(0.0454, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5528\n","Loss =  tensor(0.0391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5529\n","Loss =  tensor(0.0475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5530\n","Loss =  tensor(0.0513, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5531\n","Loss =  tensor(0.0403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5532\n","Loss =  tensor(0.0496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5533\n","Loss =  tensor(0.0596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5534\n","Loss =  tensor(0.0537, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5535\n","Loss =  tensor(0.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5536\n","Loss =  tensor(0.0484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5537\n","Loss =  tensor(0.0661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5538\n","Loss =  tensor(0.0537, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5539\n","Loss =  tensor(0.0572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5540\n","Loss =  tensor(0.0424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5541\n","Loss =  tensor(0.0512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5542\n","Loss =  tensor(0.0556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5543\n","Loss =  tensor(0.0446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5544\n","Loss =  tensor(0.0466, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5545\n","Loss =  tensor(0.0407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5546\n","Loss =  tensor(0.0450, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5547\n","Loss =  tensor(0.0427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5548\n","Loss =  tensor(0.0479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5549\n","Loss =  tensor(0.0366, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5550\n","Loss =  tensor(0.0384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5551\n","Loss =  tensor(0.0328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5552\n","Loss =  tensor(0.0430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5553\n","Loss =  tensor(0.0625, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5554\n","Loss =  tensor(0.0420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5555\n","Loss =  tensor(0.0588, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5556\n","Loss =  tensor(0.0396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5557\n","Loss =  tensor(0.0847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5558\n","Loss =  tensor(0.0525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5559\n","Loss =  tensor(0.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5560\n","Loss =  tensor(0.0604, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5561\n","Loss =  tensor(0.0803, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5562\n","Loss =  tensor(0.1192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5563\n","Loss =  tensor(0.1306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5564\n","Loss =  tensor(0.1485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5565\n","Loss =  tensor(0.0555, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  5566\n","Loss =  tensor(0.2418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5567\n","Loss =  tensor(0.0337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5568\n","Loss =  tensor(0.1649, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5569\n","Loss =  tensor(0.1063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5570\n","Loss =  tensor(0.0931, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5571\n","Loss =  tensor(0.0948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5572\n","Loss =  tensor(0.1290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5573\n","Loss =  tensor(0.0402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5574\n","Loss =  tensor(0.0709, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5575\n","Loss =  tensor(0.0642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5576\n","Loss =  tensor(0.0877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5577\n","Loss =  tensor(0.0394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5578\n","Loss =  tensor(0.0778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5579\n","Loss =  tensor(0.0590, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5580\n","Loss =  tensor(0.0478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5581\n","Loss =  tensor(0.0528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5582\n","Loss =  tensor(0.0600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5583\n","Loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5584\n","Loss =  tensor(0.0495, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5585\n","Loss =  tensor(0.0674, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5586\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5587\n","Loss =  tensor(0.0636, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5588\n","Loss =  tensor(0.0461, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5589\n","Loss =  tensor(0.0603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5590\n","Loss =  tensor(0.0384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5591\n","Loss =  tensor(0.0551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5592\n","Loss =  tensor(0.0518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5593\n","Loss =  tensor(0.0353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5594\n","Loss =  tensor(0.0584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5595\n","Loss =  tensor(0.0460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5596\n","Loss =  tensor(0.0754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5597\n","Loss =  tensor(0.0771, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5598\n","Loss =  tensor(0.0510, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5599\n","Loss =  tensor(0.1030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5600\n","Loss =  tensor(0.0391, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5601\n","Loss =  tensor(0.0809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5602\n","Loss =  tensor(0.0546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5603\n","Loss =  tensor(0.0663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5604\n","Loss =  tensor(0.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5605\n","Loss =  tensor(0.0383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5606\n","Loss =  tensor(0.1436, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5607\n","Loss =  tensor(0.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5608\n","Loss =  tensor(0.1207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5609\n","Loss =  tensor(0.0568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5610\n","Loss =  tensor(0.0506, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5611\n","Loss =  tensor(0.0981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5612\n","Loss =  tensor(0.0363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5613\n","Loss =  tensor(0.0676, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5614\n","Loss =  tensor(0.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5615\n","Loss =  tensor(0.0736, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5616\n","Loss =  tensor(0.0288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5617\n","Loss =  tensor(0.0512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5618\n","Loss =  tensor(0.0634, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5619\n","Loss =  tensor(0.0380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5620\n","Loss =  tensor(0.0614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5621\n","Loss =  tensor(0.0536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5622\n","Loss =  tensor(0.0630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5623\n","Loss =  tensor(0.0392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5624\n","Loss =  tensor(0.0769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5625\n","Loss =  tensor(0.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5626\n","Loss =  tensor(0.0532, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5627\n","Loss =  tensor(0.0934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5628\n","Loss =  tensor(0.0472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5629\n","Loss =  tensor(0.0521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5630\n","Loss =  tensor(0.0415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5631\n","Loss =  tensor(0.0369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5632\n","Loss =  tensor(0.0755, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5633\n","Loss =  tensor(0.0303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5634\n","Loss =  tensor(0.0486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5635\n","Loss =  tensor(0.0706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5636\n","Loss =  tensor(0.0455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5637\n","Loss =  tensor(0.0420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5638\n","Loss =  tensor(0.0396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5639\n","Loss =  tensor(0.0489, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5640\n","Loss =  tensor(0.0249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5641\n","Loss =  tensor(0.0355, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5642\n","Loss =  tensor(0.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5643\n","Loss =  tensor(0.0238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5644\n","Loss =  tensor(0.0421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5645\n","Loss =  tensor(0.0330, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5646\n","Loss =  tensor(0.0349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5647\n","Loss =  tensor(0.0276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5648\n","Loss =  tensor(0.0453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5649\n","Loss =  tensor(0.0250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5650\n","Loss =  tensor(0.0481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5651\n","Loss =  tensor(0.0492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5652\n","Loss =  tensor(0.0852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5653\n","Loss =  tensor(0.0360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5654\n","Loss =  tensor(0.0954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5655\n","Loss =  tensor(0.0254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5656\n","Loss =  tensor(0.0819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5657\n","Loss =  tensor(0.0370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5658\n","Loss =  tensor(0.0481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5659\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5660\n","Loss =  tensor(0.0455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5661\n","Loss =  tensor(0.0344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5662\n","Loss =  tensor(0.0406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5663\n","Loss =  tensor(0.0437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5664\n","Loss =  tensor(0.0279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5665\n","Loss =  tensor(0.0380, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5666\n","Loss =  tensor(0.0243, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5667\n","Loss =  tensor(0.0345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5668\n","Loss =  tensor(0.0259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5669\n","Loss =  tensor(0.0290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5670\n","Loss =  tensor(0.0463, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5671\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5672\n","Loss =  tensor(0.0313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5673\n","Loss =  tensor(0.0202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5674\n","Loss =  tensor(0.0501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5675\n","Loss =  tensor(0.0307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5676\n","Loss =  tensor(0.0452, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5677\n","Loss =  tensor(0.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5678\n","Loss =  tensor(0.0508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5679\n","Loss =  tensor(0.0301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5680\n","Loss =  tensor(0.0431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5681\n","Loss =  tensor(0.0356, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5682\n","Loss =  tensor(0.0310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5683\n","Loss =  tensor(0.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5684\n","Loss =  tensor(0.0270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5685\n","Loss =  tensor(0.0254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5686\n","Loss =  tensor(0.0313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5687\n","Loss =  tensor(0.0215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5688\n","Loss =  tensor(0.0302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5689\n","Loss =  tensor(0.0237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5690\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5691\n","Loss =  tensor(0.0241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5692\n","Loss =  tensor(0.0293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5693\n","Loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5694\n","Loss =  tensor(0.0241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5695\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5696\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5697\n","Loss =  tensor(0.0230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5698\n","Loss =  tensor(0.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5699\n","Loss =  tensor(0.0212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5700\n","Loss =  tensor(0.0190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5701\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5702\n","Loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5703\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5704\n","Loss =  tensor(0.0251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5705\n","Loss =  tensor(0.0201, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5706\n","Loss =  tensor(0.0210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5707\n","Loss =  tensor(0.0201, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5708\n","Loss =  tensor(0.0317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5709\n","Loss =  tensor(0.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5710\n","Loss =  tensor(0.0222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5711\n","Loss =  tensor(0.0284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5712\n","Loss =  tensor(0.0189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5713\n","Loss =  tensor(0.0231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5714\n","Loss =  tensor(0.0205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5715\n","Loss =  tensor(0.0191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5716\n","Loss =  tensor(0.0157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5717\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5718\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5719\n","Loss =  tensor(0.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5720\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5721\n","Loss =  tensor(0.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5722\n","Loss =  tensor(0.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5723\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5724\n","Loss =  tensor(0.0147, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5725\n","Loss =  tensor(0.0201, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5726\n","Loss =  tensor(0.0156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5727\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5728\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5729\n","Loss =  tensor(0.0212, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5730\n","Loss =  tensor(0.0176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5731\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5732\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5733\n","Loss =  tensor(0.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5734\n","Loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5735\n","Loss =  tensor(0.0174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5736\n","Loss =  tensor(0.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5737\n","Loss =  tensor(0.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5738\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5739\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5740\n","Loss =  tensor(0.0231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5741\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5742\n","Loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5743\n","Loss =  tensor(0.0216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5744\n","Loss =  tensor(0.0200, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5745\n","Loss =  tensor(0.0266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5746\n","Loss =  tensor(0.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5747\n","Loss =  tensor(0.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5748\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5749\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5750\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5751\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5752\n","Loss =  tensor(0.0198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5753\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5754\n","Loss =  tensor(0.0192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5755\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5756\n","Loss =  tensor(0.0145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5757\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5758\n","Loss =  tensor(0.0160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5759\n","Loss =  tensor(0.0170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5760\n","Loss =  tensor(0.0190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5761\n","Loss =  tensor(0.0153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5762\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5763\n","Loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5764\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5765\n","Loss =  tensor(0.0159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5766\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5767\n","Loss =  tensor(0.0282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5768\n","Loss =  tensor(0.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5769\n","Loss =  tensor(0.0252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5770\n","Loss =  tensor(0.0173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5771\n","Loss =  tensor(0.0262, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5772\n","Loss =  tensor(0.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5773\n","Loss =  tensor(0.0217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5774\n","Loss =  tensor(0.0175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5775\n","Loss =  tensor(0.0338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5776\n","Loss =  tensor(0.0207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5777\n","Loss =  tensor(0.0335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5778\n","Loss =  tensor(0.0218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  5779\n","Loss =  tensor(0.0260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5780\n","Loss =  tensor(0.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5781\n","Loss =  tensor(0.0318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5782\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5783\n","Loss =  tensor(0.0233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5784\n","Loss =  tensor(0.0421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5785\n","Loss =  tensor(0.0273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5786\n","Loss =  tensor(0.0271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5787\n","Loss =  tensor(0.0381, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5788\n","Loss =  tensor(0.0174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5789\n","Loss =  tensor(0.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5790\n","Loss =  tensor(0.0324, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5791\n","Loss =  tensor(0.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5792\n","Loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5793\n","Loss =  tensor(0.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5794\n","Loss =  tensor(0.0303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5795\n","Loss =  tensor(0.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5796\n","Loss =  tensor(0.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5797\n","Loss =  tensor(0.0232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5798\n","Loss =  tensor(0.0192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5799\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5800\n","Loss =  tensor(0.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5801\n","Loss =  tensor(0.0326, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5802\n","Loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5803\n","Loss =  tensor(0.0308, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5804\n","Loss =  tensor(0.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5805\n","Loss =  tensor(0.0271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5806\n","Loss =  tensor(0.0152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5807\n","Loss =  tensor(0.0276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5808\n","Loss =  tensor(0.0184, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5809\n","Loss =  tensor(0.0224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5810\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5811\n","Loss =  tensor(0.0342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5812\n","Loss =  tensor(0.0139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5813\n","Loss =  tensor(0.0252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5814\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5815\n","Loss =  tensor(0.0147, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5816\n","Loss =  tensor(0.0153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5817\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5818\n","Loss =  tensor(0.0155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5819\n","Loss =  tensor(0.0205, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5820\n","Loss =  tensor(0.0118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5821\n","Loss =  tensor(0.0278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5822\n","Loss =  tensor(0.0144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5823\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5824\n","Loss =  tensor(0.0152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5825\n","Loss =  tensor(0.0270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5826\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5827\n","Loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5828\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5829\n","Loss =  tensor(0.0202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5830\n","Loss =  tensor(0.0107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5831\n","Loss =  tensor(0.0232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5832\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5833\n","Loss =  tensor(0.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5834\n","Loss =  tensor(0.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5835\n","Loss =  tensor(0.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5836\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5837\n","Loss =  tensor(0.0118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5838\n","Loss =  tensor(0.0177, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5839\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5840\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5841\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5842\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5843\n","Loss =  tensor(0.0131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5844\n","Loss =  tensor(0.0159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5845\n","Loss =  tensor(0.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5846\n","Loss =  tensor(0.0127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5847\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5848\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5849\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5850\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5851\n","Loss =  tensor(0.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5852\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5853\n","Loss =  tensor(0.0128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5854\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5855\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5856\n","Loss =  tensor(0.0120, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5857\n","Loss =  tensor(0.0193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5858\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5859\n","Loss =  tensor(0.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5860\n","Loss =  tensor(0.0156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5861\n","Loss =  tensor(0.0196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5862\n","Loss =  tensor(0.0116, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5863\n","Loss =  tensor(0.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5864\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5865\n","Loss =  tensor(0.0154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5866\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5867\n","Loss =  tensor(0.0152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5868\n","Loss =  tensor(0.0107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5869\n","Loss =  tensor(0.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5870\n","Loss =  tensor(0.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5871\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5872\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5873\n","Loss =  tensor(0.0112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5874\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5875\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5876\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5877\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5878\n","Loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5879\n","Loss =  tensor(0.0105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5880\n","Loss =  tensor(0.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5881\n","Loss =  tensor(0.0103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5882\n","Loss =  tensor(0.0211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5883\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5884\n","Loss =  tensor(0.0211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5885\n","Loss =  tensor(0.0154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5886\n","Loss =  tensor(0.0161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5887\n","Loss =  tensor(0.0278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5888\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5889\n","Loss =  tensor(0.0300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5890\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5891\n","Loss =  tensor(0.0224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5892\n","Loss =  tensor(0.0145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5893\n","Loss =  tensor(0.0191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5894\n","Loss =  tensor(0.0257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5895\n","Loss =  tensor(0.0226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5896\n","Loss =  tensor(0.0246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5897\n","Loss =  tensor(0.0417, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5898\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5899\n","Loss =  tensor(0.0307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5900\n","Loss =  tensor(0.0227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5901\n","Loss =  tensor(0.0362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5902\n","Loss =  tensor(0.0247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5903\n","Loss =  tensor(0.0447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5904\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5905\n","Loss =  tensor(0.0377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5906\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5907\n","Loss =  tensor(0.0134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5908\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5909\n","Loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5910\n","Loss =  tensor(0.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5911\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5912\n","Loss =  tensor(0.0227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5913\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5914\n","Loss =  tensor(0.0201, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5915\n","Loss =  tensor(0.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5916\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5917\n","Loss =  tensor(0.0196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5918\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5919\n","Loss =  tensor(0.0192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5920\n","Loss =  tensor(0.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5921\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5922\n","Loss =  tensor(0.0076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5923\n","Loss =  tensor(0.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5924\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5925\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5926\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5927\n","Loss =  tensor(0.0146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5928\n","Loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5929\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5930\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5931\n","Loss =  tensor(0.0092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5932\n","Loss =  tensor(0.0251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5933\n","Loss =  tensor(0.0233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5934\n","Loss =  tensor(0.0265, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5935\n","Loss =  tensor(0.0264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5936\n","Loss =  tensor(0.0217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5937\n","Loss =  tensor(0.0266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5938\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5939\n","Loss =  tensor(0.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5940\n","Loss =  tensor(0.0126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5941\n","Loss =  tensor(0.0268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  5942\n","Loss =  tensor(0.0210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5943\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5944\n","Loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5945\n","Loss =  tensor(0.0174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5946\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5947\n","Loss =  tensor(0.0124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5948\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5949\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5950\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5951\n","Loss =  tensor(0.0103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5952\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5953\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5954\n","Loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5955\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5956\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5957\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5958\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5959\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5960\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5961\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5962\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5963\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5964\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5965\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5966\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5967\n","Loss =  tensor(0.0092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5968\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5969\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5970\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5971\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5972\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5973\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5974\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5975\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5976\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5977\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5978\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5979\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5980\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5981\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5982\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5983\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5984\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5985\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5986\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5987\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5988\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5989\n","Loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5990\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5991\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5992\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5993\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5994\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5995\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5996\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5997\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5998\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  5999\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6000\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6001\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6002\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6003\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6004\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6005\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6006\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6007\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6008\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6009\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6010\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6011\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6012\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6013\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6014\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6015\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6016\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6017\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6018\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6019\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6020\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6021\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6022\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6023\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6024\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6025\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6026\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6027\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6028\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6029\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6030\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6031\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6032\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6033\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6034\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6035\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6036\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6037\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6038\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6039\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6040\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6041\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6042\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6043\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6044\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6045\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6046\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6047\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6048\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6049\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6050\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6051\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6052\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6053\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6054\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6055\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6056\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6057\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6058\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6059\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6060\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6061\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6062\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6063\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6064\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6065\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6066\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6067\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6068\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6069\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6070\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6071\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6072\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6073\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6074\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6075\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6076\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6077\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6078\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6079\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6080\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6081\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6082\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6083\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6084\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6085\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6086\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6087\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6088\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6089\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6090\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6091\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6092\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6093\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6094\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6095\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6096\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6097\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6098\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6099\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6100\n","Loss =  tensor(0.0087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6101\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6102\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6103\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6104\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6105\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6106\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6107\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6108\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6109\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6110\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6111\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6112\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6113\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6114\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6115\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6116\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6117\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6118\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6119\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6120\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6121\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6122\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6123\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6124\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6125\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6126\n","Loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6127\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6128\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6129\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6130\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6131\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6132\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6133\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6134\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6135\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6136\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6137\n","Loss =  tensor(0.0087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6138\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6139\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6140\n","Loss =  tensor(0.0100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6141\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6142\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6143\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6144\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6145\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6146\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6147\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6148\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6149\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6150\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6151\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6152\n","Loss =  tensor(0.0128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6153\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6154\n","Loss =  tensor(0.0118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6155\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6156\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6157\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6158\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6159\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6160\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6161\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6162\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6163\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6164\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6165\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6166\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6167\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6168\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6169\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6170\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6171\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6172\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6173\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6174\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6175\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6176\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6177\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6178\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6179\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6180\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6181\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6182\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6183\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6184\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6185\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6186\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6187\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6188\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6189\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6190\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6191\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6192\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6193\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6194\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6195\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6196\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6197\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6198\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6199\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6200\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6201\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6202\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6203\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6204\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6205\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6206\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6207\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6208\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6209\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6210\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6211\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6212\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6213\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6214\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6215\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6216\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6217\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6218\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6219\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6220\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6221\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6222\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6223\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6224\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6225\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6226\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6227\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6228\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6229\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6230\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6231\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6232\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6233\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6234\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6235\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6236\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6237\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6238\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6239\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6240\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6241\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6242\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6243\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6244\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6245\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6246\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6247\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6248\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6249\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6250\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6251\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6252\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6253\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6254\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6255\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6256\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6257\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6258\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6259\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6260\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6261\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6262\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6263\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6264\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6265\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6266\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6267\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6268\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6269\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6270\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6271\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6272\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6273\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6274\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6275\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6276\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6277\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6278\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6279\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6280\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6281\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6282\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6283\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6284\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6285\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6286\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6287\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6288\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6289\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6290\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6291\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6292\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6293\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6294\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6295\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6296\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6297\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6298\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6299\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6300\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6301\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6302\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6303\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6304\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6305\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6306\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6307\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6308\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6309\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6310\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6311\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6312\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6313\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6314\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6315\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6316\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6317\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6318\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6319\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6320\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6321\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6322\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6323\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6324\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6325\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6326\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6327\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6328\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6329\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6330\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6331\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6332\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6333\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6334\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6335\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6336\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6337\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6338\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6339\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6340\n","Loss =  tensor(0.0155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6341\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6342\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6343\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6344\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6345\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6346\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6347\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6348\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6349\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6350\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6351\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6352\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6353\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6354\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6355\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6356\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6357\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6358\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6359\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6360\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6361\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6362\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6363\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6364\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6365\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6366\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6367\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6368\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6369\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6370\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6371\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6372\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6373\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6374\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6375\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6376\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6377\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6378\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6379\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6380\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6381\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6382\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6383\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6384\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6385\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6386\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6387\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6388\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6389\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6390\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6391\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6392\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6393\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6394\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6395\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6396\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6397\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6398\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6399\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6400\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6401\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6402\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6403\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6404\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6405\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6406\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6407\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6408\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6409\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6410\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6411\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6412\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6413\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6414\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6415\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6416\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6417\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6418\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6419\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6420\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6421\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6422\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6423\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6424\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6425\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6426\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6427\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6428\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6429\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6430\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6431\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6432\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6433\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6434\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6435\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6436\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6437\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6438\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6439\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6440\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6441\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6442\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6443\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6444\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6445\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6446\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6447\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6448\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6449\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6450\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6451\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6452\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6453\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6454\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6455\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6456\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6457\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6458\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6459\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6460\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6461\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6462\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6463\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6464\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6465\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6466\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6467\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6468\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6469\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6470\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6471\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6472\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6473\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6474\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6475\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6476\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6477\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6478\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6479\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6480\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6481\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6482\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6483\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6484\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6485\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6486\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6487\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6488\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6489\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6490\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6491\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6492\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6493\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6494\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6495\n","Loss =  tensor(0.0092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6496\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6497\n","Loss =  tensor(0.0133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6498\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6499\n","Loss =  tensor(0.0194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6500\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6501\n","Loss =  tensor(0.0111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6502\n","Loss =  tensor(0.0247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6503\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6504\n","Loss =  tensor(0.0515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6505\n","Loss =  tensor(0.0361, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6506\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6507\n","Loss =  tensor(0.0336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6508\n","Loss =  tensor(0.0239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6509\n","Loss =  tensor(0.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6510\n","Loss =  tensor(0.0896, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6511\n","Loss =  tensor(0.0757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6512\n","Loss =  tensor(0.0186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6513\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6514\n","Loss =  tensor(0.0278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6515\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6516\n","Loss =  tensor(0.0249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6517\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6518\n","Loss =  tensor(0.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6519\n","Loss =  tensor(0.0176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6520\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6521\n","Loss =  tensor(0.0321, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6522\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6523\n","Loss =  tensor(0.0474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6524\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6525\n","Loss =  tensor(0.0170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6526\n","Loss =  tensor(0.0388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6527\n","Loss =  tensor(0.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6528\n","Loss =  tensor(0.0561, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6529\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6530\n","Loss =  tensor(0.0523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6531\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6532\n","Loss =  tensor(0.0683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6533\n","Loss =  tensor(0.0368, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6534\n","Loss =  tensor(0.0291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6535\n","Loss =  tensor(0.1265, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6536\n","Loss =  tensor(0.0133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6537\n","Loss =  tensor(0.2092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6538\n","Loss =  tensor(0.1877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6539\n","Loss =  tensor(0.0702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6540\n","Loss =  tensor(0.1697, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6541\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6542\n","Loss =  tensor(0.1550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6543\n","Loss =  tensor(0.1783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6544\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6545\n","Loss =  tensor(0.1370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6546\n","Loss =  tensor(0.0895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6547\n","Loss =  tensor(0.0712, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6548\n","Loss =  tensor(0.1949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6549\n","Loss =  tensor(0.0432, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  6550\n","Loss =  tensor(0.2019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6551\n","Loss =  tensor(0.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6552\n","Loss =  tensor(0.0711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6553\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6554\n","Loss =  tensor(0.0435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6555\n","Loss =  tensor(0.0786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6556\n","Loss =  tensor(0.0310, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6557\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6558\n","Loss =  tensor(0.0254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6559\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6560\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6561\n","Loss =  tensor(0.0281, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6562\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6563\n","Loss =  tensor(0.0323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6564\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6565\n","Loss =  tensor(0.0144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6566\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6567\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6568\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6569\n","Loss =  tensor(0.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6570\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6571\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6572\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6573\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6574\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6575\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6576\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6577\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6578\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6579\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6580\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6581\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6582\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6583\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6584\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6585\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6586\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6587\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6588\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6589\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6590\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6591\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6592\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6593\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6594\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6595\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6596\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6597\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6598\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6599\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6600\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6601\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6602\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6603\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6604\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6605\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6606\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6607\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6608\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6609\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6610\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6611\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6612\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6613\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6614\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6615\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6616\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6617\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6618\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6619\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6620\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6621\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6622\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6623\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6624\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6625\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6626\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6627\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6628\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6629\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6630\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6631\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6632\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6633\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6634\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6635\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6636\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6637\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6638\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6639\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6640\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6641\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6642\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6643\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6644\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6645\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6646\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6647\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6648\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6649\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6650\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6651\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6652\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6653\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6654\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6655\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6656\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6657\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6658\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6659\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6660\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6661\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6662\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6663\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6664\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6665\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6666\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6667\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6668\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6669\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6670\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6671\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6672\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6673\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6674\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6675\n","Loss =  tensor(0.0133, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6676\n","Loss =  tensor(0.0076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6677\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6678\n","Loss =  tensor(0.0347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6679\n","Loss =  tensor(0.0374, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6680\n","Loss =  tensor(0.0295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6681\n","Loss =  tensor(0.0969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6682\n","Loss =  tensor(0.2445, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6683\n","Loss =  tensor(0.1458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6684\n","Loss =  tensor(0.1333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6685\n","Loss =  tensor(0.0973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6686\n","Loss =  tensor(0.0418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6687\n","Loss =  tensor(0.1199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6688\n","Loss =  tensor(0.0286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6689\n","Loss =  tensor(0.1385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6690\n","Loss =  tensor(0.0528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6691\n","Loss =  tensor(0.1843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6692\n","Loss =  tensor(0.0225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6693\n","Loss =  tensor(0.1519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6694\n","Loss =  tensor(0.0676, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6695\n","Loss =  tensor(0.0423, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6696\n","Loss =  tensor(0.2382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6697\n","Loss =  tensor(0.0609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6698\n","Loss =  tensor(0.0740, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  6699\n","Loss =  tensor(0.3560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6700\n","Loss =  tensor(0.1776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6701\n","Loss =  tensor(0.0814, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6702\n","Loss =  tensor(0.1987, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6703\n","Loss =  tensor(0.1369, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6704\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6705\n","Loss =  tensor(0.0880, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6706\n","Loss =  tensor(0.1576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6707\n","Loss =  tensor(0.0357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6708\n","Loss =  tensor(0.0422, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6709\n","Loss =  tensor(0.0922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6710\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6711\n","Loss =  tensor(0.0505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6712\n","Loss =  tensor(0.0562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6713\n","Loss =  tensor(0.0316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6714\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6715\n","Loss =  tensor(0.0336, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6716\n","Loss =  tensor(0.0292, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6717\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6718\n","Loss =  tensor(0.0401, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6719\n","Loss =  tensor(0.0173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6720\n","Loss =  tensor(0.0566, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6721\n","Loss =  tensor(0.0553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6722\n","Loss =  tensor(0.0471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6723\n","Loss =  tensor(0.1062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6724\n","Loss =  tensor(0.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6725\n","Loss =  tensor(0.0481, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6726\n","Loss =  tensor(0.1260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6727\n","Loss =  tensor(0.0137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6728\n","Loss =  tensor(0.0349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6729\n","Loss =  tensor(0.0131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6730\n","Loss =  tensor(0.0414, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6731\n","Loss =  tensor(0.0378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6732\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6733\n","Loss =  tensor(0.0160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6734\n","Loss =  tensor(0.0202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6735\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6736\n","Loss =  tensor(0.0311, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6737\n","Loss =  tensor(0.0095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6738\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6739\n","Loss =  tensor(0.0334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6740\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6741\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6742\n","Loss =  tensor(0.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6743\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6744\n","Loss =  tensor(0.0426, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6745\n","Loss =  tensor(0.0997, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6746\n","Loss =  tensor(0.0836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6747\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6748\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6749\n","Loss =  tensor(0.0156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6750\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6751\n","Loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6752\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6753\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6754\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6755\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6756\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6757\n","Loss =  tensor(0.0142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6758\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6759\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6760\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6761\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6762\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6763\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6764\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6765\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6766\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6767\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6768\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6769\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6770\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6771\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6772\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6773\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6774\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6775\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6776\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6777\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6778\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6779\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6780\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6781\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6782\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6783\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6784\n","Loss =  tensor(0.0131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6785\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6786\n","Loss =  tensor(0.0105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6787\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6788\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6789\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6790\n","Loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6791\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6792\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6793\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6794\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6795\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6796\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6797\n","Loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6798\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6799\n","Loss =  tensor(0.0111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6800\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6801\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6802\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6803\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6804\n","Loss =  tensor(0.0158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6805\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6806\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6807\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6808\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6809\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6810\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6811\n","Loss =  tensor(0.0242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6812\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6813\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6814\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6815\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6816\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6817\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6818\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6819\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6820\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6821\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6822\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6823\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6824\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6825\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6826\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6827\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6828\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6829\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6830\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6831\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6832\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6833\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6834\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6835\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6836\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6837\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6838\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6839\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6840\n","Loss =  tensor(9.0435e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6841\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6842\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6843\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6844\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6845\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6846\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6847\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6848\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6849\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6850\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6851\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6852\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6853\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6854\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6855\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6856\n","Loss =  tensor(0.0146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6857\n","Loss =  tensor(0.0393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6858\n","Loss =  tensor(0.0460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6859\n","Loss =  tensor(0.0338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6860\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6861\n","Loss =  tensor(0.0155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6862\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6863\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6864\n","Loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6865\n","Loss =  tensor(0.0337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6866\n","Loss =  tensor(0.0778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6867\n","Loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6868\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6869\n","Loss =  tensor(0.0433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6870\n","Loss =  tensor(0.0247, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6871\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6872\n","Loss =  tensor(0.0191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6873\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6874\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6875\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6876\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6877\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6878\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6879\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6880\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6881\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6882\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6883\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6884\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6885\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6886\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6887\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6888\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6889\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6890\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6891\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6892\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6893\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6894\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6895\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6896\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6897\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6898\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6899\n","Loss =  tensor(0.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6900\n","Loss =  tensor(0.0127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6901\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6902\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6903\n","Loss =  tensor(0.0235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6904\n","Loss =  tensor(0.0265, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6905\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6906\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6907\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6908\n","Loss =  tensor(0.0145, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6909\n","Loss =  tensor(0.0211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6910\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6911\n","Loss =  tensor(0.0305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6912\n","Loss =  tensor(0.0614, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6913\n","Loss =  tensor(0.1182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6914\n","Loss =  tensor(0.1198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6915\n","Loss =  tensor(0.0345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6916\n","Loss =  tensor(0.0490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6917\n","Loss =  tensor(0.0875, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6918\n","Loss =  tensor(0.0837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6919\n","Loss =  tensor(0.0218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6920\n","Loss =  tensor(0.0892, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6921\n","Loss =  tensor(0.0516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6922\n","Loss =  tensor(0.0257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6923\n","Loss =  tensor(0.0784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6924\n","Loss =  tensor(0.0076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6925\n","Loss =  tensor(0.0578, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6926\n","Loss =  tensor(0.0510, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6927\n","Loss =  tensor(0.0967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6928\n","Loss =  tensor(0.0730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6929\n","Loss =  tensor(0.0468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6930\n","Loss =  tensor(0.0651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  6931\n","Loss =  tensor(0.0775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  6932\n","Loss =  tensor(0.2218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  6933\n","Loss =  tensor(0.2235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6934\n","Loss =  tensor(0.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  6935\n","Loss =  tensor(0.3847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  6936\n","Loss =  tensor(0.5190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  6937\n","Loss =  tensor(0.5757, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  6938\n","Loss =  tensor(2.3467, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  6939\n","Loss =  tensor(5.4132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  6940\n","Loss =  tensor(8.1158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  6941\n","Loss =  tensor(8.4376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  6942\n","Loss =  tensor(1.0929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  6943\n","Loss =  tensor(2.6536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  6944\n","Loss =  tensor(7.5216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  6945\n","Loss =  tensor(2.5775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  6946\n","Loss =  tensor(13.5782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  6947\n","Loss =  tensor(3.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  6948\n","Loss =  tensor(1.3781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1990], grad_fn=<SelectBackward0>)\n","\n","Training step  6949\n","Loss =  tensor(14.3713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  6950\n","Loss =  tensor(21.9801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  6951\n","Loss =  tensor(9.2848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  6952\n","Loss =  tensor(22.7626, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  6953\n","Loss =  tensor(53.2480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  6954\n","Loss =  tensor(14.0427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  6955\n","Loss =  tensor(14.0453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  6956\n","Loss =  tensor(71.1377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1973], grad_fn=<SelectBackward0>)\n","\n","Training step  6957\n","Loss =  tensor(56.6854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  6958\n","Loss =  tensor(39.3418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  6959\n","Loss =  tensor(141.2195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1976], grad_fn=<SelectBackward0>)\n","\n","Training step  6960\n","Loss =  tensor(90.1584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  6961\n","Loss =  tensor(39.0776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2041], grad_fn=<SelectBackward0>)\n","\n","Training step  6962\n","Loss =  tensor(238.7700, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1956], grad_fn=<SelectBackward0>)\n","\n","Training step  6963\n","Loss =  tensor(204.4259, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  6964\n","Loss =  tensor(37.1585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  6965\n","Loss =  tensor(196.8738, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1967], grad_fn=<SelectBackward0>)\n","\n","Training step  6966\n","Loss =  tensor(107.8853, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1984], grad_fn=<SelectBackward0>)\n","\n","Training step  6967\n","Loss =  tensor(35.8480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  6968\n","Loss =  tensor(408.3410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1941], grad_fn=<SelectBackward0>)\n","\n","Training step  6969\n","Loss =  tensor(322.6099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  6970\n","Loss =  tensor(21.7758, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  6971\n","Loss =  tensor(300.4825, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1962], grad_fn=<SelectBackward0>)\n","\n","Training step  6972\n","Loss =  tensor(120.6978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1965], grad_fn=<SelectBackward0>)\n","\n","Training step  6973\n","Loss =  tensor(128.1844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  6974\n","Loss =  tensor(397.3835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  6975\n","Loss =  tensor(23.5939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1918], grad_fn=<SelectBackward0>)\n","\n","Training step  6976\n","Loss =  tensor(759.4105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2077], grad_fn=<SelectBackward0>)\n","\n","Training step  6977\n","Loss =  tensor(702.5284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  6978\n","Loss =  tensor(110.5525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1906], grad_fn=<SelectBackward0>)\n","\n","Training step  6979\n","Loss =  tensor(1211.8088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2152], grad_fn=<SelectBackward0>)\n","\n","Training step  6980\n","Loss =  tensor(2797.8953, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1900], grad_fn=<SelectBackward0>)\n","\n","Training step  6981\n","Loss =  tensor(1205.6617, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1949], grad_fn=<SelectBackward0>)\n","\n","Training step  6982\n","Loss =  tensor(325.2473, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2157], grad_fn=<SelectBackward0>)\n","\n","Training step  6983\n","Loss =  tensor(3744.6260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1762], grad_fn=<SelectBackward0>)\n","\n","Training step  6984\n","Loss =  tensor(7514.7471, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2189], grad_fn=<SelectBackward0>)\n","\n","Training step  6985\n","Loss =  tensor(4895.8257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1937], grad_fn=<SelectBackward0>)\n","\n","Training step  6986\n","Loss =  tensor(836.0642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1976], grad_fn=<SelectBackward0>)\n","\n","Training step  6987\n","Loss =  tensor(133.3596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  6988\n","Loss =  tensor(864.7511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  6989\n","Loss =  tensor(19.7477, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1923], grad_fn=<SelectBackward0>)\n","\n","Training step  6990\n","Loss =  tensor(811.8680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  6991\n","Loss =  tensor(1117.3917, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1959], grad_fn=<SelectBackward0>)\n","\n","Training step  6992\n","Loss =  tensor(326.1088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1952], grad_fn=<SelectBackward0>)\n","\n","Training step  6993\n","Loss =  tensor(199.0705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2057], grad_fn=<SelectBackward0>)\n","\n","Training step  6994\n","Loss =  tensor(284.6087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  6995\n","Loss =  tensor(383.3302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1871], grad_fn=<SelectBackward0>)\n","\n","Training step  6996\n","Loss =  tensor(2642.1584, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2226], grad_fn=<SelectBackward0>)\n","\n","Training step  6997\n","Loss =  tensor(4308.5039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2098], grad_fn=<SelectBackward0>)\n","\n","Training step  6998\n","Loss =  tensor(1466.8704, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1664], grad_fn=<SelectBackward0>)\n","\n","Training step  6999\n","Loss =  tensor(13993.8447, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  7000\n","Loss =  tensor(6767.1738, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2131], grad_fn=<SelectBackward0>)\n","\n","Training step  7001\n","Loss =  tensor(2321.8884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1697], grad_fn=<SelectBackward0>)\n","\n","Training step  7002\n","Loss =  tensor(11732.5459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  7003\n","Loss =  tensor(4272.0747, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2139], grad_fn=<SelectBackward0>)\n","\n","Training step  7004\n","Loss =  tensor(2842.6877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1694], grad_fn=<SelectBackward0>)\n","\n","Training step  7005\n","Loss =  tensor(13513.5947, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  7006\n","Loss =  tensor(3336.5383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2261], grad_fn=<SelectBackward0>)\n","\n","Training step  7007\n","Loss =  tensor(5493.5244, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1929], grad_fn=<SelectBackward0>)\n","\n","Training step  7008\n","Loss =  tensor(281.5350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1714], grad_fn=<SelectBackward0>)\n","\n","Training step  7009\n","Loss =  tensor(9491.1816, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  7010\n","Loss =  tensor(5406.8193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2114], grad_fn=<SelectBackward0>)\n","\n","Training step  7011\n","Loss =  tensor(2078.8411, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1743], grad_fn=<SelectBackward0>)\n","\n","Training step  7012\n","Loss =  tensor(14850.3115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2354], grad_fn=<SelectBackward0>)\n","\n","Training step  7013\n","Loss =  tensor(19301.8301, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  7014\n","Loss =  tensor(279.6339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1692], grad_fn=<SelectBackward0>)\n","\n","Training step  7015\n","Loss =  tensor(7817.4800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1849], grad_fn=<SelectBackward0>)\n","\n","Training step  7016\n","Loss =  tensor(4398.7920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2311], grad_fn=<SelectBackward0>)\n","\n","Training step  7017\n","Loss =  tensor(12988.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  7018\n","Loss =  tensor(955.3948, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1803], grad_fn=<SelectBackward0>)\n","\n","Training step  7019\n","Loss =  tensor(9316.0400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  7020\n","Loss =  tensor(1402.5867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2178], grad_fn=<SelectBackward0>)\n","\n","Training step  7021\n","Loss =  tensor(3274.1414, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  7022\n","Loss =  tensor(1968.5919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1858], grad_fn=<SelectBackward0>)\n","\n","Training step  7023\n","Loss =  tensor(5261.3110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1969], grad_fn=<SelectBackward0>)\n","\n","Training step  7024\n","Loss =  tensor(1508.6925, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  7025\n","Loss =  tensor(1419.2195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  7026\n","Loss =  tensor(387.7382, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1904], grad_fn=<SelectBackward0>)\n","\n","Training step  7027\n","Loss =  tensor(1212.0679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1913], grad_fn=<SelectBackward0>)\n","\n","Training step  7028\n","Loss =  tensor(1856.4148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2113], grad_fn=<SelectBackward0>)\n","\n","Training step  7029\n","Loss =  tensor(1926.4926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  7030\n","Loss =  tensor(475.5118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1913], grad_fn=<SelectBackward0>)\n","\n","Training step  7031\n","Loss =  tensor(2151.7983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1951], grad_fn=<SelectBackward0>)\n","\n","Training step  7032\n","Loss =  tensor(1655.5719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  7033\n","Loss =  tensor(1433.0721, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  7034\n","Loss =  tensor(355.2710, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1877], grad_fn=<SelectBackward0>)\n","\n","Training step  7035\n","Loss =  tensor(4409.1465, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2162], grad_fn=<SelectBackward0>)\n","\n","Training step  7036\n","Loss =  tensor(3828.8787, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  7037\n","Loss =  tensor(262.7061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1874], grad_fn=<SelectBackward0>)\n","\n","Training step  7038\n","Loss =  tensor(2310.2458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1943], grad_fn=<SelectBackward0>)\n","\n","Training step  7039\n","Loss =  tensor(477.6519, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  7040\n","Loss =  tensor(461.2161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  7041\n","Loss =  tensor(175.5443, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1975], grad_fn=<SelectBackward0>)\n","\n","Training step  7042\n","Loss =  tensor(291.1618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1933], grad_fn=<SelectBackward0>)\n","\n","Training step  7043\n","Loss =  tensor(587.8680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1971], grad_fn=<SelectBackward0>)\n","\n","Training step  7044\n","Loss =  tensor(595.1083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  7045\n","Loss =  tensor(476.1285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  7046\n","Loss =  tensor(108.8421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1947], grad_fn=<SelectBackward0>)\n","\n","Training step  7047\n","Loss =  tensor(499.2486, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1961], grad_fn=<SelectBackward0>)\n","\n","Training step  7048\n","Loss =  tensor(573.5634, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2054], grad_fn=<SelectBackward0>)\n","\n","Training step  7049\n","Loss =  tensor(582.4724, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  7050\n","Loss =  tensor(55.1782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1947], grad_fn=<SelectBackward0>)\n","\n","Training step  7051\n","Loss =  tensor(588.9651, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  7052\n","Loss =  tensor(359.6290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  7053\n","Loss =  tensor(96.2052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  7054\n","Loss =  tensor(69.3089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1968], grad_fn=<SelectBackward0>)\n","\n","Training step  7055\n","Loss =  tensor(319.0323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7056\n","Loss =  tensor(247.5295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7057\n","Loss =  tensor(49.1385, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7058\n","Loss =  tensor(31.1650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  7059\n","Loss =  tensor(149.7468, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  7060\n","Loss =  tensor(141.8730, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7061\n","Loss =  tensor(63.7065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  7062\n","Loss =  tensor(17.6328, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  7063\n","Loss =  tensor(92.1288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  7064\n","Loss =  tensor(137.7459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  7065\n","Loss =  tensor(26.3045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  7066\n","Loss =  tensor(115.6656, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  7067\n","Loss =  tensor(29.6714, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1967], grad_fn=<SelectBackward0>)\n","\n","Training step  7068\n","Loss =  tensor(176.4808, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  7069\n","Loss =  tensor(45.8701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  7070\n","Loss =  tensor(118.7253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1976], grad_fn=<SelectBackward0>)\n","\n","Training step  7071\n","Loss =  tensor(56.0318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1971], grad_fn=<SelectBackward0>)\n","\n","Training step  7072\n","Loss =  tensor(108.1421, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  7073\n","Loss =  tensor(90.3591, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  7074\n","Loss =  tensor(22.5702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  7075\n","Loss =  tensor(7.3246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1979], grad_fn=<SelectBackward0>)\n","\n","Training step  7076\n","Loss =  tensor(88.1511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  7077\n","Loss =  tensor(39.2425, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  7078\n","Loss =  tensor(39.6501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1979], grad_fn=<SelectBackward0>)\n","\n","Training step  7079\n","Loss =  tensor(50.5685, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  7080\n","Loss =  tensor(43.6995, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  7081\n","Loss =  tensor(75.7798, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7082\n","Loss =  tensor(2.2250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1978], grad_fn=<SelectBackward0>)\n","\n","Training step  7083\n","Loss =  tensor(51.0273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  7084\n","Loss =  tensor(12.0412, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  7085\n","Loss =  tensor(37.7643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  7086\n","Loss =  tensor(16.3949, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1979], grad_fn=<SelectBackward0>)\n","\n","Training step  7087\n","Loss =  tensor(45.5096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1990], grad_fn=<SelectBackward0>)\n","\n","Training step  7088\n","Loss =  tensor(8.3466, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  7089\n","Loss =  tensor(44.1984, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  7090\n","Loss =  tensor(8.4129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  7091\n","Loss =  tensor(34.4290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1988], grad_fn=<SelectBackward0>)\n","\n","Training step  7092\n","Loss =  tensor(12.0410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  7093\n","Loss =  tensor(20.3683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  7094\n","Loss =  tensor(20.9670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  7095\n","Loss =  tensor(22.4655, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  7096\n","Loss =  tensor(23.6420, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  7097\n","Loss =  tensor(12.0189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  7098\n","Loss =  tensor(22.1475, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7099\n","Loss =  tensor(1.7741, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  7100\n","Loss =  tensor(14.2017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  7101\n","Loss =  tensor(8.4661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  7102\n","Loss =  tensor(26.7498, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7103\n","Loss =  tensor(0.5553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  7104\n","Loss =  tensor(23.9978, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7105\n","Loss =  tensor(4.0711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  7106\n","Loss =  tensor(22.0389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1990], grad_fn=<SelectBackward0>)\n","\n","Training step  7107\n","Loss =  tensor(7.4518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  7108\n","Loss =  tensor(19.6731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  7109\n","Loss =  tensor(20.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7110\n","Loss =  tensor(1.7256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  7111\n","Loss =  tensor(16.4119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7112\n","Loss =  tensor(1.9134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  7113\n","Loss =  tensor(7.0810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7114\n","Loss =  tensor(1.0601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  7115\n","Loss =  tensor(8.1679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7116\n","Loss =  tensor(1.5544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  7117\n","Loss =  tensor(2.4353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7118\n","Loss =  tensor(2.8450, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7119\n","Loss =  tensor(3.8193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7120\n","Loss =  tensor(0.8034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7121\n","Loss =  tensor(1.4524, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7122\n","Loss =  tensor(1.4458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  7123\n","Loss =  tensor(3.3180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7124\n","Loss =  tensor(1.2999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  7125\n","Loss =  tensor(5.1602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7126\n","Loss =  tensor(1.1999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7127\n","Loss =  tensor(2.7643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7128\n","Loss =  tensor(1.4274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7129\n","Loss =  tensor(0.9479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7130\n","Loss =  tensor(0.4072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7131\n","Loss =  tensor(2.2767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7132\n","Loss =  tensor(1.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7133\n","Loss =  tensor(1.8540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7134\n","Loss =  tensor(1.5124, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7135\n","Loss =  tensor(1.9483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7136\n","Loss =  tensor(1.9579, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7137\n","Loss =  tensor(1.4399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7138\n","Loss =  tensor(2.4117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7139\n","Loss =  tensor(0.6984, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7140\n","Loss =  tensor(1.0635, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7141\n","Loss =  tensor(0.3101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7142\n","Loss =  tensor(0.5375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7143\n","Loss =  tensor(0.6347, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7144\n","Loss =  tensor(0.5608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7145\n","Loss =  tensor(0.8767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7146\n","Loss =  tensor(0.7090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7147\n","Loss =  tensor(2.2936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7148\n","Loss =  tensor(1.6234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7149\n","Loss =  tensor(0.3066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7150\n","Loss =  tensor(1.7558, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7151\n","Loss =  tensor(0.8234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7152\n","Loss =  tensor(0.5683, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7153\n","Loss =  tensor(0.3284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7154\n","Loss =  tensor(0.9220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7155\n","Loss =  tensor(1.0098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7156\n","Loss =  tensor(0.2335, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7157\n","Loss =  tensor(0.3603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7158\n","Loss =  tensor(0.6543, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7159\n","Loss =  tensor(0.6056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7160\n","Loss =  tensor(0.1689, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7161\n","Loss =  tensor(0.1611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7162\n","Loss =  tensor(0.4134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7163\n","Loss =  tensor(0.4525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7164\n","Loss =  tensor(0.0668, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7165\n","Loss =  tensor(0.1151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7166\n","Loss =  tensor(0.5188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7167\n","Loss =  tensor(0.1858, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7168\n","Loss =  tensor(0.0416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7169\n","Loss =  tensor(0.0918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7170\n","Loss =  tensor(0.2227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7171\n","Loss =  tensor(0.2274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7172\n","Loss =  tensor(0.0950, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7173\n","Loss =  tensor(0.2320, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7174\n","Loss =  tensor(0.1390, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7175\n","Loss =  tensor(0.2630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7176\n","Loss =  tensor(0.1097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7177\n","Loss =  tensor(0.0488, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7178\n","Loss =  tensor(0.1914, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7179\n","Loss =  tensor(0.0982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7180\n","Loss =  tensor(0.1352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7181\n","Loss =  tensor(0.0330, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7182\n","Loss =  tensor(0.1847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7183\n","Loss =  tensor(0.0686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7184\n","Loss =  tensor(0.1207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7185\n","Loss =  tensor(0.0211, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7186\n","Loss =  tensor(0.0802, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7187\n","Loss =  tensor(0.0637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7188\n","Loss =  tensor(0.0829, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7189\n","Loss =  tensor(0.0243, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7190\n","Loss =  tensor(0.0264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7191\n","Loss =  tensor(0.0462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7192\n","Loss =  tensor(0.0559, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7193\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7194\n","Loss =  tensor(0.0250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7195\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7196\n","Loss =  tensor(0.0454, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7197\n","Loss =  tensor(0.0202, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7198\n","Loss =  tensor(0.0256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7199\n","Loss =  tensor(0.0242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7200\n","Loss =  tensor(0.0360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7201\n","Loss =  tensor(0.0176, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7202\n","Loss =  tensor(0.0316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7203\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7204\n","Loss =  tensor(0.0409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7205\n","Loss =  tensor(0.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7206\n","Loss =  tensor(0.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7207\n","Loss =  tensor(0.0190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7208\n","Loss =  tensor(0.0459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7209\n","Loss =  tensor(0.0156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7210\n","Loss =  tensor(0.0576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7211\n","Loss =  tensor(0.0620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7212\n","Loss =  tensor(0.0410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7213\n","Loss =  tensor(0.0553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7214\n","Loss =  tensor(0.0536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7215\n","Loss =  tensor(0.0812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7216\n","Loss =  tensor(0.0126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7217\n","Loss =  tensor(0.0403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7218\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7219\n","Loss =  tensor(0.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7220\n","Loss =  tensor(0.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7221\n","Loss =  tensor(0.0317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7222\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7223\n","Loss =  tensor(0.0410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7224\n","Loss =  tensor(0.0104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7225\n","Loss =  tensor(0.0444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7226\n","Loss =  tensor(0.0085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7227\n","Loss =  tensor(0.0539, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7228\n","Loss =  tensor(0.0337, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7229\n","Loss =  tensor(0.0186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7230\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7231\n","Loss =  tensor(0.0264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7232\n","Loss =  tensor(0.0345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7233\n","Loss =  tensor(0.0275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7234\n","Loss =  tensor(0.0800, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7235\n","Loss =  tensor(0.0103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7236\n","Loss =  tensor(0.0640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7237\n","Loss =  tensor(0.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7238\n","Loss =  tensor(0.1175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7239\n","Loss =  tensor(0.0207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7240\n","Loss =  tensor(0.1589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7241\n","Loss =  tensor(0.0309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7242\n","Loss =  tensor(0.0895, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7243\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7244\n","Loss =  tensor(0.0855, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7245\n","Loss =  tensor(0.0573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7246\n","Loss =  tensor(0.0607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7247\n","Loss =  tensor(0.0479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7248\n","Loss =  tensor(0.0743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7249\n","Loss =  tensor(0.0851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7250\n","Loss =  tensor(0.1197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7251\n","Loss =  tensor(0.1379, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7252\n","Loss =  tensor(0.1042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7253\n","Loss =  tensor(0.2455, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7254\n","Loss =  tensor(0.1317, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7255\n","Loss =  tensor(0.1426, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7256\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7257\n","Loss =  tensor(0.0937, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7258\n","Loss =  tensor(0.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7259\n","Loss =  tensor(0.0340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7260\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7261\n","Loss =  tensor(0.0419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7262\n","Loss =  tensor(0.0344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7263\n","Loss =  tensor(0.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7264\n","Loss =  tensor(0.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7265\n","Loss =  tensor(0.0186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7266\n","Loss =  tensor(0.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7267\n","Loss =  tensor(0.0260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7268\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7269\n","Loss =  tensor(0.0207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7270\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7271\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7272\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7273\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7274\n","Loss =  tensor(0.0109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7275\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7276\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7277\n","Loss =  tensor(0.0364, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7278\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7279\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7280\n","Loss =  tensor(0.0153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7281\n","Loss =  tensor(0.0221, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7282\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7283\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7284\n","Loss =  tensor(0.0105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7285\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7286\n","Loss =  tensor(0.0130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7287\n","Loss =  tensor(0.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7288\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7289\n","Loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7290\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7291\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7292\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7293\n","Loss =  tensor(0.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7294\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7295\n","Loss =  tensor(0.0189, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7296\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7297\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7298\n","Loss =  tensor(0.0195, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7299\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7300\n","Loss =  tensor(0.0206, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7301\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7302\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7303\n","Loss =  tensor(0.0085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7304\n","Loss =  tensor(0.0111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7305\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7306\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7307\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7308\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7309\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7310\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7311\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7312\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7313\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7314\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7315\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7316\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7317\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7318\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7319\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7320\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7321\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7322\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7323\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7324\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7325\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7326\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7327\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7328\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7329\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7330\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7331\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7332\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7333\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7334\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7335\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7336\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7337\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7338\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7339\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7340\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7341\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7342\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7343\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7344\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7345\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7346\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7347\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7348\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7349\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7350\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7351\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7352\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7353\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7354\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7355\n","Loss =  tensor(0.0123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7356\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7357\n","Loss =  tensor(0.0100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7358\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7359\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7360\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7361\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7362\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7363\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7364\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7365\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7366\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7367\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7368\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7369\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7370\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7371\n","Loss =  tensor(0.0304, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7372\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7373\n","Loss =  tensor(0.0215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7374\n","Loss =  tensor(0.0237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7375\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7376\n","Loss =  tensor(0.0482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7377\n","Loss =  tensor(0.0357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7378\n","Loss =  tensor(0.0188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7379\n","Loss =  tensor(0.0279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7380\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7381\n","Loss =  tensor(0.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7382\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7383\n","Loss =  tensor(0.0144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7384\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7385\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7386\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7387\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7388\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7389\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7390\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7391\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7392\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7393\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7394\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7395\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7396\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7397\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7398\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7399\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7400\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7401\n","Loss =  tensor(0.0235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7402\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7403\n","Loss =  tensor(0.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7404\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7405\n","Loss =  tensor(0.0169, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7406\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7407\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7408\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7409\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7410\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7411\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7412\n","Loss =  tensor(0.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7413\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7414\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7415\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7416\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7417\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7418\n","Loss =  tensor(0.0199, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7419\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7420\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7421\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7422\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7423\n","Loss =  tensor(0.0516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7424\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7425\n","Loss =  tensor(0.0430, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7426\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7427\n","Loss =  tensor(0.0581, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7428\n","Loss =  tensor(0.0535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7429\n","Loss =  tensor(0.0388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7430\n","Loss =  tensor(0.0843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7431\n","Loss =  tensor(0.0376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7432\n","Loss =  tensor(0.1093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7433\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7434\n","Loss =  tensor(0.1182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7435\n","Loss =  tensor(0.0650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7436\n","Loss =  tensor(0.0514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7437\n","Loss =  tensor(0.0470, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7438\n","Loss =  tensor(0.0526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7439\n","Loss =  tensor(0.0485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7440\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7441\n","Loss =  tensor(0.0480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7442\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7443\n","Loss =  tensor(0.0706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7444\n","Loss =  tensor(0.0089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7445\n","Loss =  tensor(0.0528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7446\n","Loss =  tensor(0.0414, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7447\n","Loss =  tensor(0.0245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7448\n","Loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7449\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7450\n","Loss =  tensor(0.0217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7451\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7452\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7453\n","Loss =  tensor(0.0291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7454\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7455\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7456\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7457\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7458\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7459\n","Loss =  tensor(0.0098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7460\n","Loss =  tensor(0.0250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7461\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7462\n","Loss =  tensor(0.0333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7463\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7464\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7465\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7466\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7467\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7468\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7469\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7470\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7471\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7472\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7473\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7474\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7475\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7476\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7477\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7478\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7479\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7480\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7481\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7482\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7483\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7484\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7485\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7486\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7487\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7488\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7489\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7490\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7491\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7492\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7493\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7494\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7495\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7496\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7497\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7498\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7499\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7500\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7501\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7502\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7503\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7504\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7505\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7506\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7507\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7508\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7509\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7510\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7511\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7512\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7513\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7514\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7515\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7516\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7517\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7518\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7519\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7520\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7521\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7522\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7523\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7524\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7525\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7526\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7527\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7528\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7529\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7530\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7531\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7532\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7533\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7534\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7535\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7536\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7537\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7538\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7539\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7540\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7541\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7542\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7543\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7544\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7545\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7546\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7547\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7548\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7549\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7550\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7551\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7552\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7553\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7554\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7555\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7556\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7557\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7558\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7559\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7560\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7561\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7562\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7563\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7564\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7565\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7566\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7567\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7568\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7569\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7570\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7571\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7572\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7573\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7574\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7575\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7576\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7577\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7578\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7579\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7580\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7581\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7582\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7583\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7584\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7585\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7586\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7587\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7588\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7589\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7590\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7591\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7592\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7593\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7594\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7595\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7596\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7597\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7598\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7599\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7600\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7601\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7602\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7603\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7604\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7605\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7606\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7607\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7608\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7609\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7610\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7611\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7612\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7613\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7614\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7615\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7616\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7617\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7618\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7619\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7620\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7621\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7622\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7623\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7624\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7625\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7626\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7627\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7628\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7629\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7630\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7631\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7632\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7633\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7634\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7635\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7636\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7637\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7638\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7639\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7640\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7641\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7642\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7643\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7644\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7645\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7646\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7647\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7648\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7649\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7650\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7651\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7652\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7653\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7654\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7655\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7656\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7657\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7658\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7659\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7660\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7661\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7662\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7663\n","Loss =  tensor(9.1352e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7664\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7665\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7666\n","Loss =  tensor(9.1275e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7667\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7668\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7669\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7670\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7671\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7672\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7673\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7674\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7675\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7676\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7677\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7678\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7679\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7680\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7681\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7682\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7683\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7684\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7685\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7686\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7687\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7688\n","Loss =  tensor(9.7110e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7689\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7690\n","Loss =  tensor(8.7142e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7691\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7692\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7693\n","Loss =  tensor(8.9242e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7694\n","Loss =  tensor(9.5785e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7695\n","Loss =  tensor(9.9107e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7696\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7697\n","Loss =  tensor(9.7609e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7698\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7699\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7700\n","Loss =  tensor(9.2076e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7701\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7702\n","Loss =  tensor(9.8467e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7703\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7704\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7705\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7706\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7707\n","Loss =  tensor(8.7826e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7708\n","Loss =  tensor(6.6457e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7709\n","Loss =  tensor(8.7921e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7710\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7711\n","Loss =  tensor(7.5826e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7712\n","Loss =  tensor(7.2988e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7713\n","Loss =  tensor(8.5334e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7714\n","Loss =  tensor(8.7534e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7715\n","Loss =  tensor(8.9028e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7716\n","Loss =  tensor(9.0069e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7717\n","Loss =  tensor(7.3282e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7718\n","Loss =  tensor(7.6006e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7719\n","Loss =  tensor(6.6417e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7720\n","Loss =  tensor(7.8761e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7721\n","Loss =  tensor(7.6703e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7722\n","Loss =  tensor(6.4683e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7723\n","Loss =  tensor(6.0568e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7724\n","Loss =  tensor(7.4518e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7725\n","Loss =  tensor(6.2849e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7726\n","Loss =  tensor(5.7515e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7727\n","Loss =  tensor(6.4185e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7728\n","Loss =  tensor(7.8618e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7729\n","Loss =  tensor(6.8583e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7730\n","Loss =  tensor(8.9497e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7731\n","Loss =  tensor(9.1009e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7732\n","Loss =  tensor(6.7887e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7733\n","Loss =  tensor(7.3427e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7734\n","Loss =  tensor(9.7204e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7735\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7736\n","Loss =  tensor(6.9784e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7737\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7738\n","Loss =  tensor(8.3419e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7739\n","Loss =  tensor(8.6352e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7740\n","Loss =  tensor(8.9818e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7741\n","Loss =  tensor(7.0261e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7742\n","Loss =  tensor(8.3951e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7743\n","Loss =  tensor(7.6084e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7744\n","Loss =  tensor(6.7530e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7745\n","Loss =  tensor(8.1121e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7746\n","Loss =  tensor(6.4365e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7747\n","Loss =  tensor(6.9336e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7748\n","Loss =  tensor(7.8213e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7749\n","Loss =  tensor(6.2361e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7750\n","Loss =  tensor(8.6093e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7751\n","Loss =  tensor(7.9278e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7752\n","Loss =  tensor(5.8039e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7753\n","Loss =  tensor(9.3571e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7754\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7755\n","Loss =  tensor(6.4861e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7756\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7757\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7758\n","Loss =  tensor(6.7371e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7759\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7760\n","Loss =  tensor(6.6845e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7761\n","Loss =  tensor(8.4056e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7762\n","Loss =  tensor(7.6247e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7763\n","Loss =  tensor(7.6349e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7764\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7765\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7766\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7767\n","Loss =  tensor(6.2820e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7768\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7769\n","Loss =  tensor(9.7815e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7770\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7771\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7772\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7773\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7774\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7775\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7776\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7777\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7778\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7779\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7780\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7781\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7782\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7783\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7784\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7785\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7786\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7787\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7788\n","Loss =  tensor(6.0172e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7789\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7790\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7791\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7792\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7793\n","Loss =  tensor(0.0107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7794\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7795\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7796\n","Loss =  tensor(0.0103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7797\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7798\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7799\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7800\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7801\n","Loss =  tensor(0.0157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7802\n","Loss =  tensor(0.0147, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7803\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7804\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7805\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7806\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7807\n","Loss =  tensor(0.0168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7808\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7809\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7810\n","Loss =  tensor(0.0231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7811\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7812\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7813\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7814\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7815\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7816\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7817\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7818\n","Loss =  tensor(0.0112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7819\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7820\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7821\n","Loss =  tensor(0.0138, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7822\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7823\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7824\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7825\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7826\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7827\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7828\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7829\n","Loss =  tensor(0.0215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7830\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7831\n","Loss =  tensor(0.0609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7832\n","Loss =  tensor(0.0142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7833\n","Loss =  tensor(0.0182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7834\n","Loss =  tensor(0.0229, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7835\n","Loss =  tensor(0.0162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7836\n","Loss =  tensor(0.0682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7837\n","Loss =  tensor(0.0268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7838\n","Loss =  tensor(0.0401, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7839\n","Loss =  tensor(0.0642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7840\n","Loss =  tensor(0.0419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7841\n","Loss =  tensor(0.2170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7842\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7843\n","Loss =  tensor(0.3300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7844\n","Loss =  tensor(0.6847, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7845\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7846\n","Loss =  tensor(0.7557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7847\n","Loss =  tensor(0.6396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7848\n","Loss =  tensor(0.0586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7849\n","Loss =  tensor(0.1920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7850\n","Loss =  tensor(0.5893, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7851\n","Loss =  tensor(0.4562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7852\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7853\n","Loss =  tensor(0.2302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7854\n","Loss =  tensor(0.0387, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7855\n","Loss =  tensor(0.2142, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7856\n","Loss =  tensor(0.3065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7857\n","Loss =  tensor(0.0261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7858\n","Loss =  tensor(0.2745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7859\n","Loss =  tensor(0.5585, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7860\n","Loss =  tensor(0.0512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7861\n","Loss =  tensor(0.4288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7862\n","Loss =  tensor(0.2761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7863\n","Loss =  tensor(0.0509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7864\n","Loss =  tensor(0.4864, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7865\n","Loss =  tensor(0.3031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7866\n","Loss =  tensor(0.0806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7867\n","Loss =  tensor(0.4812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7868\n","Loss =  tensor(0.0985, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7869\n","Loss =  tensor(0.1303, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7870\n","Loss =  tensor(0.1168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7871\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7872\n","Loss =  tensor(0.1344, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7873\n","Loss =  tensor(0.1544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7874\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7875\n","Loss =  tensor(0.2358, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7876\n","Loss =  tensor(0.1118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7877\n","Loss =  tensor(0.0484, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7878\n","Loss =  tensor(0.2424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7879\n","Loss =  tensor(0.0431, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7880\n","Loss =  tensor(0.2570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7881\n","Loss =  tensor(0.1991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7882\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7883\n","Loss =  tensor(0.2168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7884\n","Loss =  tensor(0.0154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7885\n","Loss =  tensor(0.1018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7886\n","Loss =  tensor(0.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7887\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7888\n","Loss =  tensor(0.0282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7889\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7890\n","Loss =  tensor(0.0215, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7891\n","Loss =  tensor(0.0503, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7892\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7893\n","Loss =  tensor(0.0609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7894\n","Loss =  tensor(0.0552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7895\n","Loss =  tensor(0.0345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7896\n","Loss =  tensor(0.0882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7897\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7898\n","Loss =  tensor(0.1238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7899\n","Loss =  tensor(0.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7900\n","Loss =  tensor(0.0670, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7901\n","Loss =  tensor(0.2002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7902\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7903\n","Loss =  tensor(0.0773, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7904\n","Loss =  tensor(0.2734, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7905\n","Loss =  tensor(0.2140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7906\n","Loss =  tensor(0.0566, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7907\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7908\n","Loss =  tensor(0.0639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7909\n","Loss =  tensor(0.0541, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7910\n","Loss =  tensor(0.0253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7911\n","Loss =  tensor(0.0289, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7912\n","Loss =  tensor(0.1044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7913\n","Loss =  tensor(0.2742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7914\n","Loss =  tensor(0.1156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7915\n","Loss =  tensor(0.0701, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7916\n","Loss =  tensor(0.1725, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7917\n","Loss =  tensor(0.0163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7918\n","Loss =  tensor(0.0630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7919\n","Loss =  tensor(0.1363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7920\n","Loss =  tensor(0.0570, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7921\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7922\n","Loss =  tensor(0.1139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7923\n","Loss =  tensor(0.0954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7924\n","Loss =  tensor(0.0224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7925\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7926\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7927\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7928\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7929\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7930\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7931\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7932\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7933\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7934\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7935\n","Loss =  tensor(0.0620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7936\n","Loss =  tensor(0.0274, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7937\n","Loss =  tensor(0.0620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7938\n","Loss =  tensor(0.1291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7939\n","Loss =  tensor(0.0302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7940\n","Loss =  tensor(0.0248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7941\n","Loss =  tensor(0.0398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7942\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7943\n","Loss =  tensor(0.0233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7944\n","Loss =  tensor(0.0290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7945\n","Loss =  tensor(0.0271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7946\n","Loss =  tensor(0.1394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7947\n","Loss =  tensor(0.2522, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7948\n","Loss =  tensor(0.4491, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7949\n","Loss =  tensor(0.5877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7950\n","Loss =  tensor(0.2376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7951\n","Loss =  tensor(0.0154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7952\n","Loss =  tensor(0.2266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7953\n","Loss =  tensor(0.2363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7954\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7955\n","Loss =  tensor(0.0392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7956\n","Loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7957\n","Loss =  tensor(0.5419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7958\n","Loss =  tensor(0.6653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7959\n","Loss =  tensor(0.0531, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7960\n","Loss =  tensor(0.1838, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7961\n","Loss =  tensor(0.3305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7962\n","Loss =  tensor(0.0574, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7963\n","Loss =  tensor(0.2306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7964\n","Loss =  tensor(0.5867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7965\n","Loss =  tensor(0.2190, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7966\n","Loss =  tensor(0.0248, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7967\n","Loss =  tensor(0.3026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7968\n","Loss =  tensor(0.1251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7969\n","Loss =  tensor(0.1641, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7970\n","Loss =  tensor(0.4002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7971\n","Loss =  tensor(0.0556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7972\n","Loss =  tensor(0.4759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7973\n","Loss =  tensor(0.9097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  7974\n","Loss =  tensor(0.1443, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  7975\n","Loss =  tensor(1.7079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  7976\n","Loss =  tensor(3.4876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7977\n","Loss =  tensor(3.5922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7978\n","Loss =  tensor(0.2472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  7979\n","Loss =  tensor(1.4848, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7980\n","Loss =  tensor(0.4667, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  7981\n","Loss =  tensor(0.6738, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7982\n","Loss =  tensor(0.8424, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7983\n","Loss =  tensor(0.1388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7984\n","Loss =  tensor(0.1427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  7985\n","Loss =  tensor(0.5416, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  7986\n","Loss =  tensor(0.1675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7987\n","Loss =  tensor(0.3783, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  7988\n","Loss =  tensor(1.8314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  7989\n","Loss =  tensor(2.8682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  7990\n","Loss =  tensor(0.4540, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  7991\n","Loss =  tensor(2.2918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  7992\n","Loss =  tensor(5.5743, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  7993\n","Loss =  tensor(2.2582, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  7994\n","Loss =  tensor(27.6198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  7995\n","Loss =  tensor(9.7673, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  7996\n","Loss =  tensor(19.0820, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  7997\n","Loss =  tensor(55.2578, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  7998\n","Loss =  tensor(47.8850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  7999\n","Loss =  tensor(22.7640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  8000\n","Loss =  tensor(24.3760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  8001\n","Loss =  tensor(32.2714, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8002\n","Loss =  tensor(9.1897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  8003\n","Loss =  tensor(45.1029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  8004\n","Loss =  tensor(35.7524, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8005\n","Loss =  tensor(3.8722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  8006\n","Loss =  tensor(21.6191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1974], grad_fn=<SelectBackward0>)\n","\n","Training step  8007\n","Loss =  tensor(75.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  8008\n","Loss =  tensor(38.3144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  8009\n","Loss =  tensor(15.5131, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1971], grad_fn=<SelectBackward0>)\n","\n","Training step  8010\n","Loss =  tensor(91.0993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  8011\n","Loss =  tensor(66.4711, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  8012\n","Loss =  tensor(14.7928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  8013\n","Loss =  tensor(5.8984, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2017], grad_fn=<SelectBackward0>)\n","\n","Training step  8014\n","Loss =  tensor(49.3323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1973], grad_fn=<SelectBackward0>)\n","\n","Training step  8015\n","Loss =  tensor(81.2227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  8016\n","Loss =  tensor(24.2477, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  8017\n","Loss =  tensor(1.3253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  8018\n","Loss =  tensor(17.4639, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  8019\n","Loss =  tensor(25.7135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  8020\n","Loss =  tensor(29.0877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  8021\n","Loss =  tensor(18.3676, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8022\n","Loss =  tensor(3.5722, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1981], grad_fn=<SelectBackward0>)\n","\n","Training step  8023\n","Loss =  tensor(30.3397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  8024\n","Loss =  tensor(8.8989, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  8025\n","Loss =  tensor(68.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1961], grad_fn=<SelectBackward0>)\n","\n","Training step  8026\n","Loss =  tensor(136.2779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8027\n","Loss =  tensor(45.7928, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  8028\n","Loss =  tensor(268.4008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1930], grad_fn=<SelectBackward0>)\n","\n","Training step  8029\n","Loss =  tensor(501.2246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  8030\n","Loss =  tensor(74.5876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2037], grad_fn=<SelectBackward0>)\n","\n","Training step  8031\n","Loss =  tensor(163.4563, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1934], grad_fn=<SelectBackward0>)\n","\n","Training step  8032\n","Loss =  tensor(543.4967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2053], grad_fn=<SelectBackward0>)\n","\n","Training step  8033\n","Loss =  tensor(178.2845, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2071], grad_fn=<SelectBackward0>)\n","\n","Training step  8034\n","Loss =  tensor(520.0857, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1932], grad_fn=<SelectBackward0>)\n","\n","Training step  8035\n","Loss =  tensor(510.6834, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  8036\n","Loss =  tensor(21.9159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  8037\n","Loss =  tensor(894.2200, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1873], grad_fn=<SelectBackward0>)\n","\n","Training step  8038\n","Loss =  tensor(1745.1742, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  8039\n","Loss =  tensor(62.0809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2101], grad_fn=<SelectBackward0>)\n","\n","Training step  8040\n","Loss =  tensor(1500.3026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1807], grad_fn=<SelectBackward0>)\n","\n","Training step  8041\n","Loss =  tensor(4788.9536, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2187], grad_fn=<SelectBackward0>)\n","\n","Training step  8042\n","Loss =  tensor(4115.9458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1982], grad_fn=<SelectBackward0>)\n","\n","Training step  8043\n","Loss =  tensor(394.6312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1834], grad_fn=<SelectBackward0>)\n","\n","Training step  8044\n","Loss =  tensor(2650.4702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  8045\n","Loss =  tensor(1065.4398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2076], grad_fn=<SelectBackward0>)\n","\n","Training step  8046\n","Loss =  tensor(853.7081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1779], grad_fn=<SelectBackward0>)\n","\n","Training step  8047\n","Loss =  tensor(4289.3496, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  8048\n","Loss =  tensor(47.7912, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2219], grad_fn=<SelectBackward0>)\n","\n","Training step  8049\n","Loss =  tensor(6245.4058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1747], grad_fn=<SelectBackward0>)\n","\n","Training step  8050\n","Loss =  tensor(7215.8462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  8051\n","Loss =  tensor(267.1769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2248], grad_fn=<SelectBackward0>)\n","\n","Training step  8052\n","Loss =  tensor(7993.6631, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1753], grad_fn=<SelectBackward0>)\n","\n","Training step  8053\n","Loss =  tensor(5647.4214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1837], grad_fn=<SelectBackward0>)\n","\n","Training step  8054\n","Loss =  tensor(1660.4600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2149], grad_fn=<SelectBackward0>)\n","\n","Training step  8055\n","Loss =  tensor(3430.0615, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1926], grad_fn=<SelectBackward0>)\n","\n","Training step  8056\n","Loss =  tensor(581.9377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1915], grad_fn=<SelectBackward0>)\n","\n","Training step  8057\n","Loss =  tensor(737.5428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2107], grad_fn=<SelectBackward0>)\n","\n","Training step  8058\n","Loss =  tensor(1226.8375, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  8059\n","Loss =  tensor(259.1938, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1846], grad_fn=<SelectBackward0>)\n","\n","Training step  8060\n","Loss =  tensor(1863.6360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1961], grad_fn=<SelectBackward0>)\n","\n","Training step  8061\n","Loss =  tensor(163.7754, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2088], grad_fn=<SelectBackward0>)\n","\n","Training step  8062\n","Loss =  tensor(1515.7679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1923], grad_fn=<SelectBackward0>)\n","\n","Training step  8063\n","Loss =  tensor(447.1609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1913], grad_fn=<SelectBackward0>)\n","\n","Training step  8064\n","Loss =  tensor(818.5524, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2097], grad_fn=<SelectBackward0>)\n","\n","Training step  8065\n","Loss =  tensor(1675.2091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1990], grad_fn=<SelectBackward0>)\n","\n","Training step  8066\n","Loss =  tensor(6.8113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1897], grad_fn=<SelectBackward0>)\n","\n","Training step  8067\n","Loss =  tensor(1052.5844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  8068\n","Loss =  tensor(560.8900, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8069\n","Loss =  tensor(17.1315, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1951], grad_fn=<SelectBackward0>)\n","\n","Training step  8070\n","Loss =  tensor(233.9535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1982], grad_fn=<SelectBackward0>)\n","\n","Training step  8071\n","Loss =  tensor(200.7478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  8072\n","Loss =  tensor(695.6613, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1936], grad_fn=<SelectBackward0>)\n","\n","Training step  8073\n","Loss =  tensor(313.6435, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1960], grad_fn=<SelectBackward0>)\n","\n","Training step  8074\n","Loss =  tensor(351.2150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  8075\n","Loss =  tensor(1141.2926, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1911], grad_fn=<SelectBackward0>)\n","\n","Training step  8076\n","Loss =  tensor(913.7355, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2023], grad_fn=<SelectBackward0>)\n","\n","Training step  8077\n","Loss =  tensor(251.5715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2070], grad_fn=<SelectBackward0>)\n","\n","Training step  8078\n","Loss =  tensor(576.1786, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8079\n","Loss =  tensor(160.6010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1938], grad_fn=<SelectBackward0>)\n","\n","Training step  8080\n","Loss =  tensor(540.1006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2092], grad_fn=<SelectBackward0>)\n","\n","Training step  8081\n","Loss =  tensor(931.8383, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  8082\n","Loss =  tensor(1180.1901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1852], grad_fn=<SelectBackward0>)\n","\n","Training step  8083\n","Loss =  tensor(3908.0601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2236], grad_fn=<SelectBackward0>)\n","\n","Training step  8084\n","Loss =  tensor(10223.5557, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1709], grad_fn=<SelectBackward0>)\n","\n","Training step  8085\n","Loss =  tensor(9375.0547, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1893], grad_fn=<SelectBackward0>)\n","\n","Training step  8086\n","Loss =  tensor(1995.0389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2299], grad_fn=<SelectBackward0>)\n","\n","Training step  8087\n","Loss =  tensor(9379.9805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2059], grad_fn=<SelectBackward0>)\n","\n","Training step  8088\n","Loss =  tensor(651.8359, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1697], grad_fn=<SelectBackward0>)\n","\n","Training step  8089\n","Loss =  tensor(9963.3828, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  8090\n","Loss =  tensor(1787.0334, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2213], grad_fn=<SelectBackward0>)\n","\n","Training step  8091\n","Loss =  tensor(5492.0601, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1942], grad_fn=<SelectBackward0>)\n","\n","Training step  8092\n","Loss =  tensor(668.1813, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1804], grad_fn=<SelectBackward0>)\n","\n","Training step  8093\n","Loss =  tensor(6958.9956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2147], grad_fn=<SelectBackward0>)\n","\n","Training step  8094\n","Loss =  tensor(3347.3252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2125], grad_fn=<SelectBackward0>)\n","\n","Training step  8095\n","Loss =  tensor(2393.5012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1752], grad_fn=<SelectBackward0>)\n","\n","Training step  8096\n","Loss =  tensor(9551.6309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1975], grad_fn=<SelectBackward0>)\n","\n","Training step  8097\n","Loss =  tensor(1806.6860, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2286], grad_fn=<SelectBackward0>)\n","\n","Training step  8098\n","Loss =  tensor(7573.7461, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2090], grad_fn=<SelectBackward0>)\n","\n","Training step  8099\n","Loss =  tensor(762.5167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1813], grad_fn=<SelectBackward0>)\n","\n","Training step  8100\n","Loss =  tensor(6686.4517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  8101\n","Loss =  tensor(1236.5806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  8102\n","Loss =  tensor(2393.3396, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1927], grad_fn=<SelectBackward0>)\n","\n","Training step  8103\n","Loss =  tensor(1586.9954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1852], grad_fn=<SelectBackward0>)\n","\n","Training step  8104\n","Loss =  tensor(6364.3545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2179], grad_fn=<SelectBackward0>)\n","\n","Training step  8105\n","Loss =  tensor(4383.1064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2161], grad_fn=<SelectBackward0>)\n","\n","Training step  8106\n","Loss =  tensor(3465.2139, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1793], grad_fn=<SelectBackward0>)\n","\n","Training step  8107\n","Loss =  tensor(8931.1025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8108\n","Loss =  tensor(927.0811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2239], grad_fn=<SelectBackward0>)\n","\n","Training step  8109\n","Loss =  tensor(7231.0762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1920], grad_fn=<SelectBackward0>)\n","\n","Training step  8110\n","Loss =  tensor(648.9910, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1776], grad_fn=<SelectBackward0>)\n","\n","Training step  8111\n","Loss =  tensor(5431.5474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  8112\n","Loss =  tensor(957.5047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2188], grad_fn=<SelectBackward0>)\n","\n","Training step  8113\n","Loss =  tensor(4411.1333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1973], grad_fn=<SelectBackward0>)\n","\n","Training step  8114\n","Loss =  tensor(229.6018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1848], grad_fn=<SelectBackward0>)\n","\n","Training step  8115\n","Loss =  tensor(3486.0427, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  8116\n","Loss =  tensor(613.1006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2203], grad_fn=<SelectBackward0>)\n","\n","Training step  8117\n","Loss =  tensor(5075.5161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1942], grad_fn=<SelectBackward0>)\n","\n","Training step  8118\n","Loss =  tensor(516.9020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1847], grad_fn=<SelectBackward0>)\n","\n","Training step  8119\n","Loss =  tensor(4548.7505, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2242], grad_fn=<SelectBackward0>)\n","\n","Training step  8120\n","Loss =  tensor(6893.5850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2183], grad_fn=<SelectBackward0>)\n","\n","Training step  8121\n","Loss =  tensor(3350.9092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1818], grad_fn=<SelectBackward0>)\n","\n","Training step  8122\n","Loss =  tensor(3561.9795, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1798], grad_fn=<SelectBackward0>)\n","\n","Training step  8123\n","Loss =  tensor(7693.9941, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2340], grad_fn=<SelectBackward0>)\n","\n","Training step  8124\n","Loss =  tensor(9391.3887, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2375], grad_fn=<SelectBackward0>)\n","\n","Training step  8125\n","Loss =  tensor(10223.9521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1977], grad_fn=<SelectBackward0>)\n","\n","Training step  8126\n","Loss =  tensor(158.8378, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1676], grad_fn=<SelectBackward0>)\n","\n","Training step  8127\n","Loss =  tensor(12502.4033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8128\n","Loss =  tensor(1218.7959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2331], grad_fn=<SelectBackward0>)\n","\n","Training step  8129\n","Loss =  tensor(10885.1172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2118], grad_fn=<SelectBackward0>)\n","\n","Training step  8130\n","Loss =  tensor(2246.4885, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1661], grad_fn=<SelectBackward0>)\n","\n","Training step  8131\n","Loss =  tensor(13324.9600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1808], grad_fn=<SelectBackward0>)\n","\n","Training step  8132\n","Loss =  tensor(4457.3525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2259], grad_fn=<SelectBackward0>)\n","\n","Training step  8133\n","Loss =  tensor(5571.3882, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2326], grad_fn=<SelectBackward0>)\n","\n","Training step  8134\n","Loss =  tensor(12951.6934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1781], grad_fn=<SelectBackward0>)\n","\n","Training step  8135\n","Loss =  tensor(7847.7769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1796], grad_fn=<SelectBackward0>)\n","\n","Training step  8136\n","Loss =  tensor(4305.6392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2068], grad_fn=<SelectBackward0>)\n","\n","Training step  8137\n","Loss =  tensor(1082.4407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2249], grad_fn=<SelectBackward0>)\n","\n","Training step  8138\n","Loss =  tensor(6961.8599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  8139\n","Loss =  tensor(466.5854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1804], grad_fn=<SelectBackward0>)\n","\n","Training step  8140\n","Loss =  tensor(7061.6279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8141\n","Loss =  tensor(1071.7113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2252], grad_fn=<SelectBackward0>)\n","\n","Training step  8142\n","Loss =  tensor(7567.6792, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  8143\n","Loss =  tensor(182.5806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1799], grad_fn=<SelectBackward0>)\n","\n","Training step  8144\n","Loss =  tensor(4010.8330, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1852], grad_fn=<SelectBackward0>)\n","\n","Training step  8145\n","Loss =  tensor(3406.7485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2116], grad_fn=<SelectBackward0>)\n","\n","Training step  8146\n","Loss =  tensor(2820.8572, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2203], grad_fn=<SelectBackward0>)\n","\n","Training step  8147\n","Loss =  tensor(5732.8130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1951], grad_fn=<SelectBackward0>)\n","\n","Training step  8148\n","Loss =  tensor(793.8784, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1858], grad_fn=<SelectBackward0>)\n","\n","Training step  8149\n","Loss =  tensor(2531.9922, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  8150\n","Loss =  tensor(1720.4836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2150], grad_fn=<SelectBackward0>)\n","\n","Training step  8151\n","Loss =  tensor(5647.1338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1975], grad_fn=<SelectBackward0>)\n","\n","Training step  8152\n","Loss =  tensor(362.6294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1865], grad_fn=<SelectBackward0>)\n","\n","Training step  8153\n","Loss =  tensor(2635.4255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  8154\n","Loss =  tensor(890.1278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2117], grad_fn=<SelectBackward0>)\n","\n","Training step  8155\n","Loss =  tensor(2899.9353, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  8156\n","Loss =  tensor(662.8967, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1947], grad_fn=<SelectBackward0>)\n","\n","Training step  8157\n","Loss =  tensor(751.3511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  8158\n","Loss =  tensor(369.7777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  8159\n","Loss =  tensor(948.3042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  8160\n","Loss =  tensor(715.3051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1981], grad_fn=<SelectBackward0>)\n","\n","Training step  8161\n","Loss =  tensor(389.1607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  8162\n","Loss =  tensor(24.3836, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  8163\n","Loss =  tensor(470.2433, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  8164\n","Loss =  tensor(435.1490, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1965], grad_fn=<SelectBackward0>)\n","\n","Training step  8165\n","Loss =  tensor(769.5919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  8166\n","Loss =  tensor(34.8851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2072], grad_fn=<SelectBackward0>)\n","\n","Training step  8167\n","Loss =  tensor(378.9775, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2032], grad_fn=<SelectBackward0>)\n","\n","Training step  8168\n","Loss =  tensor(336.7203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1966], grad_fn=<SelectBackward0>)\n","\n","Training step  8169\n","Loss =  tensor(794.2718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  8170\n","Loss =  tensor(74.9001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  8171\n","Loss =  tensor(274.1767, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  8172\n","Loss =  tensor(156.1279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1964], grad_fn=<SelectBackward0>)\n","\n","Training step  8173\n","Loss =  tensor(664.8052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  8174\n","Loss =  tensor(157.6881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2082], grad_fn=<SelectBackward0>)\n","\n","Training step  8175\n","Loss =  tensor(482.6605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2044], grad_fn=<SelectBackward0>)\n","\n","Training step  8176\n","Loss =  tensor(137.2979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1951], grad_fn=<SelectBackward0>)\n","\n","Training step  8177\n","Loss =  tensor(476.1428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1959], grad_fn=<SelectBackward0>)\n","\n","Training step  8178\n","Loss =  tensor(559.7762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  8179\n","Loss =  tensor(253.0991, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2104], grad_fn=<SelectBackward0>)\n","\n","Training step  8180\n","Loss =  tensor(713.1143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  8181\n","Loss =  tensor(31.3348, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1937], grad_fn=<SelectBackward0>)\n","\n","Training step  8182\n","Loss =  tensor(596.6797, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1966], grad_fn=<SelectBackward0>)\n","\n","Training step  8183\n","Loss =  tensor(289.9042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  8184\n","Loss =  tensor(231.9362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2087], grad_fn=<SelectBackward0>)\n","\n","Training step  8185\n","Loss =  tensor(713.2957, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  8186\n","Loss =  tensor(46.5652, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1950], grad_fn=<SelectBackward0>)\n","\n","Training step  8187\n","Loss =  tensor(452.4969, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  8188\n","Loss =  tensor(78.3150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  8189\n","Loss =  tensor(166.6017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2055], grad_fn=<SelectBackward0>)\n","\n","Training step  8190\n","Loss =  tensor(178.7273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2018], grad_fn=<SelectBackward0>)\n","\n","Training step  8191\n","Loss =  tensor(22.1107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1979], grad_fn=<SelectBackward0>)\n","\n","Training step  8192\n","Loss =  tensor(121.0849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1990], grad_fn=<SelectBackward0>)\n","\n","Training step  8193\n","Loss =  tensor(92.7782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  8194\n","Loss =  tensor(141.3374, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  8195\n","Loss =  tensor(106.4842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  8196\n","Loss =  tensor(48.5526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1988], grad_fn=<SelectBackward0>)\n","\n","Training step  8197\n","Loss =  tensor(69.2027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  8198\n","Loss =  tensor(34.7393, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2039], grad_fn=<SelectBackward0>)\n","\n","Training step  8199\n","Loss =  tensor(134.3517, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  8200\n","Loss =  tensor(15.8173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1982], grad_fn=<SelectBackward0>)\n","\n","Training step  8201\n","Loss =  tensor(114.0695, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  8202\n","Loss =  tensor(13.8599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2036], grad_fn=<SelectBackward0>)\n","\n","Training step  8203\n","Loss =  tensor(85.4981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  8204\n","Loss =  tensor(102.5521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  8205\n","Loss =  tensor(75.2729, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  8206\n","Loss =  tensor(39.6556, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  8207\n","Loss =  tensor(29.8175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2035], grad_fn=<SelectBackward0>)\n","\n","Training step  8208\n","Loss =  tensor(140.4025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8209\n","Loss =  tensor(42.4444, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1984], grad_fn=<SelectBackward0>)\n","\n","Training step  8210\n","Loss =  tensor(90.9632, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  8211\n","Loss =  tensor(11.2560, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  8212\n","Loss =  tensor(90.9607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  8213\n","Loss =  tensor(18.1314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1981], grad_fn=<SelectBackward0>)\n","\n","Training step  8214\n","Loss =  tensor(112.3608, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  8215\n","Loss =  tensor(3.0550, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2033], grad_fn=<SelectBackward0>)\n","\n","Training step  8216\n","Loss =  tensor(86.7309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  8217\n","Loss =  tensor(6.9897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1984], grad_fn=<SelectBackward0>)\n","\n","Training step  8218\n","Loss =  tensor(76.9929, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8219\n","Loss =  tensor(4.6324, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  8220\n","Loss =  tensor(38.9114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  8221\n","Loss =  tensor(21.5899, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  8222\n","Loss =  tensor(24.1508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  8223\n","Loss =  tensor(22.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  8224\n","Loss =  tensor(2.5469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  8225\n","Loss =  tensor(38.1231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8226\n","Loss =  tensor(2.3363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  8227\n","Loss =  tensor(28.6285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  8228\n","Loss =  tensor(3.5119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  8229\n","Loss =  tensor(34.7778, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8230\n","Loss =  tensor(4.9856, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  8231\n","Loss =  tensor(13.1914, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8232\n","Loss =  tensor(3.5749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  8233\n","Loss =  tensor(18.9376, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8234\n","Loss =  tensor(1.0702, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  8235\n","Loss =  tensor(5.1904, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8236\n","Loss =  tensor(3.3665, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  8237\n","Loss =  tensor(7.6681, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8238\n","Loss =  tensor(1.2851, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8239\n","Loss =  tensor(1.9339, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8240\n","Loss =  tensor(1.6952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  8241\n","Loss =  tensor(2.6451, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8242\n","Loss =  tensor(1.9257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8243\n","Loss =  tensor(1.0152, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8244\n","Loss =  tensor(0.9363, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  8245\n","Loss =  tensor(0.8599, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8246\n","Loss =  tensor(1.8208, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8247\n","Loss =  tensor(0.7500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8248\n","Loss =  tensor(1.6677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8249\n","Loss =  tensor(1.4565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  8250\n","Loss =  tensor(1.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8251\n","Loss =  tensor(0.5163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8252\n","Loss =  tensor(0.5285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8253\n","Loss =  tensor(0.4562, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8254\n","Loss =  tensor(0.4744, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8255\n","Loss =  tensor(0.4154, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8256\n","Loss =  tensor(0.4227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8257\n","Loss =  tensor(0.4415, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8258\n","Loss =  tensor(0.6168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8259\n","Loss =  tensor(0.2552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8260\n","Loss =  tensor(0.3074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8261\n","Loss =  tensor(0.3104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8262\n","Loss =  tensor(0.2118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8263\n","Loss =  tensor(0.2553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8264\n","Loss =  tensor(0.3699, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8265\n","Loss =  tensor(0.3165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8266\n","Loss =  tensor(0.4480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8267\n","Loss =  tensor(0.2123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  8268\n","Loss =  tensor(0.4920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8269\n","Loss =  tensor(0.2904, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8270\n","Loss =  tensor(0.4748, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8271\n","Loss =  tensor(0.2191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8272\n","Loss =  tensor(0.2733, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8273\n","Loss =  tensor(0.3633, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8274\n","Loss =  tensor(0.1914, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8275\n","Loss =  tensor(0.2952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8276\n","Loss =  tensor(0.1805, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8277\n","Loss =  tensor(0.2126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8278\n","Loss =  tensor(0.2619, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8279\n","Loss =  tensor(0.1936, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8280\n","Loss =  tensor(0.2785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8281\n","Loss =  tensor(0.1760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  8282\n","Loss =  tensor(0.2123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8283\n","Loss =  tensor(0.1869, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8284\n","Loss =  tensor(0.2207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8285\n","Loss =  tensor(0.1466, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8286\n","Loss =  tensor(0.1478, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8287\n","Loss =  tensor(0.1148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8288\n","Loss =  tensor(0.1538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8289\n","Loss =  tensor(0.1596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8290\n","Loss =  tensor(0.1458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8291\n","Loss =  tensor(0.1207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8292\n","Loss =  tensor(0.1545, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8293\n","Loss =  tensor(0.1716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8294\n","Loss =  tensor(0.1250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8295\n","Loss =  tensor(0.1457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8296\n","Loss =  tensor(0.1398, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8297\n","Loss =  tensor(0.1479, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8298\n","Loss =  tensor(0.1523, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8299\n","Loss =  tensor(0.0861, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8300\n","Loss =  tensor(0.1153, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8301\n","Loss =  tensor(0.1349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8302\n","Loss =  tensor(0.1130, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8303\n","Loss =  tensor(0.1134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8304\n","Loss =  tensor(0.0769, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8305\n","Loss =  tensor(0.1061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8306\n","Loss =  tensor(0.1008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8307\n","Loss =  tensor(0.1897, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8308\n","Loss =  tensor(0.1047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8309\n","Loss =  tensor(0.1819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8310\n","Loss =  tensor(0.1759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8311\n","Loss =  tensor(0.2162, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8312\n","Loss =  tensor(0.1977, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8313\n","Loss =  tensor(0.1254, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8314\n","Loss =  tensor(0.0713, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8315\n","Loss =  tensor(0.1777, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8316\n","Loss =  tensor(0.0993, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8317\n","Loss =  tensor(0.1650, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8318\n","Loss =  tensor(0.0785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8319\n","Loss =  tensor(0.1219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8320\n","Loss =  tensor(0.0908, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8321\n","Loss =  tensor(0.1511, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8322\n","Loss =  tensor(0.0715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8323\n","Loss =  tensor(0.1055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8324\n","Loss =  tensor(0.0833, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8325\n","Loss =  tensor(0.1031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8326\n","Loss =  tensor(0.0679, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8327\n","Loss =  tensor(0.0837, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8328\n","Loss =  tensor(0.0901, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8329\n","Loss =  tensor(0.0975, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8330\n","Loss =  tensor(0.1253, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8331\n","Loss =  tensor(0.0515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8332\n","Loss =  tensor(0.1136, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8333\n","Loss =  tensor(0.0618, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8334\n","Loss =  tensor(0.1137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8335\n","Loss =  tensor(0.0413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8336\n","Loss =  tensor(0.0760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8337\n","Loss =  tensor(0.0643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8338\n","Loss =  tensor(0.0665, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8339\n","Loss =  tensor(0.0844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8340\n","Loss =  tensor(0.0779, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8341\n","Loss =  tensor(0.0525, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8342\n","Loss =  tensor(0.0449, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8343\n","Loss =  tensor(0.0512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8344\n","Loss =  tensor(0.0410, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8345\n","Loss =  tensor(0.0706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8346\n","Loss =  tensor(0.0428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  8347\n","Loss =  tensor(0.0555, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8348\n","Loss =  tensor(0.0349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8349\n","Loss =  tensor(0.0485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8350\n","Loss =  tensor(0.0368, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8351\n","Loss =  tensor(0.0379, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8352\n","Loss =  tensor(0.0453, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8353\n","Loss =  tensor(0.0320, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8354\n","Loss =  tensor(0.0469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8355\n","Loss =  tensor(0.0312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8356\n","Loss =  tensor(0.0437, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8357\n","Loss =  tensor(0.0260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8358\n","Loss =  tensor(0.0372, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8359\n","Loss =  tensor(0.0306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8360\n","Loss =  tensor(0.0312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8361\n","Loss =  tensor(0.0366, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8362\n","Loss =  tensor(0.0352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8363\n","Loss =  tensor(0.0322, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8364\n","Loss =  tensor(0.0312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8365\n","Loss =  tensor(0.0428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8366\n","Loss =  tensor(0.0277, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8367\n","Loss =  tensor(0.0348, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8368\n","Loss =  tensor(0.0285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8369\n","Loss =  tensor(0.0302, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8370\n","Loss =  tensor(0.0225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8371\n","Loss =  tensor(0.0346, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8372\n","Loss =  tensor(0.0217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8373\n","Loss =  tensor(0.0373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8374\n","Loss =  tensor(0.0226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8375\n","Loss =  tensor(0.0306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8376\n","Loss =  tensor(0.0226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8377\n","Loss =  tensor(0.0237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8378\n","Loss =  tensor(0.0266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8379\n","Loss =  tensor(0.0203, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8380\n","Loss =  tensor(0.0242, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8381\n","Loss =  tensor(0.0246, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8382\n","Loss =  tensor(0.0210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8383\n","Loss =  tensor(0.0230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8384\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8385\n","Loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8386\n","Loss =  tensor(0.0244, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8387\n","Loss =  tensor(0.0228, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8388\n","Loss =  tensor(0.0196, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8389\n","Loss =  tensor(0.0188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8390\n","Loss =  tensor(0.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8391\n","Loss =  tensor(0.0182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8392\n","Loss =  tensor(0.0226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8393\n","Loss =  tensor(0.0193, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8394\n","Loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8395\n","Loss =  tensor(0.0210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8396\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8397\n","Loss =  tensor(0.0238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8398\n","Loss =  tensor(0.0127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8399\n","Loss =  tensor(0.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8400\n","Loss =  tensor(0.0238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8401\n","Loss =  tensor(0.0234, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8402\n","Loss =  tensor(0.0256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8403\n","Loss =  tensor(0.0214, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8404\n","Loss =  tensor(0.0295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8405\n","Loss =  tensor(0.0128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8406\n","Loss =  tensor(0.0280, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8407\n","Loss =  tensor(0.0134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8408\n","Loss =  tensor(0.0307, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8409\n","Loss =  tensor(0.0191, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8410\n","Loss =  tensor(0.0276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8411\n","Loss =  tensor(0.0171, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8412\n","Loss =  tensor(0.0279, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8413\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8414\n","Loss =  tensor(0.0288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8415\n","Loss =  tensor(0.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8416\n","Loss =  tensor(0.0313, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8417\n","Loss =  tensor(0.0141, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8418\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8419\n","Loss =  tensor(0.0184, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8420\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8421\n","Loss =  tensor(0.0109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8422\n","Loss =  tensor(0.0172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8423\n","Loss =  tensor(0.0128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8424\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8425\n","Loss =  tensor(0.0127, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8426\n","Loss =  tensor(0.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8427\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8428\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8429\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8430\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8431\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8432\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8433\n","Loss =  tensor(0.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8434\n","Loss =  tensor(0.0107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8435\n","Loss =  tensor(0.0098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8436\n","Loss =  tensor(0.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8437\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8438\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8439\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8440\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8441\n","Loss =  tensor(0.0140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8442\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8443\n","Loss =  tensor(0.0150, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8444\n","Loss =  tensor(0.0104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8445\n","Loss =  tensor(0.0192, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8446\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8447\n","Loss =  tensor(0.0170, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8448\n","Loss =  tensor(0.0095, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8449\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8450\n","Loss =  tensor(0.0109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8451\n","Loss =  tensor(0.0123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8452\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8453\n","Loss =  tensor(0.0123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8454\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8455\n","Loss =  tensor(0.0110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8456\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8457\n","Loss =  tensor(0.0178, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8458\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8459\n","Loss =  tensor(0.0235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8460\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8461\n","Loss =  tensor(0.0204, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8462\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8463\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8464\n","Loss =  tensor(0.0105, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8465\n","Loss =  tensor(0.0164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8466\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8467\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8468\n","Loss =  tensor(0.0104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8469\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8470\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8471\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8472\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8473\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8474\n","Loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8475\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8476\n","Loss =  tensor(0.0076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8477\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8478\n","Loss =  tensor(0.0104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8479\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8480\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8481\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8482\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8483\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8484\n","Loss =  tensor(0.0086, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8485\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8486\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8487\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8488\n","Loss =  tensor(0.0089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8489\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8490\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8491\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8492\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8493\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8494\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8495\n","Loss =  tensor(0.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8496\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8497\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8498\n","Loss =  tensor(0.0089, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8499\n","Loss =  tensor(0.0104, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8500\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8501\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8502\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8503\n","Loss =  tensor(0.0126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8504\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8505\n","Loss =  tensor(0.0123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8506\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8507\n","Loss =  tensor(0.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8508\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8509\n","Loss =  tensor(0.0088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8510\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8511\n","Loss =  tensor(0.0121, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8512\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8513\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8514\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8515\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8516\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8517\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8518\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8519\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8520\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8521\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8522\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8523\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8524\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8525\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8526\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8527\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8528\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8529\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8530\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8531\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8532\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8533\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8534\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8535\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8536\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8537\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8538\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8539\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8540\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8541\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8542\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8543\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8544\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8545\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8546\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8547\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8548\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8549\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8550\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8551\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8552\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8553\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8554\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8555\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8556\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8557\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8558\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8559\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8560\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8561\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8562\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8563\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8564\n","Loss =  tensor(0.0060, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8565\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8566\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8567\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8568\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8569\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8570\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8571\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8572\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8573\n","Loss =  tensor(0.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8574\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8575\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8576\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8577\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8578\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8579\n","Loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8580\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8581\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8582\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8583\n","Loss =  tensor(0.0106, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8584\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8585\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8586\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8587\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8588\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8589\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8590\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8591\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8592\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8593\n","Loss =  tensor(0.0043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8594\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8595\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8596\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8597\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8598\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8599\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8600\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8601\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8602\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8603\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8604\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8605\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8606\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8607\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8608\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8609\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8610\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8611\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8612\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8613\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8614\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8615\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8616\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8617\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8618\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8619\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8620\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8621\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8622\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8623\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8624\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8625\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8626\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8627\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8628\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8629\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8630\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8631\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8632\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8633\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8634\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8635\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8636\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8637\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8638\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8639\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8640\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8641\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8642\n","Loss =  tensor(0.0064, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8643\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8644\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8645\n","Loss =  tensor(0.0129, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8646\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8647\n","Loss =  tensor(0.0187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8648\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8649\n","Loss =  tensor(0.0076, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8650\n","Loss =  tensor(0.0148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8651\n","Loss =  tensor(0.0092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8652\n","Loss =  tensor(0.0180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8653\n","Loss =  tensor(0.0135, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8654\n","Loss =  tensor(0.0082, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8655\n","Loss =  tensor(0.0165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8656\n","Loss =  tensor(0.0185, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8657\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8658\n","Loss =  tensor(0.0101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8659\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8660\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8661\n","Loss =  tensor(0.0070, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8662\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8663\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8664\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8665\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8666\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8667\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8668\n","Loss =  tensor(0.0146, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8669\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8670\n","Loss =  tensor(0.0114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8671\n","Loss =  tensor(0.0137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8672\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8673\n","Loss =  tensor(0.0098, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8674\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8675\n","Loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8676\n","Loss =  tensor(0.0040, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8677\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8678\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8679\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8680\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8681\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8682\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8683\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8684\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8685\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8686\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8687\n","Loss =  tensor(0.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8688\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8689\n","Loss =  tensor(0.0158, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8690\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8691\n","Loss =  tensor(0.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8692\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8693\n","Loss =  tensor(0.0160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8694\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8695\n","Loss =  tensor(0.0143, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8696\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8697\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8698\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8699\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8700\n","Loss =  tensor(0.0090, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8701\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8702\n","Loss =  tensor(0.0091, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8703\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8704\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8705\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8706\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8707\n","Loss =  tensor(0.0044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8708\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8709\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8710\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8711\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8712\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8713\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8714\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8715\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8716\n","Loss =  tensor(0.0103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8717\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8718\n","Loss =  tensor(0.0306, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8719\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8720\n","Loss =  tensor(0.0239, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8721\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8722\n","Loss =  tensor(0.0225, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8723\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8724\n","Loss =  tensor(0.0251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8725\n","Loss =  tensor(0.0183, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8726\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8727\n","Loss =  tensor(0.0257, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8728\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8729\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8730\n","Loss =  tensor(0.0112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8731\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8732\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8733\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8734\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8735\n","Loss =  tensor(0.0047, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8736\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8737\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8738\n","Loss =  tensor(0.0046, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8739\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8740\n","Loss =  tensor(0.0087, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8741\n","Loss =  tensor(0.0079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8742\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8743\n","Loss =  tensor(0.0167, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8744\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8745\n","Loss =  tensor(0.0092, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8746\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8747\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8748\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8749\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8750\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8751\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8752\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8753\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  8754\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8755\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8756\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8757\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8758\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8759\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8760\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8761\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8762\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8763\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8764\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8765\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8766\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8767\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8768\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8769\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8770\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8771\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8772\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8773\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8774\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8775\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8776\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8777\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8778\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8779\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8780\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8781\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8782\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8783\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8784\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8785\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8786\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8787\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8788\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8789\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8790\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8791\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8792\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8793\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8794\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8795\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8796\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8797\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8798\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8799\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8800\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8801\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8802\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8803\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8804\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8805\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8806\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8807\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8808\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8809\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8810\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8811\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8812\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8813\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8814\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8815\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8816\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8817\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8818\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8819\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8820\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8821\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8822\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8823\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8824\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8825\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8826\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8827\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8828\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8829\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8830\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8831\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8832\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8833\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8834\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8835\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8836\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8837\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8838\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8839\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8840\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8841\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8842\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8843\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8844\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8845\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8846\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8847\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8848\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8849\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8850\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8851\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8852\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8853\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8854\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8855\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8856\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8857\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8858\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8859\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8860\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8861\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8862\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8863\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8864\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8865\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8866\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8867\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8868\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8869\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8870\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8871\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8872\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8873\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8874\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8875\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8876\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8877\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8878\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8879\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8880\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8881\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8882\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8883\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8884\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8885\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8886\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8887\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8888\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8889\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8890\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8891\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8892\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8893\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8894\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8895\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8896\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8897\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8898\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8899\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8900\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8901\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8902\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8903\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8904\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8905\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8906\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8907\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8908\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8909\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8910\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8911\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8912\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8913\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8914\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8915\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8916\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8917\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8918\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8919\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8920\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8921\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8922\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8923\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8924\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8925\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8926\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8927\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8928\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8929\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8930\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8931\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8932\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8933\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8934\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8935\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8936\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8937\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8938\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8939\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8940\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8941\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8942\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8943\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8944\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8945\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8946\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8947\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8948\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8949\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8950\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8951\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8952\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8953\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8954\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8955\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8956\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8957\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8958\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8959\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8960\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8961\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8962\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8963\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8964\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8965\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8966\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8967\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8968\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8969\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8970\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8971\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8972\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8973\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8974\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8975\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8976\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8977\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8978\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8979\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8980\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8981\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8982\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8983\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8984\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8985\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8986\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8987\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8988\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8989\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8990\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8991\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8992\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8993\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8994\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8995\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8996\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8997\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8998\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  8999\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9000\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9001\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9002\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9003\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9004\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9005\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9006\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9007\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9008\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9009\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9010\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9011\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9012\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9013\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9014\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9015\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9016\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9017\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9018\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9019\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9020\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9021\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9022\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9023\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9024\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9025\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9026\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9027\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9028\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9029\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9030\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9031\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9032\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9033\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9034\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9035\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9036\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9037\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9038\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9039\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9040\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9041\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9042\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9043\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9044\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9045\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9046\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9047\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9048\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9049\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9050\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9051\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9052\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9053\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9054\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9055\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9056\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9057\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9058\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9059\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9060\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9061\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9062\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9063\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9064\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9065\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9066\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9067\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9068\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9069\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9070\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9071\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9072\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9073\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9074\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9075\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9076\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9077\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9078\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9079\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9080\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9081\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9082\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9083\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9084\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9085\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9086\n","Loss =  tensor(0.0081, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9087\n","Loss =  tensor(0.0188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9088\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9089\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9090\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9091\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9092\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9093\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9094\n","Loss =  tensor(0.0066, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9095\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9096\n","Loss =  tensor(0.0072, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9097\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9098\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9099\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9100\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9101\n","Loss =  tensor(0.0132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9102\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9103\n","Loss =  tensor(0.0054, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9104\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9105\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9106\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9107\n","Loss =  tensor(0.0021, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9108\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9109\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9110\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9111\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9112\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9113\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9114\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9115\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9116\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9117\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9118\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9119\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9120\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9121\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9122\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9123\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9124\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9125\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9126\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9127\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9128\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9129\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9130\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9131\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9132\n","Loss =  tensor(0.0113, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9133\n","Loss =  tensor(0.0157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9134\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9135\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9136\n","Loss =  tensor(0.0117, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9137\n","Loss =  tensor(0.0034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9138\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9139\n","Loss =  tensor(0.0093, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9140\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9141\n","Loss =  tensor(0.0052, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9142\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9143\n","Loss =  tensor(0.0055, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9144\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9145\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9146\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9147\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9148\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9149\n","Loss =  tensor(0.0166, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9150\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9151\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9152\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9153\n","Loss =  tensor(0.0083, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9154\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9155\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9156\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9157\n","Loss =  tensor(0.0016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9158\n","Loss =  tensor(0.0058, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9159\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9160\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9161\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9162\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9163\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9164\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9165\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9166\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9167\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9168\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9169\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9170\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9171\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9172\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9173\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9174\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9175\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9176\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9177\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9178\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9179\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9180\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9181\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9182\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9183\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9184\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9185\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9186\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9187\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9188\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9189\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9190\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9191\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9192\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9193\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9194\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9195\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9196\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9197\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9198\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9199\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9200\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9201\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9202\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9203\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9204\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9205\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9206\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9207\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9208\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9209\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9210\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9211\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9212\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9213\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9214\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9215\n","Loss =  tensor(0.0018, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9216\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9217\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9218\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9219\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9220\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9221\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9222\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9223\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9224\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9225\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9226\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9227\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9228\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9229\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9230\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9231\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9232\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9233\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9234\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9235\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9236\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9237\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9238\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9239\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9240\n","Loss =  tensor(0.0057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9241\n","Loss =  tensor(0.0041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9242\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9243\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9244\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9245\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9246\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9247\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9248\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9249\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9250\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9251\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9252\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9253\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9254\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9255\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9256\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9257\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9258\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9259\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9260\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9261\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9262\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9263\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9264\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9265\n","Loss =  tensor(0.0049, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9266\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9267\n","Loss =  tensor(0.0065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9268\n","Loss =  tensor(0.0045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9269\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9270\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9271\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9272\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9273\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9274\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9275\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9276\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9277\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9278\n","Loss =  tensor(0.0112, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9279\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9280\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9281\n","Loss =  tensor(0.0062, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9282\n","Loss =  tensor(0.0078, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9283\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9284\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9285\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9286\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9287\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9288\n","Loss =  tensor(0.0300, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9289\n","Loss =  tensor(0.0033, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9290\n","Loss =  tensor(0.0179, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9291\n","Loss =  tensor(0.0345, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9292\n","Loss =  tensor(0.0286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9293\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9294\n","Loss =  tensor(0.0194, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9295\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9296\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9297\n","Loss =  tensor(0.0097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9298\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9299\n","Loss =  tensor(0.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9300\n","Loss =  tensor(0.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9301\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9302\n","Loss =  tensor(0.0085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9303\n","Loss =  tensor(0.0050, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9304\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9305\n","Loss =  tensor(0.0051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9306\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9307\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9308\n","Loss =  tensor(0.0056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9309\n","Loss =  tensor(0.0042, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9310\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9311\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9312\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9313\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9314\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9315\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9316\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9317\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9318\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9319\n","Loss =  tensor(0.0008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9320\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9321\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9322\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9323\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9324\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9325\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9326\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9327\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9328\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9329\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9330\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9331\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9332\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9333\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9334\n","Loss =  tensor(8.5427e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9335\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9336\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9337\n","Loss =  tensor(7.2134e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9338\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9339\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9340\n","Loss =  tensor(4.9414e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9341\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9342\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9343\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9344\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9345\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9346\n","Loss =  tensor(4.2840e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9347\n","Loss =  tensor(8.1582e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9348\n","Loss =  tensor(6.6463e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9349\n","Loss =  tensor(3.7845e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9350\n","Loss =  tensor(3.4363e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9351\n","Loss =  tensor(4.2969e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9352\n","Loss =  tensor(4.0462e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9353\n","Loss =  tensor(4.5559e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9354\n","Loss =  tensor(4.0562e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9355\n","Loss =  tensor(5.1234e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9356\n","Loss =  tensor(5.5465e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9357\n","Loss =  tensor(4.5854e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9358\n","Loss =  tensor(3.6180e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9359\n","Loss =  tensor(3.8130e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9360\n","Loss =  tensor(4.0496e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9361\n","Loss =  tensor(3.6531e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9362\n","Loss =  tensor(3.6378e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9363\n","Loss =  tensor(4.6839e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9364\n","Loss =  tensor(5.0330e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9365\n","Loss =  tensor(3.9163e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9366\n","Loss =  tensor(4.0272e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9367\n","Loss =  tensor(4.7876e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9368\n","Loss =  tensor(4.2906e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9369\n","Loss =  tensor(5.1257e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9370\n","Loss =  tensor(4.7571e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9371\n","Loss =  tensor(4.5468e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9372\n","Loss =  tensor(4.8358e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9373\n","Loss =  tensor(5.9067e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9374\n","Loss =  tensor(4.1292e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9375\n","Loss =  tensor(5.8516e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9376\n","Loss =  tensor(4.6648e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9377\n","Loss =  tensor(5.7407e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9378\n","Loss =  tensor(4.4863e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9379\n","Loss =  tensor(4.7647e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9380\n","Loss =  tensor(4.9404e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9381\n","Loss =  tensor(5.7079e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9382\n","Loss =  tensor(4.7445e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9383\n","Loss =  tensor(3.6574e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9384\n","Loss =  tensor(5.3269e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9385\n","Loss =  tensor(4.9770e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9386\n","Loss =  tensor(4.1030e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9387\n","Loss =  tensor(3.7357e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9388\n","Loss =  tensor(4.9672e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9389\n","Loss =  tensor(4.2364e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9390\n","Loss =  tensor(4.5906e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9391\n","Loss =  tensor(4.4110e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9392\n","Loss =  tensor(3.1619e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9393\n","Loss =  tensor(3.3442e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9394\n","Loss =  tensor(3.5936e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9395\n","Loss =  tensor(3.8503e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9396\n","Loss =  tensor(3.0155e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9397\n","Loss =  tensor(3.9126e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9398\n","Loss =  tensor(4.6392e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9399\n","Loss =  tensor(2.9416e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9400\n","Loss =  tensor(3.4990e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9401\n","Loss =  tensor(5.3425e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9402\n","Loss =  tensor(6.3587e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9403\n","Loss =  tensor(5.5600e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9404\n","Loss =  tensor(4.5753e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9405\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9406\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9407\n","Loss =  tensor(6.8979e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9408\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9409\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9410\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9411\n","Loss =  tensor(4.0867e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9412\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9413\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9414\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9415\n","Loss =  tensor(6.1163e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9416\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9417\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9418\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9419\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9420\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9421\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9422\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9423\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9424\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9425\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9426\n","Loss =  tensor(3.4735e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9427\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9428\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9429\n","Loss =  tensor(7.9855e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9430\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9431\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9432\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9433\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9434\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9435\n","Loss =  tensor(6.6591e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9436\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9437\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9438\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9439\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9440\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9441\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9442\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9443\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9444\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9445\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9446\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9447\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9448\n","Loss =  tensor(0.0037, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9449\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9450\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9451\n","Loss =  tensor(0.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9452\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9453\n","Loss =  tensor(0.0107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9454\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9455\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9456\n","Loss =  tensor(0.0231, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9457\n","Loss =  tensor(0.0318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9458\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9459\n","Loss =  tensor(0.0388, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9460\n","Loss =  tensor(0.0118, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9461\n","Loss =  tensor(0.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9462\n","Loss =  tensor(0.0183, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9463\n","Loss =  tensor(0.0030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9464\n","Loss =  tensor(0.0074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9465\n","Loss =  tensor(0.0108, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9466\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9467\n","Loss =  tensor(0.0149, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9468\n","Loss =  tensor(0.0428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9469\n","Loss =  tensor(0.0394, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9470\n","Loss =  tensor(0.0099, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9471\n","Loss =  tensor(0.0245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9472\n","Loss =  tensor(0.1960, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9473\n","Loss =  tensor(0.1408, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9474\n","Loss =  tensor(0.0756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9475\n","Loss =  tensor(0.4446, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9476\n","Loss =  tensor(0.0213, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9477\n","Loss =  tensor(0.1321, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9478\n","Loss =  tensor(0.0063, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9479\n","Loss =  tensor(0.2638, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9480\n","Loss =  tensor(0.3883, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9481\n","Loss =  tensor(0.3456, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9482\n","Loss =  tensor(0.1216, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9483\n","Loss =  tensor(0.0218, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9484\n","Loss =  tensor(0.3016, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9485\n","Loss =  tensor(0.1227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9486\n","Loss =  tensor(0.0144, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9487\n","Loss =  tensor(0.1333, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9488\n","Loss =  tensor(0.1207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9489\n","Loss =  tensor(0.0411, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9490\n","Loss =  tensor(0.5485, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9491\n","Loss =  tensor(1.5140, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9492\n","Loss =  tensor(0.1954, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9493\n","Loss =  tensor(0.6508, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9494\n","Loss =  tensor(0.8413, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9495\n","Loss =  tensor(0.1323, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9496\n","Loss =  tensor(0.0096, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9497\n","Loss =  tensor(0.1261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9498\n","Loss =  tensor(0.0844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9499\n","Loss =  tensor(0.0518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9500\n","Loss =  tensor(0.2227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9501\n","Loss =  tensor(0.3263, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9502\n","Loss =  tensor(0.7250, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9503\n","Loss =  tensor(0.1852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9504\n","Loss =  tensor(0.0290, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9505\n","Loss =  tensor(0.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9506\n","Loss =  tensor(0.0682, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9507\n","Loss =  tensor(0.0785, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9508\n","Loss =  tensor(0.0039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9509\n","Loss =  tensor(0.0389, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9510\n","Loss =  tensor(0.0573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9511\n","Loss =  tensor(0.0318, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9512\n","Loss =  tensor(0.1762, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9513\n","Loss =  tensor(0.3034, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9514\n","Loss =  tensor(0.0126, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9515\n","Loss =  tensor(0.3006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9516\n","Loss =  tensor(1.0053, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9517\n","Loss =  tensor(1.3273, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9518\n","Loss =  tensor(0.6906, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9519\n","Loss =  tensor(0.4746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9520\n","Loss =  tensor(0.1110, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9521\n","Loss =  tensor(0.0653, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9522\n","Loss =  tensor(0.6842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9523\n","Loss =  tensor(1.8840, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9524\n","Loss =  tensor(3.7533, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9525\n","Loss =  tensor(2.4071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9526\n","Loss =  tensor(0.0842, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9527\n","Loss =  tensor(0.8939, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9528\n","Loss =  tensor(1.2309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9529\n","Loss =  tensor(0.1745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9530\n","Loss =  tensor(0.3165, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9531\n","Loss =  tensor(0.2101, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9532\n","Loss =  tensor(0.1565, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9533\n","Loss =  tensor(0.2217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9534\n","Loss =  tensor(0.1781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9535\n","Loss =  tensor(0.1198, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9536\n","Loss =  tensor(0.0756, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9537\n","Loss =  tensor(0.0573, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9538\n","Loss =  tensor(0.1944, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9539\n","Loss =  tensor(0.2546, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9540\n","Loss =  tensor(0.1233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9541\n","Loss =  tensor(0.0255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9542\n","Loss =  tensor(0.0534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9543\n","Loss =  tensor(0.1285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9544\n","Loss =  tensor(0.0224, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9545\n","Loss =  tensor(0.0338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9546\n","Loss =  tensor(0.0459, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9547\n","Loss =  tensor(0.0197, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9548\n","Loss =  tensor(0.0961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9549\n","Loss =  tensor(0.4706, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9550\n","Loss =  tensor(0.6472, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9551\n","Loss =  tensor(0.1457, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9552\n","Loss =  tensor(0.2305, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9553\n","Loss =  tensor(1.2173, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9554\n","Loss =  tensor(0.8905, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9555\n","Loss =  tensor(0.1261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9556\n","Loss =  tensor(0.1818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9557\n","Loss =  tensor(0.6137, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9558\n","Loss =  tensor(2.2760, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9559\n","Loss =  tensor(3.2370, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9560\n","Loss =  tensor(0.3407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9561\n","Loss =  tensor(4.5881, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  9562\n","Loss =  tensor(12.5088, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9563\n","Loss =  tensor(2.7030, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9564\n","Loss =  tensor(3.3867, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9565\n","Loss =  tensor(7.2586, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  9566\n","Loss =  tensor(7.1217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9567\n","Loss =  tensor(6.0264, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9568\n","Loss =  tensor(1.5286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9569\n","Loss =  tensor(7.1509, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9570\n","Loss =  tensor(9.0611, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  9571\n","Loss =  tensor(14.0994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9572\n","Loss =  tensor(0.5084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9573\n","Loss =  tensor(6.9392, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  9574\n","Loss =  tensor(6.7661, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9575\n","Loss =  tensor(8.2377, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  9576\n","Loss =  tensor(54.5035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  9577\n","Loss =  tensor(75.2367, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9578\n","Loss =  tensor(0.5714, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1970], grad_fn=<SelectBackward0>)\n","\n","Training step  9579\n","Loss =  tensor(109.3810, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2047], grad_fn=<SelectBackward0>)\n","\n","Training step  9580\n","Loss =  tensor(368.5035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1904], grad_fn=<SelectBackward0>)\n","\n","Training step  9581\n","Loss =  tensor(1212.4719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2124], grad_fn=<SelectBackward0>)\n","\n","Training step  9582\n","Loss =  tensor(1792.1672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1943], grad_fn=<SelectBackward0>)\n","\n","Training step  9583\n","Loss =  tensor(357.9528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1882], grad_fn=<SelectBackward0>)\n","\n","Training step  9584\n","Loss =  tensor(2022.3291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2255], grad_fn=<SelectBackward0>)\n","\n","Training step  9585\n","Loss =  tensor(5511.1123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  9586\n","Loss =  tensor(11.9607, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1757], grad_fn=<SelectBackward0>)\n","\n","Training step  9587\n","Loss =  tensor(6829.7749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2270], grad_fn=<SelectBackward0>)\n","\n","Training step  9588\n","Loss =  tensor(10019.0059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1844], grad_fn=<SelectBackward0>)\n","\n","Training step  9589\n","Loss =  tensor(2383.4678, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1837], grad_fn=<SelectBackward0>)\n","\n","Training step  9590\n","Loss =  tensor(2592.4602, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2165], grad_fn=<SelectBackward0>)\n","\n","Training step  9591\n","Loss =  tensor(3119.6074, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  9592\n","Loss =  tensor(400.1981, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1821], grad_fn=<SelectBackward0>)\n","\n","Training step  9593\n","Loss =  tensor(3500.1260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2084], grad_fn=<SelectBackward0>)\n","\n","Training step  9594\n","Loss =  tensor(1132.9360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2106], grad_fn=<SelectBackward0>)\n","\n","Training step  9595\n","Loss =  tensor(1847.7589, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1800], grad_fn=<SelectBackward0>)\n","\n","Training step  9596\n","Loss =  tensor(4853.1855, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2109], grad_fn=<SelectBackward0>)\n","\n","Training step  9597\n","Loss =  tensor(1780.9819, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  9598\n","Loss =  tensor(19.5982, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1890], grad_fn=<SelectBackward0>)\n","\n","Training step  9599\n","Loss =  tensor(2001.2794, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2201], grad_fn=<SelectBackward0>)\n","\n","Training step  9600\n","Loss =  tensor(4628.4644, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1942], grad_fn=<SelectBackward0>)\n","\n","Training step  9601\n","Loss =  tensor(709.2647, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1881], grad_fn=<SelectBackward0>)\n","\n","Training step  9602\n","Loss =  tensor(1346.1079, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2075], grad_fn=<SelectBackward0>)\n","\n","Training step  9603\n","Loss =  tensor(794.2134, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  9604\n","Loss =  tensor(436.7515, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1866], grad_fn=<SelectBackward0>)\n","\n","Training step  9605\n","Loss =  tensor(1992.3148, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2049], grad_fn=<SelectBackward0>)\n","\n","Training step  9606\n","Loss =  tensor(998.0500, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2058], grad_fn=<SelectBackward0>)\n","\n","Training step  9607\n","Loss =  tensor(830.5544, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1904], grad_fn=<SelectBackward0>)\n","\n","Training step  9608\n","Loss =  tensor(776.7606, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1951], grad_fn=<SelectBackward0>)\n","\n","Training step  9609\n","Loss =  tensor(429.1103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  9610\n","Loss =  tensor(2464.1973, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1900], grad_fn=<SelectBackward0>)\n","\n","Training step  9611\n","Loss =  tensor(1079.3107, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1952], grad_fn=<SelectBackward0>)\n","\n","Training step  9612\n","Loss =  tensor(352.5891, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2121], grad_fn=<SelectBackward0>)\n","\n","Training step  9613\n","Loss =  tensor(2547.3811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1907], grad_fn=<SelectBackward0>)\n","\n","Training step  9614\n","Loss =  tensor(1175.6057, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9615\n","Loss =  tensor(179.1114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  9616\n","Loss =  tensor(596.5041, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9617\n","Loss =  tensor(47.3913, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1930], grad_fn=<SelectBackward0>)\n","\n","Training step  9618\n","Loss =  tensor(484.6406, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2038], grad_fn=<SelectBackward0>)\n","\n","Training step  9619\n","Loss =  tensor(248.9233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2045], grad_fn=<SelectBackward0>)\n","\n","Training step  9620\n","Loss =  tensor(513.4399, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1886], grad_fn=<SelectBackward0>)\n","\n","Training step  9621\n","Loss =  tensor(1553.5469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  9622\n","Loss =  tensor(657.3600, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2034], grad_fn=<SelectBackward0>)\n","\n","Training step  9623\n","Loss =  tensor(366.8715, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1923], grad_fn=<SelectBackward0>)\n","\n","Training step  9624\n","Loss =  tensor(828.3007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2051], grad_fn=<SelectBackward0>)\n","\n","Training step  9625\n","Loss =  tensor(342.4983, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2061], grad_fn=<SelectBackward0>)\n","\n","Training step  9626\n","Loss =  tensor(850.9568, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1919], grad_fn=<SelectBackward0>)\n","\n","Training step  9627\n","Loss =  tensor(613.8342, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1942], grad_fn=<SelectBackward0>)\n","\n","Training step  9628\n","Loss =  tensor(662.5295, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2167], grad_fn=<SelectBackward0>)\n","\n","Training step  9629\n","Loss =  tensor(2333.9690, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2065], grad_fn=<SelectBackward0>)\n","\n","Training step  9630\n","Loss =  tensor(1194.5518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1800], grad_fn=<SelectBackward0>)\n","\n","Training step  9631\n","Loss =  tensor(4316.5527, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9632\n","Loss =  tensor(100.8252, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2163], grad_fn=<SelectBackward0>)\n","\n","Training step  9633\n","Loss =  tensor(3027.5164, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1935], grad_fn=<SelectBackward0>)\n","\n","Training step  9634\n","Loss =  tensor(852.1155, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1896], grad_fn=<SelectBackward0>)\n","\n","Training step  9635\n","Loss =  tensor(1297.8403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2089], grad_fn=<SelectBackward0>)\n","\n","Training step  9636\n","Loss =  tensor(901.6514, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2042], grad_fn=<SelectBackward0>)\n","\n","Training step  9637\n","Loss =  tensor(370.5551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1848], grad_fn=<SelectBackward0>)\n","\n","Training step  9638\n","Loss =  tensor(2488.6409, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2031], grad_fn=<SelectBackward0>)\n","\n","Training step  9639\n","Loss =  tensor(171.6285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2132], grad_fn=<SelectBackward0>)\n","\n","Training step  9640\n","Loss =  tensor(1817.6553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1928], grad_fn=<SelectBackward0>)\n","\n","Training step  9641\n","Loss =  tensor(586.5876, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1895], grad_fn=<SelectBackward0>)\n","\n","Training step  9642\n","Loss =  tensor(1296.4990, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2127], grad_fn=<SelectBackward0>)\n","\n","Training step  9643\n","Loss =  tensor(1771.8163, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2040], grad_fn=<SelectBackward0>)\n","\n","Training step  9644\n","Loss =  tensor(170.0075, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1873], grad_fn=<SelectBackward0>)\n","\n","Training step  9645\n","Loss =  tensor(2119.4746, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2056], grad_fn=<SelectBackward0>)\n","\n","Training step  9646\n","Loss =  tensor(427.6006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2067], grad_fn=<SelectBackward0>)\n","\n","Training step  9647\n","Loss =  tensor(556.0680, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1905], grad_fn=<SelectBackward0>)\n","\n","Training step  9648\n","Loss =  tensor(1042.4595, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  9649\n","Loss =  tensor(37.4844, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2100], grad_fn=<SelectBackward0>)\n","\n","Training step  9650\n","Loss =  tensor(1093.7286, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1976], grad_fn=<SelectBackward0>)\n","\n","Training step  9651\n","Loss =  tensor(98.4662, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1937], grad_fn=<SelectBackward0>)\n","\n","Training step  9652\n","Loss =  tensor(549.8111, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2080], grad_fn=<SelectBackward0>)\n","\n","Training step  9653\n","Loss =  tensor(683.9846, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  9654\n","Loss =  tensor(134.0621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1919], grad_fn=<SelectBackward0>)\n","\n","Training step  9655\n","Loss =  tensor(1068.0123, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2096], grad_fn=<SelectBackward0>)\n","\n","Training step  9656\n","Loss =  tensor(967.2059, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2029], grad_fn=<SelectBackward0>)\n","\n","Training step  9657\n","Loss =  tensor(261.4174, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1920], grad_fn=<SelectBackward0>)\n","\n","Training step  9658\n","Loss =  tensor(925.7551, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2030], grad_fn=<SelectBackward0>)\n","\n","Training step  9659\n","Loss =  tensor(83.1918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2069], grad_fn=<SelectBackward0>)\n","\n","Training step  9660\n","Loss =  tensor(590.1397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1963], grad_fn=<SelectBackward0>)\n","\n","Training step  9661\n","Loss =  tensor(301.3663, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1975], grad_fn=<SelectBackward0>)\n","\n","Training step  9662\n","Loss =  tensor(49.8480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  9663\n","Loss =  tensor(69.5249, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2024], grad_fn=<SelectBackward0>)\n","\n","Training step  9664\n","Loss =  tensor(86.2879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1974], grad_fn=<SelectBackward0>)\n","\n","Training step  9665\n","Loss =  tensor(103.2994, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9666\n","Loss =  tensor(5.1812, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  9667\n","Loss =  tensor(37.9959, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9668\n","Loss =  tensor(25.1464, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1970], grad_fn=<SelectBackward0>)\n","\n","Training step  9669\n","Loss =  tensor(141.4770, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  9670\n","Loss =  tensor(40.1492, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2022], grad_fn=<SelectBackward0>)\n","\n","Training step  9671\n","Loss =  tensor(55.2850, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  9672\n","Loss =  tensor(84.6085, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9673\n","Loss =  tensor(9.2811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2021], grad_fn=<SelectBackward0>)\n","\n","Training step  9674\n","Loss =  tensor(71.1044, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1974], grad_fn=<SelectBackward0>)\n","\n","Training step  9675\n","Loss =  tensor(77.7930, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9676\n","Loss =  tensor(45.7268, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2043], grad_fn=<SelectBackward0>)\n","\n","Training step  9677\n","Loss =  tensor(231.4180, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  9678\n","Loss =  tensor(40.3260, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1975], grad_fn=<SelectBackward0>)\n","\n","Training step  9679\n","Loss =  tensor(72.6227, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2027], grad_fn=<SelectBackward0>)\n","\n","Training step  9680\n","Loss =  tensor(105.2316, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  9681\n","Loss =  tensor(11.8462, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1982], grad_fn=<SelectBackward0>)\n","\n","Training step  9682\n","Loss =  tensor(39.4759, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  9683\n","Loss =  tensor(18.5952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2009], grad_fn=<SelectBackward0>)\n","\n","Training step  9684\n","Loss =  tensor(9.5482, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  9685\n","Loss =  tensor(19.6159, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9686\n","Loss =  tensor(5.1533, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2019], grad_fn=<SelectBackward0>)\n","\n","Training step  9687\n","Loss =  tensor(43.0125, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9688\n","Loss =  tensor(4.1956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9689\n","Loss =  tensor(20.6719, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2010], grad_fn=<SelectBackward0>)\n","\n","Training step  9690\n","Loss =  tensor(12.2605, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9691\n","Loss =  tensor(10.6261, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1984], grad_fn=<SelectBackward0>)\n","\n","Training step  9692\n","Loss =  tensor(24.2103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9693\n","Loss =  tensor(9.2642, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2020], grad_fn=<SelectBackward0>)\n","\n","Training step  9694\n","Loss =  tensor(49.3996, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9695\n","Loss =  tensor(0.5237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1980], grad_fn=<SelectBackward0>)\n","\n","Training step  9696\n","Loss =  tensor(37.6659, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9697\n","Loss =  tensor(4.2309, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2016], grad_fn=<SelectBackward0>)\n","\n","Training step  9698\n","Loss =  tensor(41.1552, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  9699\n","Loss =  tensor(20.0918, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9700\n","Loss =  tensor(28.3282, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  9701\n","Loss =  tensor(38.7119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9702\n","Loss =  tensor(8.6161, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1983], grad_fn=<SelectBackward0>)\n","\n","Training step  9703\n","Loss =  tensor(32.6942, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9704\n","Loss =  tensor(4.0898, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  9705\n","Loss =  tensor(30.8314, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1985], grad_fn=<SelectBackward0>)\n","\n","Training step  9706\n","Loss =  tensor(19.0217, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1988], grad_fn=<SelectBackward0>)\n","\n","Training step  9707\n","Loss =  tensor(29.0256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2028], grad_fn=<SelectBackward0>)\n","\n","Training step  9708\n","Loss =  tensor(109.5256, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  9709\n","Loss =  tensor(15.2854, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1977], grad_fn=<SelectBackward0>)\n","\n","Training step  9710\n","Loss =  tensor(64.7222, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2025], grad_fn=<SelectBackward0>)\n","\n","Training step  9711\n","Loss =  tensor(80.5043, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  9712\n","Loss =  tensor(29.5526, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1987], grad_fn=<SelectBackward0>)\n","\n","Training step  9713\n","Loss =  tensor(40.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  9714\n","Loss =  tensor(6.6352, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9715\n","Loss =  tensor(2.6576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9716\n","Loss =  tensor(11.3109, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9717\n","Loss =  tensor(18.4640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9718\n","Loss =  tensor(11.2832, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9719\n","Loss =  tensor(0.8255, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  9720\n","Loss =  tensor(13.5999, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9721\n","Loss =  tensor(22.7580, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1977], grad_fn=<SelectBackward0>)\n","\n","Training step  9722\n","Loss =  tensor(58.4801, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2012], grad_fn=<SelectBackward0>)\n","\n","Training step  9723\n","Loss =  tensor(21.7934, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2011], grad_fn=<SelectBackward0>)\n","\n","Training step  9724\n","Loss =  tensor(13.3944, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1989], grad_fn=<SelectBackward0>)\n","\n","Training step  9725\n","Loss =  tensor(22.8956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9726\n","Loss =  tensor(0.6210, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9727\n","Loss =  tensor(11.1350, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9728\n","Loss =  tensor(8.9718, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  9729\n","Loss =  tensor(10.0859, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9730\n","Loss =  tensor(2.4761, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9731\n","Loss =  tensor(5.5103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9732\n","Loss =  tensor(14.4924, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9733\n","Loss =  tensor(3.2694, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9734\n","Loss =  tensor(2.6806, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9735\n","Loss =  tensor(8.2553, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9736\n","Loss =  tensor(2.6835, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9737\n","Loss =  tensor(4.8488, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9738\n","Loss =  tensor(3.0576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9739\n","Loss =  tensor(5.7849, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9740\n","Loss =  tensor(9.5245, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9741\n","Loss =  tensor(0.9114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9742\n","Loss =  tensor(7.7024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2014], grad_fn=<SelectBackward0>)\n","\n","Training step  9743\n","Loss =  tensor(19.7278, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9744\n","Loss =  tensor(0.6852, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9745\n","Loss =  tensor(24.0911, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9746\n","Loss =  tensor(9.5241, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9747\n","Loss =  tensor(1.6483, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9748\n","Loss =  tensor(4.3132, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9749\n","Loss =  tensor(2.7871, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9750\n","Loss =  tensor(12.7980, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  9751\n","Loss =  tensor(7.5809, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9752\n","Loss =  tensor(6.9657, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2013], grad_fn=<SelectBackward0>)\n","\n","Training step  9753\n","Loss =  tensor(26.9956, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1986], grad_fn=<SelectBackward0>)\n","\n","Training step  9754\n","Loss =  tensor(20.0266, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9755\n","Loss =  tensor(3.3275, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2015], grad_fn=<SelectBackward0>)\n","\n","Training step  9756\n","Loss =  tensor(25.7830, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9757\n","Loss =  tensor(3.5686, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9758\n","Loss =  tensor(6.6001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9759\n","Loss =  tensor(10.3065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9760\n","Loss =  tensor(2.7603, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9761\n","Loss =  tensor(2.4745, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  9762\n","Loss =  tensor(6.4598, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9763\n","Loss =  tensor(0.9460, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9764\n","Loss =  tensor(7.7168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9765\n","Loss =  tensor(6.7677, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9766\n","Loss =  tensor(0.2672, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9767\n","Loss =  tensor(8.4128, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9768\n","Loss =  tensor(3.0940, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9769\n","Loss =  tensor(2.7675, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  9770\n","Loss =  tensor(6.1892, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9771\n","Loss =  tensor(1.4687, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9772\n","Loss =  tensor(4.2816, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9773\n","Loss =  tensor(0.4469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9774\n","Loss =  tensor(1.5621, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9775\n","Loss =  tensor(1.9619, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9776\n","Loss =  tensor(1.5782, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9777\n","Loss =  tensor(3.3045, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9778\n","Loss =  tensor(0.3512, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9779\n","Loss =  tensor(2.8620, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9780\n","Loss =  tensor(1.7992, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9781\n","Loss =  tensor(0.0235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9782\n","Loss =  tensor(1.0147, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9783\n","Loss =  tensor(0.6172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9784\n","Loss =  tensor(0.4958, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9785\n","Loss =  tensor(0.2818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9786\n","Loss =  tensor(0.3749, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9787\n","Loss =  tensor(1.0360, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9788\n","Loss =  tensor(0.1100, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9789\n","Loss =  tensor(0.7294, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9790\n","Loss =  tensor(0.1338, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9791\n","Loss =  tensor(0.7547, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9792\n","Loss =  tensor(0.4233, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9793\n","Loss =  tensor(0.5408, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9794\n","Loss =  tensor(0.8643, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9795\n","Loss =  tensor(0.7716, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9796\n","Loss =  tensor(1.2776, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9797\n","Loss =  tensor(1.2826, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9798\n","Loss =  tensor(5.1097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9799\n","Loss =  tensor(0.7330, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9800\n","Loss =  tensor(3.2102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9801\n","Loss =  tensor(1.4271, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1992], grad_fn=<SelectBackward0>)\n","\n","Training step  9802\n","Loss =  tensor(6.4187, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9803\n","Loss =  tensor(6.1979, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2004], grad_fn=<SelectBackward0>)\n","\n","Training step  9804\n","Loss =  tensor(2.5566, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1991], grad_fn=<SelectBackward0>)\n","\n","Training step  9805\n","Loss =  tensor(10.6622, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9806\n","Loss =  tensor(0.8494, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2007], grad_fn=<SelectBackward0>)\n","\n","Training step  9807\n","Loss =  tensor(6.9538, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1994], grad_fn=<SelectBackward0>)\n","\n","Training step  9808\n","Loss =  tensor(4.0534, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9809\n","Loss =  tensor(1.1518, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2008], grad_fn=<SelectBackward0>)\n","\n","Training step  9810\n","Loss =  tensor(7.1811, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9811\n","Loss =  tensor(2.6919, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9812\n","Loss =  tensor(8.7497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2005], grad_fn=<SelectBackward0>)\n","\n","Training step  9813\n","Loss =  tensor(3.3156, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9814\n","Loss =  tensor(1.8220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9815\n","Loss =  tensor(2.5097, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1993], grad_fn=<SelectBackward0>)\n","\n","Training step  9816\n","Loss =  tensor(3.8069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9817\n","Loss =  tensor(0.8384, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2006], grad_fn=<SelectBackward0>)\n","\n","Training step  9818\n","Loss =  tensor(3.5818, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9819\n","Loss =  tensor(1.0362, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9820\n","Loss =  tensor(3.1669, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9821\n","Loss =  tensor(0.8576, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9822\n","Loss =  tensor(1.2172, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1995], grad_fn=<SelectBackward0>)\n","\n","Training step  9823\n","Loss =  tensor(2.9373, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9824\n","Loss =  tensor(0.3291, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9825\n","Loss =  tensor(1.2008, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9826\n","Loss =  tensor(0.5005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9827\n","Loss =  tensor(0.5400, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9828\n","Loss =  tensor(1.1418, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9829\n","Loss =  tensor(0.2920, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9830\n","Loss =  tensor(1.0961, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9831\n","Loss =  tensor(0.5103, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2003], grad_fn=<SelectBackward0>)\n","\n","Training step  9832\n","Loss =  tensor(1.2276, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1996], grad_fn=<SelectBackward0>)\n","\n","Training step  9833\n","Loss =  tensor(1.8402, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9834\n","Loss =  tensor(0.5648, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9835\n","Loss =  tensor(0.5403, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9836\n","Loss =  tensor(0.3151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9837\n","Loss =  tensor(0.3065, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9838\n","Loss =  tensor(0.4571, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1997], grad_fn=<SelectBackward0>)\n","\n","Training step  9839\n","Loss =  tensor(0.8002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9840\n","Loss =  tensor(0.2230, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2002], grad_fn=<SelectBackward0>)\n","\n","Training step  9841\n","Loss =  tensor(0.4879, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9842\n","Loss =  tensor(0.2039, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9843\n","Loss =  tensor(0.2469, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9844\n","Loss =  tensor(0.3774, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9845\n","Loss =  tensor(0.1114, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9846\n","Loss =  tensor(0.1731, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9847\n","Loss =  tensor(0.0025, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9848\n","Loss =  tensor(0.2609, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9849\n","Loss =  tensor(0.2528, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9850\n","Loss =  tensor(0.0207, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9851\n","Loss =  tensor(0.2235, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9852\n","Loss =  tensor(0.0419, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9853\n","Loss =  tensor(0.2549, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9854\n","Loss =  tensor(0.1497, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9855\n","Loss =  tensor(0.0219, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9856\n","Loss =  tensor(0.2238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9857\n","Loss =  tensor(0.0843, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9858\n","Loss =  tensor(0.0480, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9859\n","Loss =  tensor(0.1543, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9860\n","Loss =  tensor(0.0067, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9861\n","Loss =  tensor(0.2056, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1998], grad_fn=<SelectBackward0>)\n","\n","Training step  9862\n","Loss =  tensor(0.3168, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9863\n","Loss =  tensor(0.1061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9864\n","Loss =  tensor(0.0428, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9865\n","Loss =  tensor(0.0251, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9866\n","Loss =  tensor(0.0474, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9867\n","Loss =  tensor(0.1348, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9868\n","Loss =  tensor(0.0293, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9869\n","Loss =  tensor(0.0080, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9870\n","Loss =  tensor(0.0397, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9871\n","Loss =  tensor(0.0019, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9872\n","Loss =  tensor(0.0349, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9873\n","Loss =  tensor(0.0115, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9874\n","Loss =  tensor(0.0226, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9875\n","Loss =  tensor(0.0952, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9876\n","Loss =  tensor(0.1051, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9877\n","Loss =  tensor(0.0332, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9878\n","Loss =  tensor(0.2405, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9879\n","Loss =  tensor(0.1284, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9880\n","Loss =  tensor(0.0884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9881\n","Loss =  tensor(0.0331, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9882\n","Loss =  tensor(0.0061, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9883\n","Loss =  tensor(0.0084, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9884\n","Loss =  tensor(0.0220, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9885\n","Loss =  tensor(0.0209, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9886\n","Loss =  tensor(0.0071, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9887\n","Loss =  tensor(0.0308, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9888\n","Loss =  tensor(0.0188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9889\n","Loss =  tensor(0.0160, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9890\n","Loss =  tensor(0.0645, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9891\n","Loss =  tensor(0.0340, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9892\n","Loss =  tensor(0.0630, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9893\n","Loss =  tensor(0.1237, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9894\n","Loss =  tensor(0.0476, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9895\n","Loss =  tensor(0.0535, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9896\n","Loss =  tensor(0.0285, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9897\n","Loss =  tensor(0.0884, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9898\n","Loss =  tensor(0.1705, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9899\n","Loss =  tensor(0.0272, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9900\n","Loss =  tensor(0.0507, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9901\n","Loss =  tensor(0.1458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9902\n","Loss =  tensor(0.0781, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9903\n","Loss =  tensor(0.0312, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9904\n","Loss =  tensor(0.2971, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9905\n","Loss =  tensor(0.2182, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9906\n","Loss =  tensor(0.0157, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9907\n","Loss =  tensor(0.1238, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9908\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9909\n","Loss =  tensor(0.0660, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9910\n","Loss =  tensor(0.0012, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9911\n","Loss =  tensor(0.0640, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9912\n","Loss =  tensor(0.1624, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9913\n","Loss =  tensor(0.0877, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9914\n","Loss =  tensor(0.0094, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9915\n","Loss =  tensor(0.0458, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9916\n","Loss =  tensor(0.0077, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9917\n","Loss =  tensor(0.0407, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9918\n","Loss =  tensor(0.0151, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9919\n","Loss =  tensor(0.0501, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9920\n","Loss =  tensor(0.0357, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9921\n","Loss =  tensor(0.0175, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9922\n","Loss =  tensor(0.0637, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9923\n","Loss =  tensor(0.0181, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9924\n","Loss =  tensor(0.0288, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9925\n","Loss =  tensor(0.0596, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9926\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2001], grad_fn=<SelectBackward0>)\n","\n","Training step  9927\n","Loss =  tensor(0.0521, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.1999], grad_fn=<SelectBackward0>)\n","\n","Training step  9928\n","Loss =  tensor(0.0516, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9929\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9930\n","Loss =  tensor(0.0188, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9931\n","Loss =  tensor(0.0270, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9932\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9933\n","Loss =  tensor(0.0073, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9934\n","Loss =  tensor(0.0232, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9935\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9936\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9937\n","Loss =  tensor(0.0068, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9938\n","Loss =  tensor(0.0102, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9939\n","Loss =  tensor(0.0026, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9940\n","Loss =  tensor(0.0029, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9941\n","Loss =  tensor(0.0122, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9942\n","Loss =  tensor(0.0119, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9943\n","Loss =  tensor(0.0186, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9944\n","Loss =  tensor(0.0069, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9945\n","Loss =  tensor(0.0024, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9946\n","Loss =  tensor(0.0031, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9947\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9948\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9949\n","Loss =  tensor(0.0001, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9950\n","Loss =  tensor(0.0032, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9951\n","Loss =  tensor(0.0048, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9952\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9953\n","Loss =  tensor(0.0035, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9954\n","Loss =  tensor(0.0038, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9955\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9956\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9957\n","Loss =  tensor(0.0027, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9958\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9959\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9960\n","Loss =  tensor(0.0017, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9961\n","Loss =  tensor(0.0020, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9962\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9963\n","Loss =  tensor(0.0010, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9964\n","Loss =  tensor(0.0023, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9965\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9966\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9967\n","Loss =  tensor(0.0036, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9968\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9969\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9970\n","Loss =  tensor(0.0028, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9971\n","Loss =  tensor(0.0022, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9972\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9973\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9974\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9975\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9976\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9977\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9978\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9979\n","Loss =  tensor(0.0011, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9980\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9981\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9982\n","Loss =  tensor(0.0015, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9983\n","Loss =  tensor(3.1291e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9984\n","Loss =  tensor(0.0014, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9985\n","Loss =  tensor(0.0006, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9986\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9987\n","Loss =  tensor(0.0013, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9988\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9989\n","Loss =  tensor(4.1843e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9990\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9991\n","Loss =  tensor(0.0003, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9992\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9993\n","Loss =  tensor(4.5621e-05, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9994\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9995\n","Loss =  tensor(0.0005, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9996\n","Loss =  tensor(0.0007, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9997\n","Loss =  tensor(0.0009, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9998\n","Loss =  tensor(0.0004, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","Training step  9999\n","Loss =  tensor(0.0002, grad_fn=<MseLossBackward0>)\n","w[0] =  tensor([1.2000], grad_fn=<SelectBackward0>)\n","\n","End of training\n","[[ 1.1999874e+00]\n"," [-1.5746373e-05]\n"," [ 4.5004578e+00]\n"," [ 2.0005014e+00]\n"," [ 1.9911551e+00]]\n"]}],"source":["w2 = torch.tensor(torch.randn([5, 1]), requires_grad=True)\n","opt2 = torch.optim.Adam([w2], 0.1)\n","\n","def model2(x):\n","  g = torch.stack([ x*x*x*x, x*x*x, x*x, x , torch.ones_like(x)], 1)\n","  pred = torch.squeeze(g @ w2, 1)\n","  return pred\n","\n","def data_generator2():\n","  # Generate some training data (between -10 and 10) based on the true function\n","  x = torch.rand(100) * 20 - 10\n","  y = 1.2*x*x*x*x + 4.5*x*x + 2*x + 2  \n","  return x, y\n","\n","def train_step2():\n","  x, y = data_generator2()\n","  pred = model2(x) #g(x,w)\n","  loss = compute_loss(y, pred)\n","\n","  opt2.zero_grad()\n","  loss.backward()\n","  opt2.step()\n","  print(\"Loss = \", loss)\n","\n","for i in range(10000):\n","    print(\"Training step \", i)\n","    train_step2()\n","    print(\"w[0] = \", w2[0])\n","    print(\"\")\n","\n","print(\"End of training\")\n","print(w2.detach().numpy())\n"]}],"metadata":{"colab":{"collapsed_sections":["G50odvEWhgkv","zmGWOQATK0iZ","0hbIeSgD_YUw"],"name":"1_deep-learning-theory-with-pytorch.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.10"}},"nbformat":4,"nbformat_minor":0}
